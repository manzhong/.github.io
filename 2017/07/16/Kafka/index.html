<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-bounce.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":false,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Kafka消息队列 一消息队列概述 1 kafka企业级消息系统kafka企业级消息系统 为何使用消息系统  在没有使用消息系统以前，我们对于传统许多业务，以及跨服务器传递消息的时候，会采用串行方式或者并行方法；  与串行的差别是并行的方式可以缩短程序整体处理的时间。  消息系统:  消息系统负责将数据从一个应用程序传送到另一个应用程序，因此应用程序可以专注于数据，但是不必担心 如何共享它。分布式">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka">
<meta property="og:url" content="http://example.com/2017/07/16/Kafka/index.html">
<meta property="og:site_name" content="春雨里洗过的太阳">
<meta property="og:description" content="Kafka消息队列 一消息队列概述 1 kafka企业级消息系统kafka企业级消息系统 为何使用消息系统  在没有使用消息系统以前，我们对于传统许多业务，以及跨服务器传递消息的时候，会采用串行方式或者并行方法；  与串行的差别是并行的方式可以缩短程序整体处理的时间。  消息系统:  消息系统负责将数据从一个应用程序传送到另一个应用程序，因此应用程序可以专注于数据，但是不必担心 如何共享它。分布式">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/kafka/jg.jpg">
<meta property="og:image" content="http://example.com/images/kafka/jgg.jpg">
<meta property="og:image" content="http://example.com/images/kafka/ztjg.jpg">
<meta property="og:image" content="http://example.com/images/kafka/fq.jpg">
<meta property="og:image" content="http://example.com/images/kafka/fb.jpg">
<meta property="article:published_time" content="2017-07-16T10:30:57.000Z">
<meta property="article:modified_time" content="2020-12-13T13:17:02.764Z">
<meta property="article:author" content="HF">
<meta property="article:tag" content="Kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/kafka/jg.jpg">

<link rel="canonical" href="http://example.com/2017/07/16/Kafka/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>
<link rel="stylesheet" type="text/css" href="/css/injector.css" />
  <title>Kafka | 春雨里洗过的太阳</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">春雨里洗过的太阳</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">世间所有的相遇，都是久别重逢</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/07/16/Kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/hexo.jpg">
      <meta itemprop="name" content="HF">
      <meta itemprop="description" content="第二名就是头号输家">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="春雨里洗过的太阳">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kafka
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-07-16 18:30:57" itemprop="dateCreated datePublished" datetime="2017-07-16T18:30:57+08:00">2017-07-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-13 21:17:02" itemprop="dateModified" datetime="2020-12-13T21:17:02+08:00">2020-12-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Kafka/" itemprop="url" rel="index"><span itemprop="name">Kafka</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>36k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>32 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Kafka消息队列"><a href="#Kafka消息队列" class="headerlink" title="Kafka消息队列"></a>Kafka消息队列</h1><h2 id="一消息队列概述"><a href="#一消息队列概述" class="headerlink" title="一消息队列概述"></a>一消息队列概述</h2><h3 id="1-kafka企业级消息系统kafka企业级消息系统"><a href="#1-kafka企业级消息系统kafka企业级消息系统" class="headerlink" title="1 kafka企业级消息系统kafka企业级消息系统"></a>1 kafka企业级消息系统kafka企业级消息系统</h3><p><strong>为何使用消息系统</strong></p>
<p>在没有使用消息系统以前，我们对于传统许多业务，以及跨服务器传递消息的时候，会采用串行方式或者并行方法；</p>
<p>与串行的差别是并行的方式可以缩短程序整体处理的时间。</p>
<p><strong>消息系统:</strong></p>
<p>消息系统负责将数据从一个应用程序传送到另一个应用程序，因此应用程序可以专注于数据，但是不必担心 如何共享它。分布式消息系统基于可靠的消息队列的概念。消息在客户端应用程序和消息传递系统之间的异步排队。</p>
<p>有两种类型的消息模式可用    点对点；发布-订阅消息系统</p>
<p>点对点消息系统中，消息被保留在队列中，一个或者多个消费者可以消费队列中的消息，但是特定的消 息只能有最多的一个消费者消费。一旦消费者读取队列中的消息，他就从该队列中消失。该系统的典型应用就是订单处理系统，其中每个订单将有一个订单处理器处理，但多个订单处理器可以同时工作。</p>
<p>大多数的消息系统是基于发布-订阅消息系统</p>
<p><strong>分类</strong></p>
<h2 id="2-1、点对点"><a href="#2-1、点对点" class="headerlink" title="2.1、点对点"></a>2.1、点对点</h2><p>主要采用的队列的方式，如A-&gt;B 当B消费的队列中的数据，那么队列的数据就会被删除掉【如果B不消费那么就会存在队列中有很多的脏数据】</p>
<h2 id="2-2、发布-订阅"><a href="#2-2、发布-订阅" class="headerlink" title="2.2、发布-订阅"></a>2.2、发布-订阅</h2><p>发布与订阅主要三大组件</p>
<p>主题：一个消息的分类 </p>
<p>发布者：将消息通过主动推送的方式推送给消息系统；</p>
<p>订阅者：可以采用拉、推的方式从消息系统中获取数据</p>
<p><strong>应用场景</strong></p>
<h2 id="3-1、应用解耦"><a href="#3-1、应用解耦" class="headerlink" title="3.1、应用解耦"></a>3.1、应用解耦</h2><p>将一个大型的任务系统分成若干个小模块，将所有的消息进行统一的管理和存储，因此为了解耦，就会涉及到kafka企业级消息平台</p>
<h2 id="3-2、流量控制"><a href="#3-2、流量控制" class="headerlink" title="3.2、流量控制"></a>3.2、流量控制</h2><p>秒杀活动当中，一般会因为流量过大，应用服务器挂掉，为了解决这个问题，一般需要在应用前端加上消息队列以控制访问流量。</p>
<p>1、 可以控制活动的人数 可以缓解短时间内流量大使得服务器崩掉</p>
<p>2、 可以通过队列进行数据缓存，后续再进行消费处理</p>
<h2 id="3-3、日志处理"><a href="#3-3、日志处理" class="headerlink" title="3.3、日志处理"></a>3.3、日志处理</h2><p>日志处理指将消息队列用在日志处理中，比如kafka的应用中，解决大量的日志传输问题；</p>
<p>日志采集工具采集 数据写入kafka中；kafka消息队列负责日志数据的接收，存储，转发功能；</p>
<p>日志处理应用程序：订阅并消费 kafka队列中的数据，进行数据分析。</p>
<h2 id="3-4、消息通讯"><a href="#3-4、消息通讯" class="headerlink" title="3.4、消息通讯"></a>3.4、消息通讯</h2><p>消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯，比如点对点的消息队列，或者聊天室等。</p>
<h1 id="二-kafka概述"><a href="#二-kafka概述" class="headerlink" title="二 kafka概述"></a>二 kafka概述</h1><p>kafka是最初由linkedin公司开发的，使用scala语言编写，kafka是一个分布式，分区的，多副本的，多订阅者的日志系统（分布式MQ系统），可以用于搜索日志，监控日志，访问日志等。</p>
<p>kafka目前支持多种客户端的语言：java、python、c++、php等</p>
<p>apache kafka是一个分布式发布-订阅消息系统和一个强大的队列，可以处理大量的数据，并使能够将消息从一个端点传递到另一个端点，kafka适合离线和在线消息消费。kafka消息保留在磁盘上，并在集群内复制以防止数据丢失。kafka构建在zookeeper同步服务之上。它与apache和spark非常好的集成，应用于实时流式数据分析。</p>
<p>其他消息队列:</p>
<p>RabbitMQ </p>
<p>Redis </p>
<p>ZeroMQ </p>
<p>ActiveMQ</p>
<p><strong>kafka好处:</strong></p>
<p>可靠性：分布式的，分区，复制和容错的。</p>
<p>可扩展性：kafka消息传递系统轻松缩放，无需停机。</p>
<p>耐用性：kafka使用分布式提交日志，这意味着消息会尽可能快速的保存在磁盘上，因此它是持久的。 </p>
<p>性能：kafka对于发布和定于消息都具有高吞吐量。即使存储了许多TB的消息，他也爆出稳定的性能。 </p>
<p>kafka非常快：保证零停机和零数据丢失。</p>
<p><strong>应用场景</strong></p>
<h2 id="5-1、指标分析"><a href="#5-1、指标分析" class="headerlink" title="5.1、指标分析"></a>5.1、指标分析</h2><p>kafka   通常用于操作监控数据。这设计聚合来自分布式应用程序的统计信息，   以产生操作的数据集中反馈</p>
<h2 id="5-2、日志聚合解决方法"><a href="#5-2、日志聚合解决方法" class="headerlink" title="5.2、日志聚合解决方法"></a>5.2、日志聚合解决方法</h2><p>kafka可用于跨组织从多个服务器收集日志，并使他们以标准的合适提供给多个服务器。</p>
<h2 id="5-3、流式处理"><a href="#5-3、流式处理" class="headerlink" title="5.3、流式处理"></a>5.3、流式处理</h2><p>流式处理框架（spark，storm，ﬂink）重主题中读取数据，对齐进行处理，并将处理后的数据写入新的主题，供 用户和应用程序使用，kafka的强耐久性在流处理的上下文中也非常的有用。</p>
<h1 id="三架构"><a href="#三架构" class="headerlink" title="三架构"></a>三架构</h1><p><img src="/images/kafka/jg.jpg" alt="img"></p>
<p>四大核心:</p>
<h5 id="生产者API"><a href="#生产者API" class="headerlink" title="生产者API"></a>生产者API</h5><p>允许应用程序发布记录流至一个或者多个kafka的主题（topics）。</p>
<h5 id="消费者API"><a href="#消费者API" class="headerlink" title="消费者API"></a>消费者API</h5><p>允许应用程序订阅一个或者多个主题，并处理这些主题接收到的记录流。</p>
<h5 id="StreamsAPI"><a href="#StreamsAPI" class="headerlink" title="StreamsAPI"></a>StreamsAPI</h5><p>允许应用程序充当流处理器（stream processor），从一个或者多个主题获取输入流，并生产一个输出流到一个或 者多个主题，能够有效的变化输入流为输出流。</p>
<h5 id="ConnectorAPI"><a href="#ConnectorAPI" class="headerlink" title="ConnectorAPI"></a>ConnectorAPI</h5><p>允许构建和运行可重用的生产者或者消费者，能够把kafka主题连接到现有的应用程序或数据系统。例如：一个连 接到关系数据库的连接器可能会获取每个表的变化。</p>
<p><strong>架构关系图</strong></p>
<p><img src="/images/kafka/jgg.jpg" alt="img"></p>
<p>说明：kafka支持消息持久化，消费端为拉模型来拉取数据，消费状态和订阅关系有客户端负责维护，消息消费完 后，不会立即删除，会保留历史消息。因此支持多订阅时，消息只会存储一份就可以了</p>
<p><strong>整体架构</strong></p>
<p><img src="/images/kafka/ztjg.jpg" alt="img"></p>
<p>一个典型的kafka集群中包含若干个Producer，若干个Broker，若干个Consumer，以及一个zookeeper集群； kafka通过zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行Rebalance（负载均 衡）；Producer使用push模式将消息发布到Broker；Consumer使用pull模式从Broker中订阅并消费消息。</p>
<p><strong>kafka术语介绍</strong></p>
<p><strong>Broker</strong>：kafka集群中包含一个或者多个服务实例，这种服务实例被称为Broker</p>
<p><strong>Topic</strong>：每条发布到kafka集群的消息都有一个类别，这个类别就叫做Topic </p>
<p><strong>Partition</strong>：Partition是一个物理上的概念，每个Topic包含一个或者多个Partition </p>
<p><strong>Producer</strong>：负责发布消息到kafka的Broker中。</p>
<p><strong>Consumer</strong>：消息消费者,向kafka的broker中读取消息的客户端</p>
<p><strong>Consumer Group</strong>：每一个Consumer属于一个特定的Consumer Group（可以为每个Consumer指定 groupName）</p>
<p><strong>kafka中topic说明</strong></p>
<p> 1,kafka将消息以topic为单位进行归类</p>
<p>  2,topic特指kafka处理的消息源（feeds of messages）的不同分类。</p>
<p>  3.topic是一种分类或者发布的一些列记录的名义上的名字。kafka主题始终是支持多用户订阅的；也就是说，一 个主题可以有零个，一个或者多个消费者订阅写入的数据。</p>
<p>  4.在kafka集群中，可以有无数的主题。</p>
<p>  5.生产者和消费者消费数据一般以主题为单位。更细粒度可以到分区级别。</p>
<p><strong>kafka中分区数</strong></p>
<p>Partitions：分区数：控制topic将分片成多少个log，可以显示指定，如果不指定则会使用 broker（server.properties）中的num.partitions配置的数量。</p>
<p>一个broker服务下，是否可以创建多个分区？</p>
<p>可以的，broker数与分区数没有关系； 在kafka中，每一个分区会有一个编号：编号从0开始</p>
<p>某一个分区的数据是有序的</p>
<p>如何保证一个主题是有序的:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一个主题下面只有一个分区即可</span><br></pre></td></tr></table></figure>

<p>topic的Partition数量在创建topic时配置。</p>
<p>Partition数量决定了每个Consumer group中并发消费者的最大数量。</p>
<p>Consumer group A 有两个消费者来读取4个partition中数据；Consumer group B有四个消费者来读取4个 partition中的数据</p>
<p><img src="/images/kafka/fq.jpg" alt="img"></p>
<p><strong>kafka中的副本数</strong></p>
<p><img src="/images/kafka/fb.jpg" alt="img"></p>
<p>kafka分区副本数（kafka Partition Replicas)</p>
<p>副本数（replication-factor）：控制消息保存在几个broker（服务器）上，一般情况下等于broker的个数</p>
<p>一个broker服务下，是否可以创建多个副本因子？</p>
<p>​             不可以；创建主题时，副本因子应该小于等于可用的broker数。 </p>
<p>副本因子操作以分区为单位的。每个分区都有各自的主副本和从副本；主副本叫做leader，从副本叫做 follower（在有多个副本的情况下，kafka会为同一个分区下的分区，设定角色关系：一个leader和N个 follower），处于同步状态的副本叫做<strong>in-sync-replicas</strong>(ISR);follower通过拉的方式从leader同步数据。消费 者和生产者都是从leader读写数据，不与follower交互。</p>
<p><strong>副本因子的作用</strong>：让kafka读取数据和写入数据时的可靠性.</p>
<p>副本因子是包含本身|同一个副本因子不能放在同一个Broker中。</p>
<p>如果某一个分区有三个副本因子，就算其中一个挂掉，那么只会剩下的两个钟，选择一个leader，但不会在其 他的broker中，另启动一个副本（因为在另一台启动的话，存在数据传递，只要在机器之间有数据传递，就 会长时间占用网络IO，kafka是一个高吞吐量的消息系统，这个情况不允许发生）所以不会在零个broker中启 动。</p>
<p>如果所有的副本都挂了，生产者如果生产数据到指定分区的话，将写入不成功。</p>
<p>lsr表示：当前可用的副本</p>
<p><strong>kafka的partition offset</strong></p>
<p>任何发布到此partition的消息都会被直接追加到log文件的尾部，每条消息在文件中的位置称为oﬀset（偏移量），</p>
<p>oﬀset是一个long类型数字，它唯一标识了一条消息，消费者通过（oﬀset，partition，topic）跟踪记录。</p>
<p><strong>kafka分区与消费组之间的关系</strong></p>
<p>消费组： 由一个或者多个消费者组成，同一个组中的消费者对于同一条消息只消费一次。</p>
<p>某一个主题下的分区数，对于消费组来说，应该小于等于该主题下的分区数。如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">如：某一个主题有4个分区，那么消费组中的消费者应该小于4，而且最好与分区数成整数倍</span><br><span class="line">1	2	4</span><br><span class="line">同一个分区下的数据，在同一时刻，不能同一个消费组的不同消费者消费</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>总结：分区数越多，同一时间可以有越多的消费者来进行消费，消费数据的速度就会越快，提高消费的性能</p>
<h1 id="四-集群搭建"><a href="#四-集群搭建" class="headerlink" title="四 集群搭建"></a>四 集群搭建</h1><h2 id="1-jdk-与zookeeper必须安装"><a href="#1-jdk-与zookeeper必须安装" class="headerlink" title="1 jdk 与zookeeper必须安装"></a>1 jdk 与zookeeper必须安装</h2><h2 id="2-安装用户"><a href="#2-安装用户" class="headerlink" title="2 安装用户"></a>2 安装用户</h2><p>如默认用户安装则跳过这一步骤</p>
<p>安装hadoop，会创建一个hadoop用户 </p>
<p>安装kafka，创建一个kafka用户</p>
<p>或者 创建bigdata用户，用来安装所有的大数据软件</p>
<p>本例：使用root用户来进行安装</p>
<h2 id="3验证环境"><a href="#3验证环境" class="headerlink" title="3验证环境"></a>3验证环境</h2><p>保证三台机器的zk服务都正常启动，且正常运行</p>
<p>  查看zk的运行装填，保证有一台zk的服务状态为leader，且两台为follower即可</p>
<h2 id="4下载安装包"><a href="#4下载安装包" class="headerlink" title="4下载安装包"></a>4下载安装包</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;kafka&#x2F;0.10.0.0&#x2F;kafka_2.11-0.10.0.0.tgz</span><br></pre></td></tr></table></figure>

<h2 id="5上传解压"><a href="#5上传解压" class="headerlink" title="5上传解压"></a>5上传解压</h2><h2 id="6修改配置文件"><a href="#6修改配置文件" class="headerlink" title="6修改配置文件"></a>6修改配置文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;export&#x2F;servers&#x2F;kafka_2.11-0.10.0.0&#x2F;config</span><br><span class="line">vim server.properties</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">broker.id&#x3D;0</span><br><span class="line">num.network.threads&#x3D;3</span><br><span class="line">num.io.threads&#x3D;8</span><br><span class="line">socket.send.buffer.bytes&#x3D;102400</span><br><span class="line">socket.receive.buffer.bytes&#x3D;102400</span><br><span class="line">socket.request.max.bytes&#x3D;104857600</span><br><span class="line">log.dirs&#x3D;&#x2F;export&#x2F;servers&#x2F;kafka_2.11-0.10.0.0&#x2F;logs</span><br><span class="line">num.partitions&#x3D;2</span><br><span class="line">num.recovery.threads.per.data.dir&#x3D;1</span><br><span class="line">offsets.topic.replication.factor&#x3D;1</span><br><span class="line">transaction.state.log.replication.factor&#x3D;1</span><br><span class="line">transaction.state.log.min.isr&#x3D;1</span><br><span class="line">log.flush.interval.messages&#x3D;10000</span><br><span class="line">log.flush.interval.ms&#x3D;1000</span><br><span class="line">log.retention.hours&#x3D;168</span><br><span class="line">log.segment.bytes&#x3D;1073741824</span><br><span class="line">log.retention.check.interval.ms&#x3D;300000</span><br><span class="line">zookeeper.connect&#x3D;node01:2181,node02:2181,node03:2181</span><br><span class="line">zookeeper.connection.timeout.ms&#x3D;6000</span><br><span class="line">group.initial.rebalance.delay.ms&#x3D;0</span><br><span class="line">delete.topic.enable&#x3D;true</span><br><span class="line">host.name&#x3D;node01            &#x2F;&#x2F;每台主机不一样</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>创建数据文件存放目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p  &#x2F;export&#x2F;servers&#x2F;kafka_2.11-0.10.0.0&#x2F;logs</span><br></pre></td></tr></table></figure>

<p>分发安装包:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;export&#x2F;servers&#x2F;</span><br><span class="line">scp -r kafka_2.11-0.10.0.0&#x2F; node02:$PWD</span><br><span class="line">scp -r kafka_2.11-0.10.0.0&#x2F; node03:$PWD</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>node02修改:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;export&#x2F;servers&#x2F;kafka_2.11-0.10.0.0&#x2F;config</span><br><span class="line">vim server.properties</span><br><span class="line"></span><br><span class="line">broker.id&#x3D;1</span><br><span class="line">num.network.threads&#x3D;3</span><br><span class="line">num.io.threads&#x3D;8</span><br><span class="line">socket.send.buffer.bytes&#x3D;102400</span><br><span class="line">socket.receive.buffer.bytes&#x3D;102400</span><br><span class="line">socket.request.max.bytes&#x3D;104857600</span><br><span class="line">log.dirs&#x3D;&#x2F;export&#x2F;servers&#x2F;kafka_2.11-0.10.0.0&#x2F;logs</span><br><span class="line">num.partitions&#x3D;2</span><br><span class="line">num.recovery.threads.per.data.dir&#x3D;1</span><br><span class="line">offsets.topic.replication.factor&#x3D;1</span><br><span class="line">transaction.state.log.replication.factor&#x3D;1</span><br><span class="line">transaction.state.log.min.isr&#x3D;1</span><br><span class="line">log.flush.interval.messages&#x3D;10000</span><br><span class="line">log.flush.interval.ms&#x3D;1000</span><br><span class="line">log.retention.hours&#x3D;168</span><br><span class="line">log.segment.bytes&#x3D;1073741824</span><br><span class="line">log.retention.check.interval.ms&#x3D;300000</span><br><span class="line">zookeeper.connect&#x3D;node01:2181,node02:2181,node03:2181</span><br><span class="line">zookeeper.connection.timeout.ms&#x3D;6000</span><br><span class="line">group.initial.rebalance.delay.ms&#x3D;0</span><br><span class="line">delete.topic.enable&#x3D;true</span><br><span class="line">host.name&#x3D;node02</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>node03修改</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;export&#x2F;servers&#x2F;kafka_2.11-0.10.0.0&#x2F;config</span><br><span class="line">vim server.properties</span><br><span class="line"></span><br><span class="line">broker.id&#x3D;2</span><br><span class="line">num.network.threads&#x3D;3</span><br><span class="line">num.io.threads&#x3D;8</span><br><span class="line">socket.send.buffer.bytes&#x3D;102400</span><br><span class="line">socket.receive.buffer.bytes&#x3D;102400</span><br><span class="line">socket.request.max.bytes&#x3D;104857600</span><br><span class="line">log.dirs&#x3D;&#x2F;export&#x2F;servers&#x2F;kafka_2.11-0.10.0.0&#x2F;logs</span><br><span class="line">num.partitions&#x3D;2</span><br><span class="line">num.recovery.threads.per.data.dir&#x3D;1</span><br><span class="line">offsets.topic.replication.factor&#x3D;1</span><br><span class="line">transaction.state.log.replication.factor&#x3D;1</span><br><span class="line">transaction.state.log.min.isr&#x3D;1</span><br><span class="line">log.flush.interval.messages&#x3D;10000</span><br><span class="line">log.flush.interval.ms&#x3D;1000</span><br><span class="line">log.retention.hours&#x3D;168</span><br><span class="line">log.segment.bytes&#x3D;1073741824</span><br><span class="line">log.retention.check.interval.ms&#x3D;300000</span><br><span class="line">zookeeper.connect&#x3D;node01:2181,node02:2181,node03:2181</span><br><span class="line">zookeeper.connection.timeout.ms&#x3D;6000</span><br><span class="line">group.initial.rebalance.delay.ms&#x3D;0</span><br><span class="line">delete.topic.enable&#x3D;true</span><br><span class="line">host.name&#x3D;node03</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>启动集群:</p>
<p><strong>注意事项</strong>：在kafka启动前，一定要让zookeeper启动起来。</p>
<p>前台启动:</p>
<p>node01服务器执行以下命令来启动kafka集群</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;export&#x2F;servers&#x2F;kafka_2.11-0.10.0.0</span><br><span class="line">bin&#x2F;kafka-server-start.sh config&#x2F;server.properties</span><br></pre></td></tr></table></figure>

<p>后台启动:</p>
<p><strong>node01**</strong>执行以下命令将kafka进程启动在后台**</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;export&#x2F;servers&#x2F;kafka_2.11-0.10.0.0</span><br><span class="line">nohup bin&#x2F;kafka-server-start.sh config&#x2F;server.properties &gt;&#x2F;export&#x2F;log&#x2F;kafka.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>

<p>停止命令:</p>
<p>node01执行以下命令便可以停止kakfa进程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;export&#x2F;servers&#x2F;kafka_2.11-0.10.0.0</span><br><span class="line">bin&#x2F;kafka-server-stop.sh</span><br></pre></td></tr></table></figure>

<p>查看启动进程:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure>

<h1 id="五-集群操作"><a href="#五-集群操作" class="headerlink" title="五 集群操作"></a>五 集群操作</h1><p>nohup bin/kafka-server-start.sh config/server.properties 2&gt;&amp;1 &amp;</p>
<h3 id="创建topic"><a href="#创建topic" class="headerlink" title="创建topic"></a>创建topic</h3><p>三分区 两副本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --create  --partitions 3 --replication-factor 2 --topic test --zookeeper node01:2181,node02:2181,node03:2181</span><br></pre></td></tr></table></figure>

<h3 id="查看topic"><a href="#查看topic" class="headerlink" title="查看topic"></a>查看topic</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --list --zookeeper node01:2181,node02:2181,node03:2181</span><br></pre></td></tr></table></figure>

<h3 id="生产数据"><a href="#生产数据" class="headerlink" title="生产数据"></a>生产数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-console-producer.sh --broker-list node01:9092,node02:9092,node03:9092 --topic test</span><br></pre></td></tr></table></figure>

<h3 id="消费数据"><a href="#消费数据" class="headerlink" title="消费数据"></a>消费数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-console-consumer.sh --from-beginning  --topic test --zookeeper node01:2181,node02:2181,node03:2181</span><br></pre></td></tr></table></figure>

<h3 id="查看topic的一些信息"><a href="#查看topic的一些信息" class="headerlink" title="查看topic的一些信息"></a>查看topic的一些信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --describe  --topic test --zookeeper node01:2181</span><br></pre></td></tr></table></figure>

<h3 id="修改topic的配置属性"><a href="#修改topic的配置属性" class="headerlink" title="修改topic的配置属性"></a>修改topic的配置属性</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --zookeeper node01:2181 --alter --topic test --config flush.messages&#x3D;1</span><br></pre></td></tr></table></figure>

<h3 id="删除topic"><a href="#删除topic" class="headerlink" title="删除topic"></a>删除topic</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --zookeeper node01:2181 --delete --topic test</span><br></pre></td></tr></table></figure>



<h2 id="kafka集群当中JavaAPI操作"><a href="#kafka集群当中JavaAPI操作" class="headerlink" title="kafka集群当中JavaAPI操作"></a>kafka集群当中JavaAPI操作</h2><p>依赖</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependencies&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.kafka&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;kafka-clients&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;version&gt; 0.10.0.0&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;&#x2F;dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.kafka&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;kafka-streams&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;version&gt;0.10.0.0&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;&#x2F;dependencies&gt;</span><br><span class="line"></span><br><span class="line">&lt;build&gt;</span><br><span class="line">    &lt;plugins&gt;</span><br><span class="line">        &lt;!-- java编译插件 --&gt;</span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;maven-compiler-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;version&gt;3.2&lt;&#x2F;version&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;source&gt;1.8&lt;&#x2F;source&gt;</span><br><span class="line">                &lt;target&gt;1.8&lt;&#x2F;target&gt;</span><br><span class="line">                &lt;encoding&gt;UTF-8&lt;&#x2F;encoding&gt;</span><br><span class="line">            &lt;&#x2F;configuration&gt;</span><br><span class="line">        &lt;&#x2F;plugin&gt;</span><br><span class="line">    &lt;&#x2F;plugins&gt;</span><br><span class="line">&lt;&#x2F;build&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="kafka集群当中ProducerAPI"><a href="#kafka集群当中ProducerAPI" class="headerlink" title="kafka集群当中ProducerAPI"></a>kafka集群当中ProducerAPI</h3><p>生产者代码:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyProducer</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 实现生产数据到kafka test这个topic里面去</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">//kafka的机器</span></span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;node01:9092&quot;</span>);</span><br><span class="line">        <span class="comment">//消息确认机制</span></span><br><span class="line">        props.put(<span class="string">&quot;acks&quot;</span>, <span class="string">&quot;all&quot;</span>);</span><br><span class="line">        <span class="comment">//消息没有发送成功 重试几次</span></span><br><span class="line">        props.put(<span class="string">&quot;retries&quot;</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="comment">//消息最大一批次 发送多少条</span></span><br><span class="line">        props.put(<span class="string">&quot;batch.size&quot;</span>, <span class="number">16384</span>);</span><br><span class="line">        <span class="comment">//消息每条都进行确认</span></span><br><span class="line">        props.put(<span class="string">&quot;linger.ms&quot;</span>, <span class="number">1</span>);</span><br><span class="line">        <span class="comment">//缓存内存大小</span></span><br><span class="line">        props.put(<span class="string">&quot;buffer.memory&quot;</span>, <span class="number">33554432</span>);</span><br><span class="line">        <span class="comment">//一下俩个  k和value 进行序列化 和反序列化</span></span><br><span class="line">        props.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        <span class="comment">//获取kafakProducer这个类</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">        <span class="comment">//使用循环发送消息</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i&lt;<span class="number">100</span>;i++)&#123;</span><br><span class="line">           <span class="comment">// kafkaProducer.send(new ProducerRecord&lt;String, String&gt;(&quot;test&quot;,&quot;mymessage&quot; + i));</span></span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">&quot;mypartition&quot;</span>,<span class="string">&quot;mymessage&quot;</span> + i));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//关闭生产者</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="kafka集群当中的consumerAPI"><a href="#kafka集群当中的consumerAPI" class="headerlink" title="kafka集群当中的consumerAPI"></a>kafka集群当中的consumerAPI</h3><p>消费者:</p>
<p>自动提交offset：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AutomaticConsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自动提交offset</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;node01:9092&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;test_group&quot;</span>);  <span class="comment">//消费组</span></span><br><span class="line">        props.put(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;true&quot;</span>);<span class="comment">//允许自动提交offset</span></span><br><span class="line">        props.put(<span class="string">&quot;auto.commit.interval.ms&quot;</span>, <span class="string">&quot;1000&quot;</span>);<span class="comment">//每隔多久自动提交offset</span></span><br><span class="line">        props.put(<span class="string">&quot;session.timeout.ms&quot;</span>, <span class="string">&quot;30000&quot;</span>);</span><br><span class="line">        <span class="comment">//指定key，value的反序列化类</span></span><br><span class="line">        props.put(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定消费哪个topic里面的数据</span></span><br><span class="line">        kafkaConsumer.subscribe(Arrays.asList(<span class="string">&quot;test&quot;</span>));</span><br><span class="line">        <span class="comment">//使用死循环来消费test这个topic里面的数据</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>)&#123;</span><br><span class="line">            <span class="comment">//这里面是我们所有拉取到的数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(<span class="number">1000</span>);</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                <span class="keyword">long</span> offset = consumerRecord.offset();</span><br><span class="line">                String value = consumerRecord.value();</span><br><span class="line">                System.out.println(<span class="string">&quot;消息的offset值为&quot;</span>+offset +<span class="string">&quot;消息的value值为&quot;</span>+ value);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>手动提交offset：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MannualConsumer</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 实现手动的提交offset</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;node01:9092&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;test_group&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;false&quot;</span>); <span class="comment">//禁用自动提交offset，后期我们手动提交offset</span></span><br><span class="line">        props.put(<span class="string">&quot;auto.commit.interval.ms&quot;</span>, <span class="string">&quot;1000&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;session.timeout.ms&quot;</span>, <span class="string">&quot;30000&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">        kafkaConsumer.subscribe(Arrays.asList(<span class="string">&quot;test&quot;</span>));  <span class="comment">//订阅test这个topic</span></span><br><span class="line">        <span class="keyword">int</span> minBatchSize = <span class="number">200</span>;  <span class="comment">//达到200条进行批次的处理，处理完了之后，提交offset</span></span><br><span class="line">        List&lt;ConsumerRecord&lt;String, String&gt;&gt; consumerRecordList = <span class="keyword">new</span> ArrayList&lt;&gt;();<span class="comment">//定义一个集合，用于存储我们的ConsumerRecorder</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>)&#123;</span><br><span class="line"></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(<span class="number">1000</span>);</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                consumerRecordList.add(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(consumerRecordList.size() &gt;=  minBatchSize)&#123;</span><br><span class="line">                <span class="comment">//如果集合当中的数据大于等于200条的时候，我们批量进行处理</span></span><br><span class="line">                <span class="comment">//将这一批次的数据保存到数据库里面去</span></span><br><span class="line">                <span class="comment">//insertToDb(consumerRecordList);</span></span><br><span class="line">                System.out.println(<span class="string">&quot;手动提交offset的值&quot;</span>);</span><br><span class="line">                <span class="comment">//提交offset，表示这一批次的数据全部都处理完了</span></span><br><span class="line">               <span class="comment">// kafkaConsumer.commitAsync();  //异步提交offset值</span></span><br><span class="line">                kafkaConsumer.commitSync();<span class="comment">//同步提交offset的值</span></span><br><span class="line">                consumerRecordList.clear();<span class="comment">//清空集合当中的数据</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>offset：offset记录了每个分区里面的消息消费到了哪一条，下一次来的时候，我们继续从上一次的记录接着消费</p>
<h3 id="kafka的streamAPI"><a href="#kafka的streamAPI" class="headerlink" title="kafka的streamAPI"></a>kafka的streamAPI</h3><p>需求：使用StreamAPI获取test这个topic当中的数据，然后将数据全部转为大写，写入到test2这个topic当中去</p>
<h4 id="第一步：创建一个topic"><a href="#第一步：创建一个topic" class="headerlink" title="第一步：创建一个topic"></a>第一步：创建一个topic</h4><p>node01服务器使用以下命令来常见一个topic 名称为test2</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/servers/kafka_2.11-0.10.0.0/</span><br><span class="line">bin/kafka-topics.sh --create  --partitions 3 --replication-factor 2 --topic test2 --zookeeper node01:2181,node02:2181,node03:2181</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="第二步：开发StreamAPI"><a href="#第二步：开发StreamAPI" class="headerlink" title="第二步：开发StreamAPI"></a>第二步：开发StreamAPI</h4><p>注意：如果程序启动的时候抛出异常，找不到文件夹的路径，需要我们手动的去创建文件夹的路径</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Stream</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 通过streamAPI实现将数据从test里面读取出来，写入到test2里面去</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(StreamsConfig.APPLICATION_ID_CONFIG,<span class="string">&quot;bigger&quot;</span>);</span><br><span class="line">        properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">&quot;node01:9092&quot;</span>);</span><br><span class="line">        properties.put(StreamsConfig.KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());<span class="comment">//key的序列化和反序列化的类</span></span><br><span class="line">        properties.put(StreamsConfig.VALUE_SERDE_CLASS_CONFIG,Serdes.String().getClass());</span><br><span class="line">        <span class="comment">//获取核心类 KStreamBuilder</span></span><br><span class="line">        KStreamBuilder kStreamBuilder = <span class="keyword">new</span> KStreamBuilder();</span><br><span class="line">        <span class="comment">//通过KStreamBuilder调用stream方法表示从哪个topic当中获取数据</span></span><br><span class="line">        <span class="comment">//调用mapValues方法，表示将每一行value都给取出来</span></span><br><span class="line">        <span class="comment">//line表示我们取出来的一行行的数据</span></span><br><span class="line">        <span class="comment">//将转成大写的数据，写入到test2这个topic里面去</span></span><br><span class="line">        kStreamBuilder.stream(<span class="string">&quot;test&quot;</span>).mapValues(line -&gt; line.toString().toUpperCase()).to(<span class="string">&quot;test2&quot;</span>);</span><br><span class="line">        <span class="comment">//通过kStreamBuilder可以用于创建KafkaStream  通过kafkaStream来实现流失的编程启动</span></span><br><span class="line">        KafkaStreams kafkaStreams = <span class="keyword">new</span> KafkaStreams(kStreamBuilder, properties);</span><br><span class="line">        kafkaStreams.start();  <span class="comment">//调用start启动kafka的流 API</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="第三步：生产数据"><a href="#第三步：生产数据" class="headerlink" title="第三步：生产数据"></a>第三步：生产数据</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">node01执行以下命令，向test这个topic当中生产数据</span><br><span class="line">cd /export/servers/kafka_2.11-0.10.0.0</span><br><span class="line">bin/kafka-console-producer.sh --broker-list node01:9092,node02:9092,node03:9092 --topic test</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p> <strong>第四步：消费数据</strong></p>
<p>node02执行一下命令消费test2这个topic当中的数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /export/servers/kafka_2.11-0.10.0.0</span><br><span class="line">bin/kafka-console-consumer.sh --from-beginning  --topic test2 --zookeeper node01:2181,node02:2181,node03:2181</span><br></pre></td></tr></table></figure>

<h2 id="六-kafka原理"><a href="#六-kafka原理" class="headerlink" title="六 kafka原理"></a>六 kafka原理</h2><h3 id="一-生产者"><a href="#一-生产者" class="headerlink" title="一 生产者"></a>一 生产者</h3><p>生产者是一个向kafka Cluster发布记录的客户端；<strong>生产者是线程安全的</strong>，跨线程共享单个生产者实例通常比具有多个实例更快。</p>
<p><strong>必要条件</strong></p>
<p>生产者要进行生产数据到kafka  Cluster中，必要条件有以下三个：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#1、地址</span><br><span class="line">bootstrap.servers&#x3D;node01:9092</span><br><span class="line">#2、序列化 key.serializer&#x3D;org.apache.kafka.common.serialization.StringSerializer value.serializer&#x3D;org.apache.kafka.common.serialization.StringSerializer</span><br><span class="line">#3、主题（topic） 需要制定具体的某个topic（order）即可。</span><br></pre></td></tr></table></figure>

<p><strong>生产者写数据</strong></p>
<p>流程:</p>
<p>1、总体流程</p>
<p>Producer连接任意活着的Broker，请求指定Topic，Partion的Leader元数据信息，然后直接与对应的Broker直接连接，发布数据</p>
<p>2、开放分区接口(生产者数据分发策略)</p>
<p>2.1、用户可以指定分区函数，使得消息可以根据key，发送到指定的Partition中。</p>
<p>2.2、kafka在数据生产的时候，有一个数据分发策略。默认的情况使用DefaultPartitioner.class类。 这个类中就定义数据分发的策略。</p>
<p>2.3、如果是用户指定了partition，生产就不会调用DefaultPartitioner.partition()方法</p>
<p>2.4、当用户指定key，使用hash算法。如果key一直不变，同一个key算出来的hash值是个固定值。如果是固定 值，这种hash取模就没有意义。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions</span><br></pre></td></tr></table></figure>

<p>2.5、 当用既没有指定partition也没有key。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line">The default partitioning strategy:</span><br><span class="line">&lt;ul&gt;</span><br><span class="line">&lt;li&gt;If a partition is specified in the record, use it</span><br><span class="line">&lt;li&gt;If no partition is specified but a key is present choose a partition based on a hash of the key</span><br><span class="line">&lt;li&gt;If no partition or key is present choose a partition in a round-robin fashion</span><br><span class="line">*&#x2F;</span><br></pre></td></tr></table></figure>

<p>2.6、数据分发策略的时候，可以指定数据发往哪个partition。当ProducerRecord 的构造参数中有partition的时 候，就可以发送到对应partition上。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PartitionProducer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * kafka生产数据 通过不同的方式，将数据写入到不同的分区里面去</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;node01:9092&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;acks&quot;</span>, <span class="string">&quot;all&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;retries&quot;</span>, <span class="number">0</span>);</span><br><span class="line">        props.put(<span class="string">&quot;batch.size&quot;</span>, <span class="number">16384</span>);</span><br><span class="line">        props.put(<span class="string">&quot;linger.ms&quot;</span>, <span class="number">1</span>);</span><br><span class="line">        props.put(<span class="string">&quot;buffer.memory&quot;</span>, <span class="number">33554432</span>);</span><br><span class="line">        props.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//配置我们自定义分区类</span></span><br><span class="line">        props.put(<span class="string">&quot;partitioner.class&quot;</span>,<span class="string">&quot;cn.itcast.kafka.partition.MyPartitioner&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取kafakProducer这个类</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">        <span class="comment">//使用循环发送消息</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i&lt;<span class="number">100</span>;i++)&#123;</span><br><span class="line">            <span class="comment">//分区策略第一种，如果既没有指定分区号，也没有指定数据key，那么就会使用轮询的方式将数据均匀的发送到不同的分区里面去</span></span><br><span class="line">            <span class="comment">//ProducerRecord&lt;String, String&gt; producerRecord1 = new ProducerRecord&lt;&gt;(&quot;mypartition&quot;, &quot;mymessage&quot; + i);</span></span><br><span class="line">            <span class="comment">//kafkaProducer.send(producerRecord1);</span></span><br><span class="line">            <span class="comment">//第二种分区策略 如果没有指定分区号，指定了数据key，通过key.hashCode  % numPartitions来计算数据究竟会保存在哪一个分区里面</span></span><br><span class="line">            <span class="comment">//注意：如果数据key，没有变化   key.hashCode % numPartitions  =  固定值  所有的数据都会写入到同一个分区里面去</span></span><br><span class="line">            <span class="comment">//ProducerRecord&lt;String, String&gt; producerRecord2 = new ProducerRecord&lt;&gt;(&quot;mypartition&quot;, &quot;mykey&quot;, &quot;mymessage&quot; + i);</span></span><br><span class="line">            <span class="comment">//kafkaProducer.send(producerRecord2);</span></span><br><span class="line">            <span class="comment">//第三种分区策略：如果指定了分区号，那么就会将数据直接写入到对应的分区里面去</span></span><br><span class="line">          <span class="comment">//  ProducerRecord&lt;String, String&gt; producerRecord3 = new ProducerRecord&lt;&gt;(&quot;mypartition&quot;, 0, &quot;mykey&quot;, &quot;mymessage&quot; + i);</span></span><br><span class="line">           <span class="comment">// kafkaProducer.send(producerRecord3);</span></span><br><span class="line">            <span class="comment">//第四种分区策略：自定义分区策略。如果不自定义分区规则，那么会将数据使用轮询的方式均匀的发送到各个分区里面去</span></span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">&quot;mypartition&quot;</span>,<span class="string">&quot;mymessage&quot;</span>+i));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//关闭生产者</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>自定义分区策略:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//对应第四种分区</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyPartitioner</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    这个方法就是确定数据到哪一个分区里面去</span></span><br><span class="line"><span class="comment">    直接return  2 表示将数据写入到2号分区里面去</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>总体四种:</p>
<p>a、可根据主题和内容发送</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line"><span class="comment">//可根据主题和内容发送</span></span><br><span class="line"></span><br><span class="line">producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">&quot;my-topic&quot;</span>,<span class="string">&quot;具体的数据&quot;</span>));</span><br></pre></td></tr></table></figure>

<p>b、根据主题，key、内容发送</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Producer&lt;String, String&gt; producer &#x3D; new KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;可根据主题、key、内容发送</span><br><span class="line"></span><br><span class="line">producer.send(new  ProducerRecord&lt;String,  String&gt;(&quot;my-topic&quot;,&quot;key&quot;,&quot;具体的数据&quot;));</span><br></pre></td></tr></table></figure>

<p>c、根据主题、分区、key、内容发送</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Producer&lt;String, String&gt; producer &#x3D; new KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;可根据主题、分区、key、内容发送</span><br><span class="line"></span><br><span class="line">producer.send(new  ProducerRecord&lt;String,  String&gt;(&quot;my-topic&quot;,1,&quot;key&quot;,&quot;具体的数据&quot;));</span><br></pre></td></tr></table></figure>

<p>d、根据主题、分区、时间戳、key，内容发送</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Producer&lt;String, String&gt; producer &#x3D; new KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;可根据主题、分区、时间戳、key、内容发送</span><br><span class="line">producer.send(new  ProducerRecord&lt;String,  String&gt;(&quot;my-topic&quot;,1,12L,&quot;key&quot;,&quot;具体的数据&quot;));</span><br></pre></td></tr></table></figure>

<p>总结：1如果指定了数据的分区号，那么数据直接生产到对应的分区里面去</p>
<p>2如果没有指定分区好，出现了数据key，通过key取hashCode来计算数据究竟该落在哪一个分区里面</p>
<p>3如果既没有指定分区号，也没有指定数据的key，使用round-robin轮询 的这种机制来是实现</p>
<h3 id="二-消费者"><a href="#二-消费者" class="headerlink" title="二   消费者"></a>二   消费者</h3><p>消费者是一个从kafka Cluster中消费数据的一个客户端；该客户端可以处理kafka brokers中的故障问题，并且可以适应在集群内的迁移的topic分区；该客户端还允许消费者组使用消费者组来进行负载均衡。</p>
<p>消费者维持一个TCP的长连接来获取数据，使用后未能正常关闭这些消费者问题会出现，因此<strong>消费者不是线程安全 的。</strong></p>
<p><strong>必要条件</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#1、地址</span><br><span class="line">bootstrap.servers&#x3D;node01:9092</span><br><span class="line">#2、序列化 key.serializer&#x3D;org.apache.kafka.common.serialization.StringSerializer value.serializer&#x3D;org.apache.kafka.common.serialization.StringSerializer</span><br><span class="line">#3、主题（topic） 需要制定具体的某个topic（order）即可。</span><br><span class="line">#4、消费者组 group.id&#x3D;test</span><br></pre></td></tr></table></figure>

<p>一 自动提交offset的值(参考上面)</p>
<p>二 手动提交offset的值(参考上面)</p>
<p>三处理完每一个分区里面的数据，就马上提交这个分区里面的数据</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConmsumerPartition</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 处理完每一个分区里面的数据，就马上提交这个分区里面的数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;node01:9092&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;test_group&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;false&quot;</span>); <span class="comment">//禁用自动提交offset，后期我们手动提交offset</span></span><br><span class="line">        props.put(<span class="string">&quot;auto.commit.interval.ms&quot;</span>, <span class="string">&quot;1000&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;session.timeout.ms&quot;</span>, <span class="string">&quot;30000&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">        kafkaConsumer.subscribe(Arrays.asList(<span class="string">&quot;mypartition&quot;</span>));</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>)&#123;</span><br><span class="line">            <span class="comment">//通过while ture进行消费数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(<span class="number">1000</span>);</span><br><span class="line">            <span class="comment">//获取mypartition这个topic里面所有的分区</span></span><br><span class="line">            Set&lt;TopicPartition&gt; partitions = records.partitions();</span><br><span class="line">            <span class="comment">//循环遍历每一个分区里面的数据，然后将每一个分区里面的数据进行处理，处理完了之后再提交每一个分区里面的offset</span></span><br><span class="line">            <span class="keyword">for</span> (TopicPartition partition : partitions) &#123;</span><br><span class="line">                <span class="comment">//获取每一个分区里面的数据</span></span><br><span class="line">                List&lt;ConsumerRecord&lt;String, String&gt;&gt; records1 = records.records(partition);</span><br><span class="line">                <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records1) &#123;</span><br><span class="line">                    System.out.println(record.value()+<span class="string">&quot;====&quot;</span>+ record.offset());</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//获取我们分区里面最后一条数据的offset，表示我们已经消费到了这个offset了</span></span><br><span class="line">                <span class="keyword">long</span> offset = records1.get(records1.size() - <span class="number">1</span>).offset();</span><br><span class="line">                <span class="comment">//提交offset</span></span><br><span class="line">                <span class="comment">//提交我们的offset，并且给offset加1  表示我们下次从没有消费的那一条数据开始消费</span></span><br><span class="line">                kafkaConsumer.commitSync(Collections.singletonMap(partition,<span class="keyword">new</span> OffsetAndMetadata(offset + <span class="number">1</span>)));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>四 实现消费一个topic里面某些分区里面的数据</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerSomePartition</span> </span>&#123;</span><br><span class="line">    <span class="comment">//实现消费一个topic里面某些分区里面的数据</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;node01:9092,node02:9092,node03:9092&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;test_group&quot;</span>);  <span class="comment">//消费组</span></span><br><span class="line">        props.put(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;true&quot;</span>);<span class="comment">//允许自动提交offset</span></span><br><span class="line">        props.put(<span class="string">&quot;auto.commit.interval.ms&quot;</span>, <span class="string">&quot;1000&quot;</span>);<span class="comment">//每隔多久自动提交offset</span></span><br><span class="line">        props.put(<span class="string">&quot;session.timeout.ms&quot;</span>, <span class="string">&quot;30000&quot;</span>);</span><br><span class="line">        <span class="comment">//指定key，value的反序列化类</span></span><br><span class="line">        props.put(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取kafkaConsumer</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//通过consumer订阅某一个topic，进行消费.会消费topic里面所有分区的数据</span></span><br><span class="line">       <span class="comment">// consumer.subscribe();</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//通过调用assign方法实现消费mypartition这个topic里面的0号和1号分区里面的数据</span></span><br><span class="line"></span><br><span class="line">        TopicPartition topicPartition0 = <span class="keyword">new</span> TopicPartition(<span class="string">&quot;mypartition&quot;</span>, <span class="number">0</span>);</span><br><span class="line">        TopicPartition topicPartition1 = <span class="keyword">new</span> TopicPartition(<span class="string">&quot;mypartition&quot;</span>, <span class="number">1</span>);</span><br><span class="line">        <span class="comment">//订阅我们某个topic里面指定分区的数据进行消费</span></span><br><span class="line">        consumer.assign(Arrays.asList(topicPartition0,topicPartition1));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> i =<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">1000</span>);</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                i++;</span><br><span class="line">                System.out.println(<span class="string">&quot;数据值为&quot;</span>+ record.value()+<span class="string">&quot;数据的offset为&quot;</span>+ record.offset());</span><br><span class="line">                System.out.println(<span class="string">&quot;消费第&quot;</span>+i+<span class="string">&quot;条数据&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>五 消费者数据丢失-数据重复</p>
<p>说明：</p>
<p>1、已经消费的数据对于kafka来说，会将消费组里面的oﬀset值进行修改，那什么时候进行修改了？是在数据消费 完成之后，比如在控制台打印完后自动提交；</p>
<p>2、提交过程：是通过kafka将oﬀset进行移动到下个message所处的oﬀset的位置。</p>
<p>3、拿到数据后，存储到hbase中或者mysql中，如果hbase或者mysql在这个时候连接不上，就会抛出异常，如果在处理数据的时候已经进行了提交，那么kafka伤的oﬀset值已经进行了修改了，但是hbase或者mysql中没有数据，这个时候就会出现<strong>数据丢失</strong>。</p>
<p>4、什么时候提交oﬀset值？在Consumer将数据处理完成之后，再来进行oﬀset的修改提交。默认情况下oﬀset是 自动提交，需要修改为手动提交oﬀset值。</p>
<p>5、如果在处理代码中正常处理了，但是在提交oﬀset请求的时候，没有连接到kafka或者出现了故障，那么该次修 改oﬀset的请求是失败的，那么下次在进行读取同一个分区中的数据时，会从已经处理掉的oﬀset值再进行处理一 次，那么在hbase中或者mysql中就会产生两条一样的数据，也就是<strong>数据重复</strong></p>
<p><strong>kafka当中数据消费模型:</strong></p>
<p>eactly  once：消费且仅仅消费一次，可以在事务里面执行kafka的操作</p>
<p>at  most  once：至多消费一次，数据丢失的问题</p>
<p>at  least  once ：至少消费一次，数据重复消费的问题</p>
<p><strong>kafka的消费模式：决定了offset值保存在哪里:</strong></p>
<p>kafka的highLevel API进行消费：将offset保存在zk当中，每次更新offset的时候，都需要连接zk</p>
<p>以及kafka的lowLevelAP进行消费：保存了消费的状态，其实就是保存了offset，将offset保存在kafka的一个默认的topic里面。kafka会自动的创建一个topic，保存所有其他topic里面的offset在哪里</p>
<p>kafka将数据全部都以文件的方式保存到了文件里面去了。</p>
<p>###三   kafka的log-存储机制</p>
<p>kafka里面一个topic有多个partition组成，每一个partition里面有多个segment组成，每个segment都由两部分组成，分别是.log文件和.index文件  。一旦.log文件达到1GB的时候，就会生成一个新的segment</p>
<p>.log文件：顺序的保存了我们的写入的数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">00000000000000000000.log</span><br></pre></td></tr></table></figure>



<p>.index文件：索引文件，使用索引文件，加快kafka数据的查找速度   </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">00000000000000000000.index</span><br></pre></td></tr></table></figure>

<p><strong>kafka日志的组成:</strong></p>
<p>1 segment  ﬁle组成：由两个部分组成，分别为index ﬁle和data ﬁle，此两个文件一一对应且成对出现； 后缀.index和.log分别表示为segment的索引文件、数据文件。</p>
<p>2 segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个全局 partion的最大oﬀset（偏移message数）。数值最大为64位long大小，19位数字字符长度，没有数字就用0 填充</p>
<p>3 通过索引信息可以快速定位到message。通过index元数据全部映射到memory，可以避免segment ﬁle的IO磁盘操作；</p>
<p>4 通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。 稀疏索引：为了数据创建索引，但范围并不是为每一条创建，而是为某一个区间创建；</p>
<p><strong>好处</strong>：就是可以减少索引值的数量。</p>
<p><strong>不好的地方</strong>：找到索引区间之后，要得进行第二次处理。</p>
<p><strong>kafka日志清理</strong></p>
<p>kafka中清理日志的方式有两种：delete和compact。</p>
<p>删除的阈值有两种：过期的时间和分区内总日志大小。</p>
<p>在kafka中，因为数据是存储在本地磁盘中，并没有像hdfs的那样的分布式存储，就会产生磁盘空间不足的情 况，可以采用删除或者合并的方式来进行处理</p>
<p>可以通过时间来删除、合并：默认7天 还可以通过字节大小、合并</p>
<p><strong>总结：查找数据的过程</strong></p>
<p>第一步：通过offset确定数据保存在哪一个segment里面了，</p>
<p>第二部：查找对应的segment里面的index文件  。index文件都是key/value对的。key表示数据在log文件里面的顺序是第几条。value记录了这一条数据在全局的标号。如果能够直接找到对应的offset直接去获取对应的数据即可</p>
<p>如果index文件里面没有存储offset，就会查找offset最近的那一个offset，例如查找offset为7的数据找不到，那么就会去查找offset为6对应的数据，找到之后，再取下一条数据就是offset为7的数据</p>
<h3 id="四-kafka的消息不丢失机制"><a href="#四-kafka的消息不丢失机制" class="headerlink" title="四 kafka的消息不丢失机制"></a>四 kafka的消息不丢失机制</h3><p>生产者：使用ack机制     有多少个分区，就启动多少个线程来进行同步数据</p>
<pre><code> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1发送数据的方式:</span><br><span class="line"></span><br><span class="line">     可以采用同步或者异步的方式</span><br><span class="line">      同步：发送一批数据给kafka后，等待kafka返回结果</span><br><span class="line">         1、生产者等待10s，如果broker没有给出ack相应，就认为失败。</span><br><span class="line">         2、生产者重试3次，如果还没有相应，就报错</span><br><span class="line">      异步: 发送一批数据给kafka，只是提供一个回调函数</span><br><span class="line">         1、先将数据保存在生产者端的buffer中。buffer大小是2万条 </span><br><span class="line">         2、满足数据阈值或者数量阈值其中的一个条件就可以发送数据。</span><br><span class="line">         3、发送一批数据的大小是500条</span><br><span class="line">         说明：如果broker迟迟不给ack，而buﬀer又满了，开发者可以设置是否直接清空buﬀer中的数据。</span><br></pre></td></tr></table></figure></code></pre>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ask机制   确认机制</span><br><span class="line">服务端返回一个确认码，即ack响应码；ack的响应有三个状态值</span><br><span class="line">   0：生产者只负责发送数据，不关心数据是否丢失，响应的状态码为0（丢失的数据，需要再次发送      ）</span><br><span class="line">   1：partition的leader收到数据，响应的状态码为1</span><br><span class="line">   -1：所有的从节点都收到数据，响应的状态码为-1</span><br><span class="line">   说明：如果broker端一直不给ack状态，producer永远不知道是否成功；producer可以设置一个超时时间10s，超 过时间认为失败。</span><br></pre></td></tr></table></figure>

<p>broker：使用partition的副本机制     </p>
<p>消费者：使用offset来进行记录     在消费者消费数据的时候，只要每个消费者记录好oﬀset值即可，就能保证数据不丢失。</p>
<h3 id="五-CAP-理论-与kafka中的CAP"><a href="#五-CAP-理论-与kafka中的CAP" class="headerlink" title="五 CAP 理论  与kafka中的CAP"></a>五 CAP 理论  与kafka中的CAP</h3><p>分布式系统（distributed system）正变得越来越重要，大型网站几乎都是分布式的。</p>
<p>分布式系统的最大难点，就是各个节点的状态如何同步。</p>
<p>为了解决各个节点之间的状态同步问题，在1998年，由加州大学的计算机科学家 Eric Brewer 提出分布式系统的三个指标，分别是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> Consistency：一致性</span><br><span class="line">Availability：可用性</span><br><span class="line">Partition tolerance：分区容错性</span><br><span class="line"></span><br><span class="line">这三个指标不可能同时做到。这个结论就叫做 CAP 定理</span><br></pre></td></tr></table></figure>

<p>1  Partition tolerance</p>
<p>大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区（partition）。分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信</p>
<p>  一般来说，分区容错无法避免，因此可以认为 CAP 的 P 总是存在的。即永远可能存在分区容错这个问题  </p>
<p>2  Consistency</p>
<p>Consistency 中文叫做”一致性”。意思是，写操作之后的读操作，必须返回该值。</p>
<p>   如  v0这个数据存在  s1和s2中  用户向s1中 把v0这个值改为v1  则s2中的值也应该改为 v1  </p>
<p>3  Availability</p>
<p>Availability 中文叫做”可用性”，意思是只要收到用户的请求，服务器就必须给出回应。</p>
<p>用户可以选择向服务器 G1 或 G2 发起读操作。不管是哪台服务器，只要收到请求，就必须告诉用户，到底是 v0 还是 v1，否则就不满足可用性。</p>
<p> <strong>kafka中的CAP 应用</strong></p>
<p>  kafka为一个分布式消息队列系统,一定满足CAP 定理</p>
<p>​    kafka满足的是CAP定律当中的CA，其中Partition  tolerance通过的是一定的机制尽量的保证分区容错性。</p>
<p>其中C表示的是数据一致性。A表示数据可用性。</p>
<p>kafka首先将数据写入到不同的分区里面去，每个分区又可能有好多个副本，数据首先写入到leader分区里面去，读写的操作都是与leader分区进行通信，保证了数据的一致性原则，也就是满足了Consistency原则。然后kafka通过分区副本机制，来保证了kafka当中数据的可用性。但是也存在另外一个问题，就是副本分区当中的数据与leader当中的数据存在差别的问题如何解决，这个就是Partition tolerance的问题。</p>
<p><strong>kafka为了解决Partition tolerance的问题，使用了ISR的同步策略，来尽最大可能减少Partition tolerance的问题</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">每个leader会维护一个ISR（a set of in-sync replicas，基本同步）列表</span><br><span class="line">ISR列表主要的作用就是决定哪些副本分区是可用的，也就是说可以将leader分区里面的数据同步到副本分区里面去，决定一个副本分区是否可用的条件有两个</span><br><span class="line">•	replica.lag.time.max.ms&#x3D;10000     副本分区与主分区心跳时间延迟</span><br><span class="line">•	replica.lag.max.messages&#x3D;4000    副本分区与主分区消息同步最大差</span><br></pre></td></tr></table></figure>

<p> 总结  主分区与副本分区之间的数据同步：</p>
<p>两个指标，一个是副本分区与主分区之间的心跳间隔，超过10S就认为副本分区已经宕机，会将副本分区从ISR当中移除</p>
<p>主分区与副本分区之间的数据同步延迟，默认数据差值是4000条</p>
<p>例如主分区有10000条数据，副本分区同步了3000条，差值是7000 &gt;  4000条，也会将这个副本分区从ISR列表里面移除掉</p>
<p><strong>kafka in zookeeper</strong></p>
<p>kafka集群中：包含了很多的broker，但是在这么的broker中也会有一个老大存在；是在kafka节点中的一个临时节 点，去创建相应的数据，这个老大就是 <strong>Controller</strong> <strong>Broker</strong>。</p>
<p><strong>Controller Broker职责</strong>：管理所有的</p>
<h2 id="kafka-监控及运维"><a href="#kafka-监控及运维" class="headerlink" title="kafka 监控及运维"></a>kafka 监控及运维</h2><p>在开发工作中，消费在Kafka集群中消息，数据变化是我们关注的问题，当业务前提不复杂时，我们可以使用Kafka 命令提供带有Zookeeper客户端工具的工具，可以轻松完成我们的工作。随着业务的复杂性，增加Group和 Topic，那么我们使用Kafka提供命令工具，已经感到无能为力，那么Kafka监控系统目前尤为重要，我们需要观察 消费者应用的细节。</p>
<h2 id="1、kafka-eagle概述"><a href="#1、kafka-eagle概述" class="headerlink" title="1、kafka-eagle概述"></a>1、kafka-eagle概述</h2><p> 为了简化开发者和服务工程师维护Kafka集群的工作有一个监控管理工具，叫做 Kafka-eagle。这个管理工具可以很容易地发现分布在集群中的哪些topic分布不均匀，或者是分区在整个集群分布不均匀的的情况。它支持管理多个集群、选择副本、副本重新分配以及创建Topic。同时，这个管理工具也是一个非常好的可以快速浏览这个集群的工具， </p>
<h2 id="2、环境和安装"><a href="#2、环境和安装" class="headerlink" title="2、环境和安装"></a>2、环境和安装</h2><h3 id="1、环境要求"><a href="#1、环境要求" class="headerlink" title="1、环境要求"></a>1、环境要求</h3><p>需要安装jdk，启动zk以及kafka的服务</p>
<h3 id="2、安装步骤"><a href="#2、安装步骤" class="headerlink" title="2、安装步骤"></a>2、安装步骤</h3><h4 id="1、下载源码包"><a href="#1、下载源码包" class="headerlink" title="1、下载源码包"></a>1、下载源码包</h4><p>kafka-eagle官网：</p>
<p><a target="_blank" rel="noopener" href="http://download.kafka-eagle.org/">http://download.kafka-eagle.org/</a> </p>
<p>我们可以从官网上面直接下载最细的安装包即可kafka-eagle-bin-1.3.2.tar.gz这个版本即可</p>
<p>代码托管地址：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/smartloli/kafka-eagle/releases">https://github.com/smartloli/kafka-eagle/releases</a></p>
<h4 id="2、解压"><a href="#2、解压" class="headerlink" title="2、解压"></a>2、解压</h4><p>这里我们选择将kafak-eagle安装在第三台</p>
<p>直接将kafka-eagle安装包上传到node03服务器的/export/softwares路径下，然后进行解压</p>
<p>node03服务器执行一下命令进行解压</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;export&#x2F;softwares&#x2F;</span><br><span class="line">tar -zxf kafka-eagle-bin-1.3.2.tar.gz -C &#x2F;export&#x2F;servers&#x2F;</span><br><span class="line">cd &#x2F;export&#x2F;servers&#x2F;kafka-eagle-bin-1.3.2</span><br><span class="line">tar -zxf kafka-eagle-web-1.3.2-bin.tar.gz</span><br></pre></td></tr></table></figure>

<h4 id="3、准备数据库"><a href="#3、准备数据库" class="headerlink" title="3、准备数据库"></a>3、准备数据库</h4><p>kafka-eagle需要使用一个数据库来保存一些元数据信息，我们这里直接使用msyql数据库来保存即可，在node03服务器执行以下命令创建一个mysql数据库即可</p>
<p>进入mysql客户端</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> eagle;</span><br><span class="line"></span><br><span class="line">在这个库中创建表:</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> Navicat MySQL Data Transfer</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> Source Server         : local</span></span><br><span class="line"><span class="comment"> Source Server Version : 50616</span></span><br><span class="line"><span class="comment"> Source Host           : localhost</span></span><br><span class="line"><span class="comment"> Source Database       : ke</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> Target Server Version : 50616</span></span><br><span class="line"><span class="comment"> File Encoding         : utf-8</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> Date: 06/23/2017 17:02:12 PM</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">use</span> eagle;</span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">NAMES</span> utf8;</span><br><span class="line"><span class="keyword">SET</span> FOREIGN_KEY_CHECKS = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="comment">--  Table structure for `ke_p_role`</span></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> <span class="string">`ke_p_role`</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`ke_p_role`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">tinyint</span>(<span class="number">4</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="string">`name`</span> <span class="built_in">varchar</span>(<span class="number">64</span>) <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">&#x27;role name&#x27;</span>,</span><br><span class="line">  <span class="string">`seq`</span> <span class="built_in">tinyint</span>(<span class="number">4</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">&#x27;rank&#x27;</span>,</span><br><span class="line">  <span class="string">`description`</span> <span class="built_in">varchar</span>(<span class="number">128</span>) <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">&#x27;role describe&#x27;</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> AUTO_INCREMENT=<span class="number">4</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="comment">--  Records of `ke_p_role`</span></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="keyword">BEGIN</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`ke_p_role`</span> <span class="keyword">VALUES</span> (<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;Administrator&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;Have all permissions&#x27;</span>), (<span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;Devs&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;Own add or delete&#x27;</span>), (<span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;Tourist&#x27;</span>, <span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;Only viewer&#x27;</span>);</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="comment">--  Table structure for `ke_resources`</span></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> <span class="string">`ke_resources`</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`ke_resources`</span> (</span><br><span class="line">  <span class="string">`resource_id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="string">`name`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">&#x27;resource name&#x27;</span>,</span><br><span class="line">  <span class="string">`url`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`parent_id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`resource_id`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> AUTO_INCREMENT=<span class="number">17</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="comment">--  Records of `ke_resources`</span></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="keyword">BEGIN</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`ke_resources`</span> <span class="keyword">VALUES</span> (<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;System&#x27;</span>, <span class="string">&#x27;/system&#x27;</span>, <span class="string">&#x27;-1&#x27;</span>), (<span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;User&#x27;</span>, <span class="string">&#x27;/system/user&#x27;</span>, <span class="string">&#x27;1&#x27;</span>), (<span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;Role&#x27;</span>, <span class="string">&#x27;/system/role&#x27;</span>, <span class="string">&#x27;1&#x27;</span>), (<span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;Resource&#x27;</span>, <span class="string">&#x27;/system/resource&#x27;</span>, <span class="string">&#x27;1&#x27;</span>), (<span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;Notice&#x27;</span>, <span class="string">&#x27;/system/notice&#x27;</span>, <span class="string">&#x27;1&#x27;</span>), (<span class="string">&#x27;6&#x27;</span>, <span class="string">&#x27;Topic&#x27;</span>, <span class="string">&#x27;/topic&#x27;</span>, <span class="string">&#x27;-1&#x27;</span>), (<span class="string">&#x27;7&#x27;</span>, <span class="string">&#x27;Message&#x27;</span>, <span class="string">&#x27;/topic/message&#x27;</span>, <span class="string">&#x27;6&#x27;</span>), (<span class="string">&#x27;8&#x27;</span>, <span class="string">&#x27;Create&#x27;</span>, <span class="string">&#x27;/topic/create&#x27;</span>, <span class="string">&#x27;6&#x27;</span>), (<span class="string">&#x27;9&#x27;</span>, <span class="string">&#x27;Alarm&#x27;</span>, <span class="string">&#x27;/alarm&#x27;</span>, <span class="string">&#x27;-1&#x27;</span>), (<span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;Add&#x27;</span>, <span class="string">&#x27;/alarm/add&#x27;</span>, <span class="string">&#x27;9&#x27;</span>), (<span class="string">&#x27;11&#x27;</span>, <span class="string">&#x27;Modify&#x27;</span>, <span class="string">&#x27;/alarm/modify&#x27;</span>, <span class="string">&#x27;9&#x27;</span>), (<span class="string">&#x27;12&#x27;</span>, <span class="string">&#x27;Cluster&#x27;</span>, <span class="string">&#x27;/cluster&#x27;</span>, <span class="string">&#x27;-1&#x27;</span>), (<span class="string">&#x27;13&#x27;</span>, <span class="string">&#x27;ZkCli&#x27;</span>, <span class="string">&#x27;/cluster/zkcli&#x27;</span>, <span class="string">&#x27;12&#x27;</span>), (<span class="string">&#x27;14&#x27;</span>, <span class="string">&#x27;UserDelete&#x27;</span>, <span class="string">&#x27;/system/user/delete&#x27;</span>, <span class="string">&#x27;1&#x27;</span>), (<span class="string">&#x27;15&#x27;</span>, <span class="string">&#x27;UserModify&#x27;</span>, <span class="string">&#x27;/system/user/modify&#x27;</span>, <span class="string">&#x27;1&#x27;</span>), (<span class="string">&#x27;16&#x27;</span>, <span class="string">&#x27;Mock&#x27;</span>, <span class="string">&#x27;/topic/mock&#x27;</span>, <span class="string">&#x27;6&#x27;</span>);</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="comment">--  Table structure for `ke_role_resource`</span></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> <span class="string">`ke_role_resource`</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`ke_role_resource`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="string">`role_id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`resource_id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> AUTO_INCREMENT=<span class="number">19</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="comment">--  Records of `ke_role_resource`</span></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="keyword">BEGIN</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`ke_role_resource`</span> <span class="keyword">VALUES</span> (<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;1&#x27;</span>), (<span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>), (<span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;3&#x27;</span>), (<span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;4&#x27;</span>), (<span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;5&#x27;</span>), (<span class="string">&#x27;6&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;7&#x27;</span>), (<span class="string">&#x27;7&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;8&#x27;</span>), (<span class="string">&#x27;8&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;10&#x27;</span>), (<span class="string">&#x27;9&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;11&#x27;</span>), (<span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;13&#x27;</span>), (<span class="string">&#x27;11&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;7&#x27;</span>), (<span class="string">&#x27;12&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;8&#x27;</span>), (<span class="string">&#x27;13&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;13&#x27;</span>), (<span class="string">&#x27;14&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;10&#x27;</span>), (<span class="string">&#x27;15&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;11&#x27;</span>), (<span class="string">&#x27;16&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;14&#x27;</span>), (<span class="string">&#x27;17&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;15&#x27;</span>), (<span class="string">&#x27;18&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;16&#x27;</span>);</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="comment">--  Table structure for `ke_trend`</span></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> <span class="string">`ke_trend`</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`ke_trend`</span> (</span><br><span class="line">  <span class="string">`cluster`</span> <span class="built_in">varchar</span>(<span class="number">64</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`key`</span> <span class="built_in">varchar</span>(<span class="number">64</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`value`</span> <span class="built_in">varchar</span>(<span class="number">64</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`hour`</span> <span class="built_in">varchar</span>(<span class="number">2</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`tm`</span> <span class="built_in">varchar</span>(<span class="number">16</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span></span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="comment">--  Table structure for `ke_user_role`</span></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> <span class="string">`ke_user_role`</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`ke_user_role`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="string">`user_id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`role_id`</span> <span class="built_in">tinyint</span>(<span class="number">4</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> AUTO_INCREMENT=<span class="number">2</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="comment">--  Records of `ke_user_role`</span></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="keyword">BEGIN</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`ke_user_role`</span> <span class="keyword">VALUES</span> (<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;1&#x27;</span>);</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="comment">--  Table structure for `ke_users`</span></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> <span class="string">`ke_users`</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`ke_users`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="string">`rtxno`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`username`</span> <span class="built_in">varchar</span>(<span class="number">64</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`password`</span> <span class="built_in">varchar</span>(<span class="number">128</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`email`</span> <span class="built_in">varchar</span>(<span class="number">64</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`realname`</span> <span class="built_in">varchar</span>(<span class="number">128</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> AUTO_INCREMENT=<span class="number">2</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="comment">--  Records of `ke_users`</span></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="keyword">BEGIN</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`ke_users`</span> <span class="keyword">VALUES</span> (<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;1000&#x27;</span>, <span class="string">&#x27;admin&#x27;</span>, <span class="string">&#x27;123456&#x27;</span>, <span class="string">&#x27;admin@email.com&#x27;</span>, <span class="string">&#x27;Administrator&#x27;</span>);</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> FOREIGN_KEY_CHECKS = <span class="number">1</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4、修改kafak-eagle配置文件"><a href="#4、修改kafak-eagle配置文件" class="headerlink" title="4、修改kafak-eagle配置文件"></a>4、修改kafak-eagle配置文件</h4><p>node03执行以下命令修改kafak-eagle配置文件</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">cd</span> <span class="string">/export/servers/kafka-eagle-bin-1.3.2/kafka-eagle-web-1.3.2/conf</span></span><br><span class="line"><span class="attr">vim</span> <span class="string">system-config.properties</span></span><br><span class="line"></span><br><span class="line"><span class="meta">kafka.eagle.zk.cluster.alias</span>=<span class="string">cluster1,cluster2</span></span><br><span class="line"><span class="meta">cluster1.zk.list</span>=<span class="string">node01:2181,node02:2181,node03:2181</span></span><br><span class="line"><span class="meta">cluster2.zk.list</span>=<span class="string">node01:2181,node02:2181,node03:2181</span></span><br><span class="line"></span><br><span class="line"><span class="meta">kafka.eagle.driver</span>=<span class="string">com.mysql.jdbc.Driver</span></span><br><span class="line"><span class="meta">kafka.eagle.url</span>=<span class="string">jdbc:mysql://node03:3306/eagle</span></span><br><span class="line"><span class="meta">kafka.eagle.username</span>=<span class="string">root</span></span><br><span class="line"><span class="meta">kafka.eagle.password</span>=<span class="string">123456</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="5、配置环境变量"><a href="#5、配置环境变量" class="headerlink" title="5、配置环境变量"></a>5、配置环境变量</h4><p>kafka-eagle必须配置环境变量，node03服务器执行以下命令来进行配置环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;profile</span><br><span class="line"></span><br><span class="line">export KE_HOME&#x3D;&#x2F;export&#x2F;servers&#x2F;kafka-eagle-bin-1.3.2&#x2F;kafka-eagle-web-1.3.2</span><br><span class="line">export PATH&#x3D;:$KE_HOME&#x2F;bin:$PATH</span><br><span class="line"></span><br><span class="line">source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure>

<h4 id="6、启动kafka-eagle"><a href="#6、启动kafka-eagle" class="headerlink" title="6、启动kafka-eagle"></a>6、启动kafka-eagle</h4><p>node03执行以下界面启动kafka-eagle</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/servers/kafka-eagle-bin-1.3.2/kafka-eagle-web-1.3.2/bin</span><br><span class="line">chmod u+x ke.sh</span><br><span class="line">./ke.sh start  stop  status</span><br></pre></td></tr></table></figure>

<h4 id="7、主界面"><a href="#7、主界面" class="headerlink" title="7、主界面"></a>7、主界面</h4><p>访问kafka-eagle</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;node03:8048&#x2F;ke</span><br><span class="line">用户名：admin</span><br><span class="line">密码：123456</span><br></pre></td></tr></table></figure>
    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>HF
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://example.com/2017/07/16/Kafka/" title="Kafka">http://example.com/2017/07/16/Kafka/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Kafka/" rel="tag"># Kafka</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2017/07/15/ClouderaManager/" rel="prev" title="ClouderaManager">
      <i class="fa fa-chevron-left"></i> ClouderaManager
    </a></div>
      <div class="post-nav-item">
    <a href="/2017/07/17/Hbase/" rel="next" title="Hbase">
      Hbase <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Kafka%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="nav-number">1.</span> <span class="nav-text">Kafka消息队列</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%A6%82%E8%BF%B0"><span class="nav-number">1.1.</span> <span class="nav-text">一消息队列概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-kafka%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9Fkafka%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F"><span class="nav-number">1.1.1.</span> <span class="nav-text">1 kafka企业级消息系统kafka企业级消息系统</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1%E3%80%81%E7%82%B9%E5%AF%B9%E7%82%B9"><span class="nav-number">1.2.</span> <span class="nav-text">2.1、点对点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2%E3%80%81%E5%8F%91%E5%B8%83-%E8%AE%A2%E9%98%85"><span class="nav-number">1.3.</span> <span class="nav-text">2.2、发布-订阅</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1%E3%80%81%E5%BA%94%E7%94%A8%E8%A7%A3%E8%80%A6"><span class="nav-number">1.4.</span> <span class="nav-text">3.1、应用解耦</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6"><span class="nav-number">1.5.</span> <span class="nav-text">3.2、流量控制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3%E3%80%81%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86"><span class="nav-number">1.6.</span> <span class="nav-text">3.3、日志处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-4%E3%80%81%E6%B6%88%E6%81%AF%E9%80%9A%E8%AE%AF"><span class="nav-number">1.7.</span> <span class="nav-text">3.4、消息通讯</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%8C-kafka%E6%A6%82%E8%BF%B0"><span class="nav-number">2.</span> <span class="nav-text">二 kafka概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1%E3%80%81%E6%8C%87%E6%A0%87%E5%88%86%E6%9E%90"><span class="nav-number">2.1.</span> <span class="nav-text">5.1、指标分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2%E3%80%81%E6%97%A5%E5%BF%97%E8%81%9A%E5%90%88%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95"><span class="nav-number">2.2.</span> <span class="nav-text">5.2、日志聚合解决方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-3%E3%80%81%E6%B5%81%E5%BC%8F%E5%A4%84%E7%90%86"><span class="nav-number">2.3.</span> <span class="nav-text">5.3、流式处理</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%89%E6%9E%B6%E6%9E%84"><span class="nav-number">3.</span> <span class="nav-text">三架构</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85API"><span class="nav-number">3.0.0.0.1.</span> <span class="nav-text">生产者API</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85API"><span class="nav-number">3.0.0.0.2.</span> <span class="nav-text">消费者API</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#StreamsAPI"><span class="nav-number">3.0.0.0.3.</span> <span class="nav-text">StreamsAPI</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#ConnectorAPI"><span class="nav-number">3.0.0.0.4.</span> <span class="nav-text">ConnectorAPI</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9B-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA"><span class="nav-number">4.</span> <span class="nav-text">四 集群搭建</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-jdk-%E4%B8%8Ezookeeper%E5%BF%85%E9%A1%BB%E5%AE%89%E8%A3%85"><span class="nav-number">4.1.</span> <span class="nav-text">1 jdk 与zookeeper必须安装</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E5%AE%89%E8%A3%85%E7%94%A8%E6%88%B7"><span class="nav-number">4.2.</span> <span class="nav-text">2 安装用户</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3%E9%AA%8C%E8%AF%81%E7%8E%AF%E5%A2%83"><span class="nav-number">4.3.</span> <span class="nav-text">3验证环境</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%E5%8C%85"><span class="nav-number">4.4.</span> <span class="nav-text">4下载安装包</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5%E4%B8%8A%E4%BC%A0%E8%A7%A3%E5%8E%8B"><span class="nav-number">4.5.</span> <span class="nav-text">5上传解压</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">4.6.</span> <span class="nav-text">6修改配置文件</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%94-%E9%9B%86%E7%BE%A4%E6%93%8D%E4%BD%9C"><span class="nav-number">5.</span> <span class="nav-text">五 集群操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BAtopic"><span class="nav-number">5.0.1.</span> <span class="nav-text">创建topic</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8Btopic"><span class="nav-number">5.0.2.</span> <span class="nav-text">查看topic</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E6%95%B0%E6%8D%AE"><span class="nav-number">5.0.3.</span> <span class="nav-text">生产数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E6%95%B0%E6%8D%AE"><span class="nav-number">5.0.4.</span> <span class="nav-text">消费数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8Btopic%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BF%A1%E6%81%AF"><span class="nav-number">5.0.5.</span> <span class="nav-text">查看topic的一些信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9topic%E7%9A%84%E9%85%8D%E7%BD%AE%E5%B1%9E%E6%80%A7"><span class="nav-number">5.0.6.</span> <span class="nav-text">修改topic的配置属性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A0%E9%99%A4topic"><span class="nav-number">5.0.7.</span> <span class="nav-text">删除topic</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kafka%E9%9B%86%E7%BE%A4%E5%BD%93%E4%B8%ADJavaAPI%E6%93%8D%E4%BD%9C"><span class="nav-number">5.1.</span> <span class="nav-text">kafka集群当中JavaAPI操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka%E9%9B%86%E7%BE%A4%E5%BD%93%E4%B8%ADProducerAPI"><span class="nav-number">5.1.1.</span> <span class="nav-text">kafka集群当中ProducerAPI</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka%E9%9B%86%E7%BE%A4%E5%BD%93%E4%B8%AD%E7%9A%84consumerAPI"><span class="nav-number">5.1.2.</span> <span class="nav-text">kafka集群当中的consumerAPI</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka%E7%9A%84streamAPI"><span class="nav-number">5.1.3.</span> <span class="nav-text">kafka的streamAPI</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AAtopic"><span class="nav-number">5.1.3.1.</span> <span class="nav-text">第一步：创建一个topic</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E5%BC%80%E5%8F%91StreamAPI"><span class="nav-number">5.1.3.2.</span> <span class="nav-text">第二步：开发StreamAPI</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E7%94%9F%E4%BA%A7%E6%95%B0%E6%8D%AE"><span class="nav-number">5.1.3.3.</span> <span class="nav-text">第三步：生产数据</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%AD-kafka%E5%8E%9F%E7%90%86"><span class="nav-number">5.2.</span> <span class="nav-text">六 kafka原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80-%E7%94%9F%E4%BA%A7%E8%80%85"><span class="nav-number">5.2.1.</span> <span class="nav-text">一 生产者</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C-%E6%B6%88%E8%B4%B9%E8%80%85"><span class="nav-number">5.2.2.</span> <span class="nav-text">二   消费者</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B-kafka%E7%9A%84%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1%E6%9C%BA%E5%88%B6"><span class="nav-number">5.2.3.</span> <span class="nav-text">四 kafka的消息不丢失机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%94-CAP-%E7%90%86%E8%AE%BA-%E4%B8%8Ekafka%E4%B8%AD%E7%9A%84CAP"><span class="nav-number">5.2.4.</span> <span class="nav-text">五 CAP 理论  与kafka中的CAP</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kafka-%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%BF%90%E7%BB%B4"><span class="nav-number">5.3.</span> <span class="nav-text">kafka 监控及运维</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1%E3%80%81kafka-eagle%E6%A6%82%E8%BF%B0"><span class="nav-number">5.4.</span> <span class="nav-text">1、kafka-eagle概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2%E3%80%81%E7%8E%AF%E5%A2%83%E5%92%8C%E5%AE%89%E8%A3%85"><span class="nav-number">5.5.</span> <span class="nav-text">2、环境和安装</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1%E3%80%81%E7%8E%AF%E5%A2%83%E8%A6%81%E6%B1%82"><span class="nav-number">5.5.1.</span> <span class="nav-text">1、环境要求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2%E3%80%81%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4"><span class="nav-number">5.5.2.</span> <span class="nav-text">2、安装步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81%E4%B8%8B%E8%BD%BD%E6%BA%90%E7%A0%81%E5%8C%85"><span class="nav-number">5.5.2.1.</span> <span class="nav-text">1、下载源码包</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81%E8%A7%A3%E5%8E%8B"><span class="nav-number">5.5.2.2.</span> <span class="nav-text">2、解压</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E3%80%81%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">5.5.2.3.</span> <span class="nav-text">3、准备数据库</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4%E3%80%81%E4%BF%AE%E6%94%B9kafak-eagle%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">5.5.2.4.</span> <span class="nav-text">4、修改kafak-eagle配置文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5%E3%80%81%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="nav-number">5.5.2.5.</span> <span class="nav-text">5、配置环境变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6%E3%80%81%E5%90%AF%E5%8A%A8kafka-eagle"><span class="nav-number">5.5.2.6.</span> <span class="nav-text">6、启动kafka-eagle</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7%E3%80%81%E4%B8%BB%E7%95%8C%E9%9D%A2"><span class="nav-number">5.5.2.7.</span> <span class="nav-text">7、主界面</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="HF"
      src="/images/hexo.jpg">
  <p class="site-author-name" itemprop="name">HF</p>
  <div class="site-description" itemprop="description">第二名就是头号输家</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">78</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">38</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">39</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      推荐阅读
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.54tianzhisheng.cn/tags/Flink/" title="http:&#x2F;&#x2F;www.54tianzhisheng.cn&#x2F;tags&#x2F;Flink&#x2F;" rel="noopener" target="_blank">Flink</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://nginxconfig.io/" title="https:&#x2F;&#x2F;nginxconfig.io&#x2F;" rel="noopener" target="_blank">Nginxconfig</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://linux.51yip.com/" title="http:&#x2F;&#x2F;linux.51yip.com&#x2F;" rel="noopener" target="_blank">Linux命令手册</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://echarts.baidu.com/index.html" title="https:&#x2F;&#x2F;echarts.baidu.com&#x2F;index.html" rel="noopener" target="_blank">echarts可视化库</a>
        </li>
    </ul>
  </div>
<div style="">
  <canvas id="canvas" style="width:60%;">当前浏览器不支持canvas，请更换浏览器后再试</canvas>
</div>
<script>
(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*更新时钟*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //时间发生变化
            if(NewData[i] !== data[i]){
                //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //增加小球
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*渲染*/
    function render(){
        //重置画布宽度，达到清空画布的效果
        canvas.height = 100;
        //渲染时钟
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //渲染小球
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //更新时钟
        updateDigitTime();
        //更新小球状态
        updateBalls();
        //渲染
        render();
    },50);
}

})();
</script>
      </div>

    
          <script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
         <script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
           <div class="widget-wrap">
        <h3 class="widget-title">Tag Cloud</h3>
        <div id="myCanvasContainer" class="widget tagcloud">
            <canvas width="250" height="250" id="resCanvas" style="width=100%">
                <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ai/" rel="tag">Ai</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Azkaban/" rel="tag">Azkaban</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Blog/" rel="tag">Blog</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ClouderaManager/" rel="tag">ClouderaManager</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ElSearch/" rel="tag">ElSearch</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Flink/" rel="tag">Flink</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Flume/" rel="tag">Flume</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/" rel="tag">Git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hbase/" rel="tag">Hbase</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hdfs/" rel="tag">Hdfs</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/" rel="tag">Hexo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/" rel="tag">Hive</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hue/" rel="tag">Hue</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Impala/" rel="tag">Impala</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/" rel="tag">Java</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jvm/" rel="tag">Jvm</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kettle/" rel="tag">Kettle</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kudu/" rel="tag">Kudu</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Livy/" rel="tag">Livy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MapReduce/" rel="tag">MapReduce</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mysql/" rel="tag">Mysql</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Oozie/" rel="tag">Oozie</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis/" rel="tag">Redis</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scala/" rel="tag">Scala</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Shell/" rel="tag">Shell</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/" rel="tag">Spark</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sqoop/" rel="tag">Sqoop</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Web/" rel="tag">Web</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Yarn/" rel="tag">Yarn</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ZK/" rel="tag">ZK</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E5%8F%AF%E8%A7%86%E5%8C%96/" rel="tag">数据分析与可视化</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">数据库</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%88%86%E6%9E%90/" rel="tag">数据挖掘与分析</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" rel="tag">数据结构与算法</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习与深度学习</a><span class="tag-list-count">2</span></li></ul>
            </canvas>
        </div>
    </div>
    

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright" style=" text-align:center;">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">HF</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">1.2m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">18:44</span>
</div>

  <!-- 网站运行时间的设置 -->
<div class="run_time" style=" text-align:center;">
  <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
  <script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("07/23/2017 10:00:00");//此处修改你的建站时间或者网站上线时间 
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
    } 
    setInterval("createtime()",250);
  </script>
</div>
        
<div class="busuanzi-count" style=" text-align:center;">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      我的第 <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> 位朋友，
    </span>
  



  
    <span class="site-pv">
      历经 <span class="busuanzi-value" id="busuanzi_value_site_pv"></span> 次回眸才与你相遇
    </span>
  
</div>










      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_lines.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  
<div class="moon-menu">
  <div class="moon-menu-items">
    
    <div class="moon-menu-item" onclick="back2bottom()">
      <i class='fas fa-chevron-down'></i>    </div>
    
    <div class="moon-menu-item" onclick="back2top()">
      <i class='fas fa-chevron-up'></i>    </div>
    
  </div>
  <div class="moon-menu-button">
    <svg class="moon-menu-bg">
      <circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle>
      <circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle>
    </svg>
    <div class="moon-menu-content">
      <div class="moon-menu-icon"><i class='fas fa-ellipsis-v'></i></div>
      <div class="moon-menu-text"></div>
    </div>
  </div>
</div><script src="/js/injector.js"></script>
</body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/clicklove.js"></script>
<!-- 雪花特效 -->
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/jquery.min.js"></script>
<script type="text/javascript" src="/js/snow.js"></script>