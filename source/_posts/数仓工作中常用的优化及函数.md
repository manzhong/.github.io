---
title: 数仓工作中常用的优化及函数
tags:
  - Hive
categories: Hive
encrypt: 
enc_pwd: 
abbrlink: 55701
date: 2020-05-02 22:36:20
summary_img:
---

# 数仓中常用的优化及函数

# 一 常用函数

​	hive提供了很多函数,可以使用命令show functions罗列所有的函数,会发现这些函数名大部分与mysql相同,可以通过describe function functionName 查看函数的使用方法

```
1:greatest(T v1, T v2, ...) 返回最大值，会过滤null
2:least(T v1, T v2, ...) 返回最小值，会过滤null
3:select nvl(null,'dd')  如果第一个值 is null ，返回后一个值
4:repeat(string str, int n) 重复N次字符串
5:lpad(string str, int len, string pad) 将字符串str 用pad进行左补足 到len位(如果位数不足的话)
6:rpad(string str, int len, string pad) 将字符串str 用pad进行右补足 到len位(如果位数不足的话)
7:parse_url(url, partToExtract[, key])
解析URL字符串，partToExtract的选项包含[HOST,PATH,QUERY,REF,PROTOCOL,FILE,AUTHORITY,USERINFO]
8:DOUBLE   variance(col),var_pop(col)   返回组内某个数字列的方差
9:var_samp(col)  返回组内某个数字列的无偏样本方差
10:stddev_pop(col)  返回组内某个数字列的标准差
11:stddev_samp(col)   返回组内某个数字列的无偏样本标准差
12:covar_pop(col1, col2)  返回组内两个数字列的总体协方差
13:covar_samp(col1, col2)   返回组内两个数字列的样本协方差
14:corr(col1, col2)   返回组内两个数字列的皮尔逊相关系数
15:round() 四舍五入
16：FLOOR(54.56)  54
17：CEILING(13.15)  14
18：hive 实现类似 contain 包含查询:
select ‘QQqq‘ regexp(‘.*qq.*‘);
返回
true 
如 :
where reg regexp('\\[,\\[')
19：regexp_replace(string,'reg','提换为')   replace()
20:uuid() 
21: 浮点数比较问题
	假设 有张employees 表的taxes 字段是float 类型的，标识有两条数据的taxes 的值为0.2
	此时使用查询
	Select * from employees where taxes > 0.2;
	你会惊奇的发现 这两条数据在列！！
	为了避免这种情况发生应该使用下列语句
	Select * from employees where taxes > cast(0.2 as float);
22:  hive  的not in 不支持子查询
23: 常用的空值处理函数有 NVL (0.11 + ), COALESCE , NULLIF (2.3.0 +).
14: 年龄分组 concat('0',cast(age/5 as int)*5,'-',cast(age/5 as int)*5+4)
```

## 1 行转列,列转行

### 1.1 列转行

```sql
collect_list() --不去重
collect_set() --去重  
--两者都是无需序,col都是string
```

```sql
--多列转为一行并排序
sort_array(
	split(
    	concat_ws(',',collect_list(sleep_time),collect_list(awaking_time)),','
    )
)
```

                                                                                                                                                                                                                                                                                                                                                                   ### 1.2行转列

```sql
lateral view explode(array) a as name
lateral view explode(map) a as name,age
```

例子:

```sql
select user_id,order_value,order_id
from lie_col
lateral view explode(split(order_value,',')) num as order_id
limit 10;
```

## 2 分位函数

```sql
percentile(BIGINT col, p)  返回组内某个列精确的第p位百分数，p必须在0和1之间，
```

### 3 hive 的复杂类型

```sql
Structs： structs内部的数据可以通过DOT（.）来存取，例如，表中一列c的类型为STRUCT{a INT; b INT}，我们可以通过c.a来访问域a
	如:
	hive>create table student_test(id INT, info struct<name:STRING, age:INT>) 
		    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','                        
    		> COLLECTION ITEMS TERMINATED BY ':';   
	cat test5.txt   
			1,zhou:30  
			2,yan:30  
			3,chen:20  
			4,li:80  
	hive> LOAD DATA LOCAL INPATH '/home/work/data/test5.txt' INTO TABLE student_test;  
		Copying data from file:/home/work/data/test5.txt  
		Copying file: file:/home/work/data/test5.txt  
		Loading data to table default.student_test
	select info.age from student_test;  
		30  
		30  
		20  
		80 
```

```sql
Maps（K-V对）：访问指定域可以通过["指定域名称"]进行，例如，一个Map M包含了一个group-》gid的kv对，gid的值可以通过M['group']来获取
		如:map("1":"2","3":"4") as p p['1'] 的值为 '2'  可以cast转为int  
		字符串转map  str_to_map(str,dc1,dc2) dc1将str分成K-V对,dc2分割每个K-V对  dc1默认分隔符是','  dc2默认分隔符是'='
	

    > select str_to_map('aaa:11&bbb:22', '&', ':')
    > from tmp.tmp_jzl_20140725_test11;
	OK
	
	{"bbb":"22","aaa":"11"}
	
	案例2:
	
	hive> select str_to_map('aaa:11&bbb:22', '&', ':')['aaa']
	    > from tmp.tmp_jzl_20140725_test11;
	
	OK
	11

	假设有一张表，表名为t，其中字段params的数据类型是map，其map的具体k-v对如下：

		{'k0':'abc','k1':'01,02,03','k2':'456'}
		1. size(Map)函数：可得map的长度。返回值类型：int
		
		select size(map(t.params));
		>> 3
		2. map_keys(Map)函数：可得map中所有的key;  返回值类型: array
		
		select map_keys(map(t.params));
		>> ["k0","k1","k2"]
		3.map_values(Map)函数：可得map中所有的value; 返回值类型: array
		
		select map_value(map(t.params));
		>> ["abc","01,02,03","456"]
		4.判断map中是否包含某个key值：
		
		select array_contains(map_keys(t.params),'k0');
		>> true
		5. 在k-v对中，若value有多个值的情况，如 {'k1':'01,02,03'} ，如果要用 'k1' 中 '02'作为过滤条件，则语句如下：（这里用到split来处理）
		select * 
		from t 
		where split(t.params['k1'],',')[1]
		>> 02
	    6.如果过滤条件为：k2的值必须为'45'开头，则语句如下：
		  （这里用到substr方法来处理，这里注明一下，1和2分别表示起始位置和长度）
		select * 
		from t 
		where substr(t.params['k2'],1,2) = '45'
```

````
Arrays：array中的数据为相同类型，例如，假如array A中元素['a','b','c']，则A[1]的值为'b'
	排序:sort_array()  不能降序排列,如果要倒序排的话在子查询里新增一个辅助列来排序即可。
	数组转字符串:concat_ws(',',array)
	字符串转数组 : split(string,',')
	数组的包含查询:
	array_contains(array,'')
````

### 4 时间的转换

```sql
时间的转换:
		unix_timestamp() 是将当前系统时间转换成数字型秒数，from_unixtime 将数字型按照 格式进行时间转换。
			select from_unixtime(unix_timestamp(),'yyyy-MM-dd HH:mm:ss');
		to_date(string timestamp) 将时间戳转换成日期型字符串
			select to_date('2020-03-03 09:55:54');  2020-03-03
		datediff(string enddate, string startdate) 返回int 的两个日期差
			select datediff('2017-01-16', '2017-01-10');  6
		date_add(string startdate, int days) 日期加减
			select date_add('2017-01-10', 7); 2017-01-17  若为-3  2017-01-07
		date_sub(current_date,1) 日期减1
		current_timestamp 和 current_date 返回当前时间戳，当前日期
			2020-03-17 20:04:49.854   2020-03-17
		date_format(date/timestamp/string ts, string fmt) 按照格式返回字符串
			select date_format('2017-01-16 09:55:54', 'yyyy-MM-dd');
			select date_format('2017-01-16 09:55:54', 'yyyy');'MM'等
		last_day(string date) 返回 当前时间的月末日期
			select last_day('2017-01-16 09:55:54');
			select last_day('2017-01-16');
			2017-01-31
		YEAR(str),MONTH( string date ) ,DAY( string date ), DAYOFMONTH( date ) 月中的第几天,HOUR( string date ),MINUTE( string date ),SECOND( string date ) 
		,WEEKOFYEAR( string date ) 一年中的第几周

		--20171205转成2017-12-05 
		select from_unixtime(unix_timestamp('20171205','yyyymmdd'),'yyyy-mm-dd') from dual;
		--2017-12-05转成20171205
		select from_unixtime(unix_timestamp('2017-12-05','yyyy-mm-dd'),'yyyymmdd') from dual;
select pmod(datediff(date, '1920-01-01') - 3, 7)  0 周日 1 周一 2 周三.....
计算这一天的周一的日期:

select date_sub('2020-06-14',cast(date_format('2020-06-14','u') as int)-1)

计算这一天的上一周的周一的日期:
select date_sub('2020-01-01',cast(date_format('2020-01-01','u') as int)+6)


select DAYOFMONTH( date ) 月中的第几天 
hive 的窗口函数:
		算截止到当前的累计:
		sum(user_cou) over (partition by sex,age order by score  asc ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)
```

### 5 多维聚合

````
grouping sets：对分组集中指定的组表达式的每个子集执行group by；Eg:group by A,B grouping sets(A,B)就等价于 group by A union ALL group by B,其中A和B也可以是一个集合，比如group by A,B,C grouping sets((A,B),(A,C)) 等价于group by A,B union all group by A,C 。

rollup：在指定表达式的最左侧的维度为主 每个层次级别创建分组集。group by A,B,C with rollup首先会对(A、B、C)进行group by，然后对(A、B)进行group by，然后是(A)进行group by，最后对全表进行group by操作(GROUP BY NULL,NULL,NULL)(没有分组条件，所有的分组字段均为null的情况下)，最后将结果进行union ALL。

cube:为指定表达式集的每个可能组合创建分组集。首先会对(A、B、C)进行group by，然后依次是(A、B)，(A、C)，(A)，(B、C)，(B)，( C)，最后对全表进行group by操作（没有分组条件，所有的分组字段均为null的情况下)，最后将结果进行union。
````

### 6 like ,rlike

```
like 与rlike
		select
		* from wmods_dbmall_order_info_full a where   order_close_reason rlike '.*退款*.'
		 
		select
		* from wmods_dbmall_order_info_full a where   order_close_reason like '%退款%'

	like vs rlike vs regexp

		rlike == regexp，底层实现一样，使用正则 
		like 有一些优化，对于查询类型分为五种类型：
		
		NONE, // "abc"
		BEGIN, // "abc%"
		END, // "%abc"
		MIDDLE, // "%abc%"
		COMPLEX, // all other cases, such as "ab%c_de"
		NONE、BEGIN和END三种使用字符串查找，不使用正则，COMPLEX使用正则，MIDDLE分两种：（1）%abc% 使用字符串查找（2）%ab_c%使用正则。
```

### 7 json 数组的解析

```sql
select
--json_tuple(json, 'itemId')
json
,get_json_object(json,'$.itemId')
,nu
from
(select
1 as nu
,'[{"buyerPay":188800,"commissionRate":26,"itemId":201740006020,"refund":false},{"buyerPay":188800,"commissionRate":26,"itemId":201740006021,"refund":false}]' as jj
) a lateral view explode(split(regexp_replace
	(regexp_replace(jj,'\\[|\\]',''),'\\}\\,\\{','\\}\\;\\{'),'\\;')) a as  json


2 
select json_tuple(json, 'itemId') from 
(SELECT explode(split(regexp_replace(regexp_replace(distribution_items, '\\[|\\]',''),'\\}\\,\\{','\\}\\;\\{'),'\\;')) as json
from wmods_dbfamily_distribution_order_t2_full a
) test;
```

### 8 分析函数

```sql
1：LAG(col,n,DEFAULT) 用于统计窗口内往上第n行值
第一个参数为列名，第二个参数为往上第n行（可选，默认为1），第三个参数为默认值（当往上第n行为NULL时候，取默认值，如不指定，则为NULL）
SELECT cookieid,
createtime,
url,
ROW_NUMBER() OVER(PARTITION BY cookieid ORDER BY createtime) AS rn,
LAG(createtime,1,'1970-01-01 00:00:00') OVER(PARTITION BY cookieid ORDER BY createtime) AS last_1_time,
LAG(createtime,2) OVER(PARTITION BY cookieid ORDER BY createtime) AS last_2_time 
FROM lxw1234;
2：LEAD(col,n,DEFAULT) 用于统计窗口内往下第n行值
第一个参数为列名，第二个参数为往下第n行（可选，默认为1），第三个参数为默认值（当往下第n行为NULL时候，取默认值，如不指定，则为NULL）

SELECT cookieid,
createtime,
url,
ROW_NUMBER() OVER(PARTITION BY cookieid ORDER BY createtime) AS rn,
LEAD(createtime,1,'1970-01-01 00:00:00') OVER(PARTITION BY cookieid ORDER BY createtime) AS next_1_time,
LEAD(createtime,2) OVER(PARTITION BY cookieid ORDER BY createtime) AS next_2_time 
FROM lxw1234;

3：FIRST_VALUE  取分组内排序后，截止到当前行，第一个值
SELECT cookieid,
createtime,
url,
ROW_NUMBER() OVER(PARTITION BY cookieid ORDER BY createtime) AS rn,
FIRST_VALUE(url) OVER(PARTITION BY cookieid ORDER BY createtime) AS first1 
FROM lxw1234;

4：LAST_VALUE 取分组内排序后，截止到当前行，最后一个值
SELECT cookieid,
createtime,
url,
ROW_NUMBER() OVER(PARTITION BY cookieid ORDER BY createtime) AS rn,
LAST_VALUE(url) OVER(PARTITION BY cookieid ORDER BY createtime) AS last1 
FROM lxw1234;
```

