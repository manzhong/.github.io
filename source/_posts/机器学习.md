---
title: 机器学习
tags: 机器学习
categories: 机器学习
abbrlink: 29139
date: 2022-02-26 19:27:28
summary_img:
encrypt:
enc_pwd:
---

## 一 简介

​		机器学习是一门能够让编程计算机从数据中学习的计算机科学或艺术.

 																													--Arthur Samuel

## 二 类别

机器学习系统种类繁多,常见有以下几种分类:

**1. 是否在人类监督下训练**

```
监督式学习,无监督学习,半监督学习和强化学习
```

**2.是否可以动态地进行增量学习**

```
在线学习和批量学习
```

**3 .基于模型学习和基于实例学习**

这些标准间并不排斥,你可以以你喜欢的方式将其任意组合,例如最先进的垃圾邮件过滤器可能使用深度神经网路模型对垃圾邮件和常规邮件训练,完成动态学习,这使其成为一个在线的基于模型的,监督式学习系统

### 2.2 有/无监督种类

​	根据训练期间接受的监督数量和监督类型,可以将机器学习系统分为以下4个主要类别: 监督学习,无监督学习,半监督学习和强化学习

**1.监督学习**

在监督学习中,提供给算法的包含所需解决方案的训练数据,称为标签或标记(有标记的训练集)

```
1.分类任务就是一个典型的监督式学习任务
2.通过预测变量,也就是一组给定特征来预测一个目标值
```

**回归与分类**

​	**分类模型和回归模型本质一样，分类模型可将回归模型的输出离散化，回归模型也可将分类模型的输出连续化.**

**回归与分类的根本区别在于输出空间是否为一个[度量空间]**

```
1:对于回归问题，其输出空间B是一个度量空间，即所谓“定量”。也就是说，回归问题的输出空间定义了一个度量  去衡量输出值与真实值之间的“误差大小”。例如：预测一瓶700毫升的可乐的价格（真实价格为5元）为6元时，误差为1；预测其为7元时，误差为2。这两个预测结果是不一样的，是有度量定义来衡量这种“不一样”的。（于是有了均方误差这类误差函数）。

2:对于分类问题，其输出空间B不是度量空间，即所谓“定性”。也就是说，在分类问题中，只有分类“正确”与“错误”之分，至于错误时是将Class 5分到Class 6,还是Class 7，并没有区别，都是在error counter上+1。
```

```
1.定量输出称为回归，或者说是连续变量预测；
2.定性输出称为分类，或者说是离散变量预测。
如:
预测明天的气温是多少度，这是一个回归任务；
预测明天是阴、晴还是雨，就是一个分类任务。
```

回归算法可以应用于分类,反之亦然,如:逻辑回归广泛地用于分类,因为他可以输出(属于某个给定类别的概率的值.如20%的概率为垃圾邮件)

 常见的监督学习,后期会单独介绍

```
K-近邻(KNN)
线性回归(Linear Regression)
逻辑回归(Logistic Regression)
支持向量机(SVM)
决策树(Decision Tree)
随机森林(Random Forests)
神经网络(Nenral Networks)
朴素贝叶斯(Navie Bayes)
```

#### 2 无监督学习

**无监督学习的训练数据都是未经标记的.**

常见的无监督学习的算法

```
聚类算法
	K-平均算法(K-means)
	分层聚类分析(HCA)
	最大期望算法
可视化和降维(降维是在不丢失太多信息的前提下简化数据)
	主成分分析(PCA)
	核主成分分析(Kernel PCA)
	局部线性嵌入(LLE)
	T-分布随机近邻嵌入(t-SNE)
关联规则学习(目的是挖掘大量数据,发现属性之间的有趣联系)
	Apriori
	Eclat
```

### 3 半监督学习

处理部分标记的训练数据-通常是大量未标记的数据和少量的标记数据,

大多数的半监督学习算法是无监督和监督算法的结合

### 4 强化学习

用于描述和解决[智能体](https://baike.baidu.com/item/智能体/9446647)（agent）在与环境的交互过程中通过学习策略以达成回报最大化或实现特定目标的问题

## 三 机器学习的挑战

机器学习的任务就是选择一种算法,对某些数据进行训练,所以最可能出现的问题就是"坏数据"和"坏算法"

### 3.1 数据问题

- 训练数据不足(采样偏差)

- 训练数据不具有代表性

- 质量差的数据

- 无关特征

  ```
  	只有训练数据里包含足够多的相关特征,以及较少的无关特征,系统才能够完成学习,一个成功的机器学习项目,关键部分是提取出一组好的用来训练的特征集,这个过程叫做特征工程(后续会专门介绍这一部分)
  	1:特征选择:从现有特征中选择最有用的特征进行训练
  	2:特征提取:将现有特征进行整合,产生更有用的特征(如降维)
  	3:收集新数据创造新特征
  ```

### 3.2 算法问题

```
训练数据过拟合
训练数据欠拟合
```

**1 欠拟合**

首先欠拟合就是模型没有很好地捕捉到数据特征，不能够很好地拟合数据,

解决:

```
1: 选择一个带有更多参数,更强大的模型 或 添加多项式特征
2: 给学习算法提供更好的特征集(特征工程)
		如:“组合”、“泛化”、“相关性”三类特征是特征添加的重要手段，无论在什么场景，都可以照葫芦画瓢，总会得到意想不到的效果
3: 减少模型中的约束(如: 减少正则化超参数)
```

**2 过拟合**

通俗一点地来说过拟合就是模型把数据学习的太彻底，以至于把噪声数据的特征也学习到了，这样就会导致在后期测试的时候不能够很好地识别数据，即不能正确的分类，模型泛化能力太差.(总之就是,训练集优秀,测试集不尽如人意)

解决:

```
1: 重新清洗数据
2: 增大数据的训练量，还有一个原因就是我们用于训练的数据量太小导致的，训练数据占总数据的比例过小。
3: 采用正则化方法。正则化方法包括L0正则、L1正则和L2正则，而正则一般是在目标函数之后加上对于的范数。但是在机器学习中一般使用L2正则(具体需要参考:L0,L1,L2的区别与相关问题的计算难度,如NP难等)
4: 简化模型
5: 采用dropout方法。这个方法在神经网络里面很常用。dropout方法是ImageNet中提出的一种方法，通俗一点讲就是dropout方法在训练的时候让神经元以一定的概率不工作
```

后续会根据具体的例子介绍相关过拟合和欠拟合

**3 偏差与方差**

```
偏差：是指一个模型的在不同训练集上的平均性能和最优模型的差异。偏差可以用来衡量一个模型的拟合能力。偏差越大，预测值平均性能越偏离最优模型。偏差衡量模型的预测能力，对象是一个在不同训练集上模型，形容这个模型平均性能对最优模型的预测能力。
方差：（ variance）描述的是 一个模型在不同训练集上的差异，描述的是一个模型在不同训练集之间的差异，表示模型的泛化能力，方差越小，模型的泛化能力越强。可以用来衡量一个模型是否容易过拟合。
预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，预测结果数据的分布越散。方差用于衡量一个模型在不同训练集之间的关系，和最优模型无关。对象是不同训练集上的一个模型，表示选取不同的训练集，得出的模型之间的差异性。
```

记住：方差和偏差都是衡量模型的，方差表示选取不同的训练集，训练出模型的差异有多大，而偏差是指一个模型在不同训练集上的平均性能和最优模型的差异。

吴恩达老师的课程中曾说过偏差与方差,在这做个总结:

```
1:当你的训练误差和交叉验证误差或测试误差都很大，且值差不多时，是处于高偏差，低方差，欠拟合状态，需要增加多项式的次数来解决。
2:当你的训练误差和交叉验证误差差距很大，且测试集误差很小，验证误差很大，是处于低偏差，高方差，过拟合状态，需要减少多项式的次数或者利用正则化来解决
```

**4 判断欠拟合和过拟合**

绘制训练集和测试集的学习曲线(后期补充)

## 四 测试与验证

常见的做法是,将数据分割成两部分: 训练集和测试集(划分是80%训练集,20%测试集,且抽样应是随机的)且最好在查看数据之前最好将测试集创建出来,防止**数据窥探偏误**,导致最后测试集估计结果过于乐观,但线上不尽如人意.

​	应对新场景的误差称为泛化误差(样例外误差),通过测试集评估模型,可以得到这个误差,如训练误差很低,但泛化误差很高,说明模型对于训练数据存在过拟合.

​	若是多模型多超参数验证的话,一般吧数据集划分为 训练集,验证集,测试集 

为避免验证集浪费太多的数据,一般使用交叉验证,将验证集分成若干互补子集,然后每个模型都通过这些子集的不同组合来进行训练,之后用剩余子集验证,一旦模型和超参数都被选定,最终模型带着参数对整个训练集进行一次训练,最后在测试集测量泛化误差.

​	选择模型,就需要对数据做出一些合理的假设(且对数据理解很深),然后评估部分合理的模型(对模型了解也很透彻),往往需要经验了

## 五 模型评估

### 1 回归问题

**回归问题的典型性能衡量指标是均方根误差(RMSE)**

### 2 分类问题

**1 混淆矩阵(误差矩阵)**

**2 准确率和错误率**

**3 精准率和召回率**

**4 F-score**

**5 平均(宏平均与微平均)**

**6 ROC与AUC**

**7 PR曲线**



