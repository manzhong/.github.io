<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-bounce.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":false,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="一 架构概览 sparkSql 使用antlr4 解析sql ,所以用户可以基于spark引擎使用sql语句对数据进行分析，而不用去编写程序代码.   spark sql的运行流程如下：    大概有6步：   1. sql 语句经过 SqlParser 解析成 Unresolved Logical Plan;  2. analyzer 结合 catalog 进行绑定,生成 Logical Pla">
<meta property="og:type" content="article">
<meta property="og:title" content="SparkSql-2.4.3源码解析">
<meta property="og:url" content="http://example.com/2020/06/07/SparkSql-2-4-3%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/index.html">
<meta property="og:site_name" content="春雨里洗过的太阳">
<meta property="og:description" content="一 架构概览 sparkSql 使用antlr4 解析sql ,所以用户可以基于spark引擎使用sql语句对数据进行分析，而不用去编写程序代码.   spark sql的运行流程如下：    大概有6步：   1. sql 语句经过 SqlParser 解析成 Unresolved Logical Plan;  2. analyzer 结合 catalog 进行绑定,生成 Logical Pla">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190124150236498.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW9qaWFvNTIxNzY1MTQ2NTE0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190129155353223.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW9qaWFvNTIxNzY1MTQ2NTE0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2019013014250169.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW9qaWFvNTIxNzY1MTQ2NTE0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190130142719285.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW9qaWFvNTIxNzY1MTQ2NTE0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190130143128524.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW9qaWFvNTIxNzY1MTQ2NTE0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190130175726850.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW9qaWFvNTIxNzY1MTQ2NTE0,size_16,color_FFFFFF,t_70">
<meta property="article:published_time" content="2020-06-07T10:53:01.000Z">
<meta property="article:modified_time" content="2021-03-17T14:22:17.338Z">
<meta property="article:author" content="HF">
<meta property="article:tag" content="Spark">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20190124150236498.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW9qaWFvNTIxNzY1MTQ2NTE0,size_16,color_FFFFFF,t_70">

<link rel="canonical" href="http://example.com/2020/06/07/SparkSql-2-4-3%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>
<link rel="stylesheet" type="text/css" href="/css/injector.css" />
  <title>SparkSql-2.4.3源码解析 | 春雨里洗过的太阳</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">春雨里洗过的太阳</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">世间所有的相遇，都是久别重逢</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/06/07/SparkSql-2-4-3%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/hexo.jpg">
      <meta itemprop="name" content="HF">
      <meta itemprop="description" content="第二名就是头号输家">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="春雨里洗过的太阳">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          SparkSql-2.4.3源码解析
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-06-07 18:53:01" itemprop="dateCreated datePublished" datetime="2020-06-07T18:53:01+08:00">2020-06-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-03-17 22:22:17" itemprop="dateModified" datetime="2021-03-17T22:22:17+08:00">2021-03-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>65k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>59 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="一-架构概览"><a href="#一-架构概览" class="headerlink" title="一 架构概览"></a>一 架构概览</h1><p>sparkSql 使用antlr4 解析sql ,所以用户可以基于spark引擎使用sql语句对数据进行分析，而不用去编写程序代码.</p>
<p> spark sql的运行流程如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20190124150236498.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW9qaWFvNTIxNzY1MTQ2NTE0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>大概有6步：</p>
<ol>
<li>sql 语句经过 SqlParser 解析成 Unresolved Logical Plan;</li>
<li>analyzer 结合 catalog 进行绑定,生成 Logical Plan;</li>
<li>optimizer 对 Logical Plan 优化,生成 Optimized LogicalPlan;</li>
<li>SparkPlan 将 Optimized LogicalPlan 转换成 Physical Plan;</li>
<li>prepareForExecution()将 Physical Plan 转换成 executed Physical Plan;</li>
<li>execute()执行可执行物理计划，得到RDD;</li>
</ol>
<p>上述流程在spark中对应的源码部分：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QueryExecution</span>(<span class="params">val sparkSession: <span class="type">SparkSession</span>, val logical: <span class="type">LogicalPlan</span></span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> Move the planner an optimizer into here from SessionState.</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">planner</span> </span>= sparkSession.sessionState.planner</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">assertAnalyzed</span></span>(): <span class="type">Unit</span> = analyzed</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">assertSupported</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (sparkSession.sessionState.conf.isUnsupportedOperationCheckEnabled) &#123;</span><br><span class="line">      <span class="type">UnsupportedOperationChecker</span>.checkForBatch(analyzed)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> analyzed: <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line">    <span class="type">SparkSession</span>.setActiveSession(sparkSession)</span><br><span class="line">    sparkSession.sessionState.analyzer.executeAndCheck(logical)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> withCachedData: <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line">    assertAnalyzed()</span><br><span class="line">    assertSupported()</span><br><span class="line">    sparkSession.sharedState.cacheManager.useCachedData(analyzed)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> optimizedPlan: <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line">    sparkSession.sessionState.optimizer.execute(withCachedData)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> sparkPlan: <span class="type">SparkPlan</span> = &#123;</span><br><span class="line">    <span class="type">SparkSession</span>.setActiveSession(sparkSession)</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> We use next(), i.e. take the first plan returned by the planner, here for now,</span></span><br><span class="line">    <span class="comment">//       but we will implement to choose the best plan.</span></span><br><span class="line">    planner.plan(<span class="type">ReturnAnswer</span>(optimizedPlan)).next()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// executedPlan should not be used to initialize any SparkPlan. It should be</span></span><br><span class="line">  <span class="comment">// only used for execution.</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> executedPlan: <span class="type">SparkPlan</span> = prepareForExecution(sparkPlan)</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Internal version of the RDD. Avoids copies and has no schema */</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> toRdd: <span class="type">RDD</span>[<span class="type">InternalRow</span>] = executedPlan.execute()</span><br></pre></td></tr></table></figure>

<p>​     逻辑交代的非常清楚，从最后一行的   lazy val toRdd: RDD[InternalRow] = executedPlan.execute() 往前推便可清晰看到整个流程。细心的同学也可以看到 所有步骤都是lazy的，只有调用了execute才会触发执行，这也是spark的重要设计思想。</p>
<h1 id="二-源码分析"><a href="#二-源码分析" class="headerlink" title="二 源码分析"></a>二 源码分析</h1><p>当我们执行: 以SparkSession 的 sql(sqlText: String): DataFrame 为例</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sparkSession.sql(<span class="string">&quot;select * .....&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="2-1-sql的parser"><a href="#2-1-sql的parser" class="headerlink" title="2.1 sql的parser"></a>2.1 sql的parser</h2><p>看一下sql函数:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Executes a SQL query using Spark, returning the result as a `DataFrame`.</span></span><br><span class="line"><span class="comment"> * The dialect that is used for SQL parsing can be configured with &#x27;spark.sql.dialect&#x27;.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @since 2.0.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sql</span></span>(sqlText: <span class="type">String</span>): <span class="type">DataFrame</span> = &#123;</span><br><span class="line">  <span class="type">Dataset</span>.ofRows(self, sessionState.sqlParser.parsePlan(sqlText))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Interface for a parser.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">ParserInterface</span> </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Parse a string to a [[LogicalPlan]].</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="comment">//将sql转为逻辑计划</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parsePlan</span></span>(sqlText: <span class="type">String</span>): <span class="type">LogicalPlan</span></span><br><span class="line">  .....</span><br></pre></td></tr></table></figure>

<p>而在抽象类AbstractSqlParser中重写了这个方法:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractSqlParser</span> <span class="keyword">extends</span> <span class="title">ParserInterface</span> <span class="keyword">with</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">	.</span><br><span class="line">  .</span><br><span class="line">  .</span><br><span class="line">  <span class="comment">/** Creates LogicalPlan for a given SQL string. */</span></span><br><span class="line">  <span class="comment">//这里调用了主函数parse 把sql变为LogicalPlan(逻辑计划) </span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">parsePlan</span></span>(sqlText: <span class="type">String</span>): <span class="type">LogicalPlan</span> = parse(sqlText) &#123; parser =&gt;</span><br><span class="line">    <span class="comment">//从 singleStatement 结点开始，遍历语法树，将结点转换为逻辑计划</span></span><br><span class="line">    astBuilder.visitSingleStatement(parser.singleStatement()) <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> plan: <span class="type">LogicalPlan</span> =&gt; plan</span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">        <span class="keyword">val</span> position = <span class="type">Origin</span>(<span class="type">None</span>, <span class="type">None</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">ParseException</span>(<span class="type">Option</span>(sqlText), <span class="string">&quot;Unsupported SQL statement&quot;</span>, position, position)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Get the builder (visitor) which converts a ParseTree into an AST. */</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">astBuilder</span></span>: <span class="type">AstBuilder</span></span><br><span class="line"><span class="comment">//变为逻辑计划的最终实现方法</span></span><br><span class="line">  <span class="comment">//使用 ANTLR 4 实现了 SQL 语句的词法分析和语法分析，获得了抽象语法树</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">parse</span></span>[<span class="type">T</span>](command: <span class="type">String</span>)(toResult: <span class="type">SqlBaseParser</span> =&gt; <span class="type">T</span>): <span class="type">T</span> = &#123;</span><br><span class="line">    logDebug(<span class="string">s&quot;Parsing command: <span class="subst">$command</span>&quot;</span>)</span><br><span class="line"><span class="comment">//词法解析器SqlBaseLexer(将SQL语句解析成一个个短语)</span></span><br><span class="line">    <span class="keyword">val</span> lexer = <span class="keyword">new</span> <span class="type">SqlBaseLexer</span>(<span class="keyword">new</span> <span class="type">UpperCaseCharStream</span>(<span class="type">CharStreams</span>.fromString(command)))</span><br><span class="line">    lexer.removeErrorListeners()</span><br><span class="line">    lexer.addErrorListener(<span class="type">ParseErrorListener</span>)</span><br><span class="line">    lexer.legacy_setops_precedence_enbled = <span class="type">SQLConf</span>.get.setOpsPrecedenceEnforced</span><br><span class="line">    <span class="comment">//语法解析器SqlBaseParser</span></span><br><span class="line">    <span class="comment">// Antlr 生成的 SqlBaseParser 进行语法分析，得到 LogicalPlan</span></span><br><span class="line">    <span class="keyword">val</span> tokenStream = <span class="keyword">new</span> <span class="type">CommonTokenStream</span>(lexer)</span><br><span class="line">    <span class="keyword">val</span> parser = <span class="keyword">new</span> <span class="type">SqlBaseParser</span>(tokenStream)</span><br><span class="line">    parser.addParseListener(<span class="type">PostProcessor</span>)</span><br><span class="line">    parser.removeErrorListeners()</span><br><span class="line">    parser.addErrorListener(<span class="type">ParseErrorListener</span>)</span><br><span class="line">    parser.legacy_setops_precedence_enbled = <span class="type">SQLConf</span>.get.setOpsPrecedenceEnforced</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// first, try parsing with potentially faster SLL mode</span></span><br><span class="line">        parser.getInterpreter.setPredictionMode(<span class="type">PredictionMode</span>.<span class="type">SLL</span>)</span><br><span class="line">        toResult(parser)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">ParseCancellationException</span> =&gt;</span><br><span class="line">          <span class="comment">// if we fail, parse with LL mode</span></span><br><span class="line">          tokenStream.seek(<span class="number">0</span>) <span class="comment">// rewind input stream</span></span><br><span class="line">          parser.reset()</span><br><span class="line"></span><br><span class="line">          <span class="comment">// Try Again.</span></span><br><span class="line">          parser.getInterpreter.setPredictionMode(<span class="type">PredictionMode</span>.<span class="type">LL</span>)</span><br><span class="line">          toResult(parser)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">ParseException</span> <span class="keyword">if</span> e.command.isDefined =&gt;</span><br><span class="line">        <span class="keyword">throw</span> e</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">ParseException</span> =&gt;</span><br><span class="line">        <span class="keyword">throw</span> e.withCommand(command)</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">AnalysisException</span> =&gt;</span><br><span class="line">        <span class="keyword">val</span> position = <span class="type">Origin</span>(e.line, e.startPosition)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">ParseException</span>(<span class="type">Option</span>(command), e.message, position, position)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在AbstractSqlParser的实现类SparkSqlParser中:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Concrete parser for Spark SQL statements.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SparkSqlParser</span>(<span class="params">conf: <span class="type">SQLConf</span></span>) <span class="keyword">extends</span> <span class="title">AbstractSqlParser</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> astBuilder = <span class="keyword">new</span> <span class="type">SparkSqlAstBuilder</span>(conf)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> substitutor = <span class="keyword">new</span> <span class="type">VariableSubstitution</span>(conf)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">protected</span> <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">parse</span></span>[<span class="type">T</span>](command: <span class="type">String</span>)(toResult: <span class="type">SqlBaseParser</span> =&gt; <span class="type">T</span>): <span class="type">T</span> = &#123;</span><br><span class="line">    <span class="comment">//调用父类的parse方法</span></span><br><span class="line">    <span class="keyword">super</span>.parse(substitutor.substitute(command))(toResult)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>**最终 parsePlan 函数将 sql语句变成了 LogicalPlan **</p>
<p>仔细阅读 parse函数，可以发现其中主要的工作主力是SqlBaseLexer 和 SparkSqlAstBuilder,它们都是antlr4相关的代码</p>
<p><strong>要了解antlr4 可以参考我的另一篇博客:</strong></p>
<figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">http</span></span><br></pre></td></tr></table></figure>

<p><strong>接下来我们看一下SparkSqlAstBuilder:</strong></p>
<p>首先我门看一下SparkSqlAstBuilder 的继承体系:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SparkSqlAstBuilder</span>(<span class="params">conf: <span class="type">SQLConf</span></span>) <span class="keyword">extends</span> <span class="title">AstBuilder</span>(<span class="params">conf</span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">AstBuilder</span>(<span class="params">conf: <span class="type">SQLConf</span></span>) <span class="keyword">extends</span> <span class="title">SqlBaseBaseVisitor</span>[<span class="type">AnyRef</span>] <span class="keyword">with</span> <span class="title">Logging</span> </span></span><br></pre></td></tr></table></figure>

<p>参考我的博客sparksql的语法词法解析可以对SqlBaseBaseVisitor有个大致了解:</p>
<figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">http</span></span><br></pre></td></tr></table></figure>

<p><strong>实际就是AstBuilder 封装了大量的visit开头的方法,使用这些方法对sql语句进行分段解析如(join,where, from,select等)(个人理解,可能有失偏颇)</strong></p>
<p>为了使读者,不看上面的博客对antlr4也有个大概了解,一下我简单介绍一下:</p>
<p>使用antlr4 ,需要的因素:</p>
<p><strong>1.语法文件(org.apache.spark.sql.catalyst.parser.SqlBase.g4，放置在子工程catalyst中)</strong></p>
<p><strong>2.监视器类或者访问者类</strong><br>在spark-sql的体系中,主要是使用访问者类(SparkSqlAstBuilder),但是也使用了监听器类辅助(PostProcessor)来处理格式转换</p>
<h3 id="第一步-从-astBuilder-visitSingleStatement结点开始，遍历语法树，将结点转换为逻辑计划"><a href="#第一步-从-astBuilder-visitSingleStatement结点开始，遍历语法树，将结点转换为逻辑计划" class="headerlink" title="第一步: 从 astBuilder.visitSingleStatement结点开始，遍历语法树，将结点转换为逻辑计划"></a>第一步: 从 astBuilder.visitSingleStatement结点开始，遍历语法树，将结点转换为逻辑计划</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">visitSingleStatement</span></span>(ctx: <span class="type">SingleStatementContext</span>): <span class="type">LogicalPlan</span> = withOrigin(ctx) &#123;</span><br><span class="line">  visit(ctx.statement).asInstanceOf[<span class="type">LogicalPlan</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>SqlBaseBaseVisitor 的父类就是AbstractParseTreeVisitor</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractParseTreeVisitor</span>&lt;<span class="title">T</span>&gt; <span class="keyword">implements</span> <span class="title">ParseTreeVisitor</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * &#123;<span class="doctag">@inheritDoc</span>&#125;</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * &lt;p&gt;The default implementation calls &#123;<span class="doctag">@link</span> ParseTree#accept&#125; on the</span></span><br><span class="line"><span class="comment">	 * specified tree.&lt;/p&gt;</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> T <span class="title">visit</span><span class="params">(ParseTree tree)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> tree.accept(<span class="keyword">this</span>);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> &lt;T&gt; <span class="function">T <span class="title">accept</span><span class="params">(ParseTreeVisitor&lt;? extends T&gt; visitor)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">if</span> ( visitor <span class="keyword">instanceof</span> SqlBaseVisitor ) <span class="keyword">return</span> ((SqlBaseVisitor&lt;? extends T&gt;)visitor).visitQuerySpecification(<span class="keyword">this</span>);</span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">return</span> visitor.visitChildren(<span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="第二步-AstBuilder-scala-实现了SqlBaseBaseVisitor用于解析逻辑的实现"><a href="#第二步-AstBuilder-scala-实现了SqlBaseBaseVisitor用于解析逻辑的实现" class="headerlink" title="第二步:AstBuilder.scala 实现了SqlBaseBaseVisitor用于解析逻辑的实现"></a>第二步:AstBuilder.scala 实现了SqlBaseBaseVisitor用于解析逻辑的实现</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">visitQuerySpecification</span></span>(</span><br><span class="line">    ctx: <span class="type">QuerySpecificationContext</span>): <span class="type">LogicalPlan</span> = withOrigin(ctx) &#123;</span><br><span class="line">  <span class="keyword">val</span> from = <span class="type">OneRowRelation</span>().optional(ctx.fromClause) &#123;</span><br><span class="line">    visitFromClause(ctx.fromClause)</span><br><span class="line">  &#125;</span><br><span class="line">  withQuerySpecification(ctx, from)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>FROM 语句解析</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">visitFromClause</span></span>(ctx: <span class="type">FromClauseContext</span>): <span class="type">LogicalPlan</span> = withOrigin(ctx) &#123;</span><br><span class="line">  <span class="keyword">val</span> from = ctx.relation.asScala.foldLeft(<span class="literal">null</span>: <span class="type">LogicalPlan</span>) &#123; (left, relation) =&gt;</span><br><span class="line">    <span class="keyword">val</span> right = plan(relation.relationPrimary)</span><br><span class="line">    <span class="keyword">val</span> join = right.optionalMap(left)(<span class="type">Join</span>(_, _, <span class="type">Inner</span>, <span class="type">None</span>))</span><br><span class="line">    withJoinRelations(join, relation)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (ctx.pivotClause() != <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!ctx.lateralView.isEmpty) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">ParseException</span>(<span class="string">&quot;LATERAL cannot be used together with PIVOT in FROM clause&quot;</span>, ctx)</span><br><span class="line">    &#125;</span><br><span class="line">    withPivot(ctx.pivotClause, from)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ctx.lateralView.asScala.foldLeft(from)(withGenerate)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>WHERE 等语句解析,看这很复杂,但我们只需要关注自己的sql:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Add a query specification to a logical plan. The query specification is the core of the logical</span></span><br><span class="line"><span class="comment">   * plan, this is where sourcing (FROM clause), transforming (SELECT TRANSFORM/MAP/REDUCE),</span></span><br><span class="line"><span class="comment">   * projection (SELECT), aggregation (GROUP BY ... HAVING ...) and filtering (WHERE) takes place.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Note that query hints are ignored (both by the parser and the builder).</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">withQuerySpecification</span></span>(</span><br><span class="line">      ctx: <span class="type">QuerySpecificationContext</span>,</span><br><span class="line">      relation: <span class="type">LogicalPlan</span>): <span class="type">LogicalPlan</span> = withOrigin(ctx) &#123;</span><br><span class="line">    <span class="keyword">import</span> ctx._</span><br><span class="line"></span><br><span class="line">    <span class="comment">// WHERE</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(ctx: <span class="type">BooleanExpressionContext</span>, plan: <span class="type">LogicalPlan</span>): <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line">      <span class="type">Filter</span>(expression(ctx), plan)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">withHaving</span></span>(ctx: <span class="type">BooleanExpressionContext</span>, plan: <span class="type">LogicalPlan</span>): <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line">      <span class="comment">// Note that we add a cast to non-predicate expressions. If the expression itself is</span></span><br><span class="line">      <span class="comment">// already boolean, the optimizer will get rid of the unnecessary cast.</span></span><br><span class="line">      <span class="keyword">val</span> predicate = expression(ctx) <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> p: <span class="type">Predicate</span> =&gt; p</span><br><span class="line">        <span class="keyword">case</span> e =&gt; <span class="type">Cast</span>(e, <span class="type">BooleanType</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="type">Filter</span>(predicate, plan)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Expressions. 也就是要查询的内容</span></span><br><span class="line">    <span class="keyword">val</span> expressions = <span class="type">Option</span>(namedExpressionSeq).toSeq</span><br><span class="line">      .flatMap(_.namedExpression.asScala)</span><br><span class="line">      .map(typedVisit[<span class="type">Expression</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create either a transform or a regular query.</span></span><br><span class="line">    <span class="keyword">val</span> specType = <span class="type">Option</span>(kind).map(_.getType).getOrElse(<span class="type">SqlBaseParser</span>.<span class="type">SELECT</span>)</span><br><span class="line">    specType <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">SqlBaseParser</span>.<span class="type">MAP</span> | <span class="type">SqlBaseParser</span>.<span class="type">REDUCE</span> | <span class="type">SqlBaseParser</span>.<span class="type">TRANSFORM</span> =&gt;</span><br><span class="line">        <span class="comment">// Transform</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// Add where.</span></span><br><span class="line">        <span class="keyword">val</span> withFilter = relation.optionalMap(where)(filter)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Create the attributes.</span></span><br><span class="line">        <span class="keyword">val</span> (attributes, schemaLess) = <span class="keyword">if</span> (colTypeList != <span class="literal">null</span>) &#123;</span><br><span class="line">          <span class="comment">// Typed return columns.</span></span><br><span class="line">          (createSchema(colTypeList).toAttributes, <span class="literal">false</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (identifierSeq != <span class="literal">null</span>) &#123;</span><br><span class="line">          <span class="comment">// Untyped return columns.</span></span><br><span class="line">          <span class="keyword">val</span> attrs = visitIdentifierSeq(identifierSeq).map &#123; name =&gt;</span><br><span class="line">            <span class="type">AttributeReference</span>(name, <span class="type">StringType</span>, nullable = <span class="literal">true</span>)()</span><br><span class="line">          &#125;</span><br><span class="line">          (attrs, <span class="literal">false</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          (<span class="type">Seq</span>(<span class="type">AttributeReference</span>(<span class="string">&quot;key&quot;</span>, <span class="type">StringType</span>)(),</span><br><span class="line">            <span class="type">AttributeReference</span>(<span class="string">&quot;value&quot;</span>, <span class="type">StringType</span>)()), <span class="literal">true</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Create the transform.</span></span><br><span class="line">        <span class="type">ScriptTransformation</span>(</span><br><span class="line">          expressions,</span><br><span class="line">          string(script),</span><br><span class="line">          attributes,</span><br><span class="line">          withFilter,</span><br><span class="line">          withScriptIOSchema(</span><br><span class="line">            ctx, inRowFormat, recordWriter, outRowFormat, recordReader, schemaLess))</span><br><span class="line">      <span class="comment">//select语句</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">SqlBaseParser</span>.<span class="type">SELECT</span> =&gt;</span><br><span class="line">        <span class="comment">// Regular select</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// Add lateral views.</span></span><br><span class="line">        <span class="keyword">val</span> withLateralView = ctx.lateralView.asScala.foldLeft(relation)(withGenerate)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Add where.</span></span><br><span class="line">        <span class="keyword">val</span> withFilter = withLateralView.optionalMap(where)(filter)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Add aggregation or a project.</span></span><br><span class="line">        <span class="keyword">val</span> namedExpressions = expressions.map &#123;</span><br><span class="line">          <span class="keyword">case</span> e: <span class="type">NamedExpression</span> =&gt; e</span><br><span class="line">          <span class="keyword">case</span> e: <span class="type">Expression</span> =&gt; <span class="type">UnresolvedAlias</span>(e)</span><br><span class="line">        &#125;</span><br><span class="line">      </span><br><span class="line">        <span class="comment">//最终返回的是 Project(namedExpressions, withFilter)，他继承了LogicalPlan</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">createProject</span></span>() = <span class="keyword">if</span> (namedExpressions.nonEmpty) &#123;</span><br><span class="line">          <span class="comment">//sql语句返回的结果</span></span><br><span class="line">          <span class="type">Project</span>(namedExpressions, withFilter)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          withFilter</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> withProject = <span class="keyword">if</span> (aggregation == <span class="literal">null</span> &amp;&amp; having != <span class="literal">null</span>) &#123;</span><br><span class="line">          <span class="keyword">if</span> (conf.getConf(<span class="type">SQLConf</span>.<span class="type">LEGACY_HAVING_WITHOUT_GROUP_BY_AS_WHERE</span>)) &#123;</span><br><span class="line">            <span class="comment">// If the legacy conf is set, treat HAVING without GROUP BY as WHERE.</span></span><br><span class="line">            withHaving(having, createProject())</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// According to SQL standard, HAVING without GROUP BY means global aggregate.</span></span><br><span class="line">            withHaving(having, <span class="type">Aggregate</span>(<span class="type">Nil</span>, namedExpressions, withFilter))</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (aggregation != <span class="literal">null</span>) &#123;</span><br><span class="line">          <span class="keyword">val</span> aggregate = withAggregation(aggregation, namedExpressions, withFilter)</span><br><span class="line">          aggregate.optionalMap(having)(withHaving)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// When hitting this branch, `having` must be null.</span></span><br><span class="line">          <span class="comment">//</span></span><br><span class="line">          createProject()</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Distinct</span></span><br><span class="line">        <span class="keyword">val</span> withDistinct = <span class="keyword">if</span> (setQuantifier() != <span class="literal">null</span> &amp;&amp; setQuantifier().<span class="type">DISTINCT</span>() != <span class="literal">null</span>) &#123;</span><br><span class="line">          <span class="type">Distinct</span>(withProject)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          withProject</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Window</span></span><br><span class="line">        <span class="keyword">val</span> withWindow = withDistinct.optionalMap(windows)(withWindows)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Hint</span></span><br><span class="line">        hints.asScala.foldRight(withWindow)(withHints)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h3 id="第三步-最终返回的是-Project-namedExpressions-withFilter-，继承了LogicalPlan"><a href="#第三步-最终返回的是-Project-namedExpressions-withFilter-，继承了LogicalPlan" class="headerlink" title="第三步:最终返回的是 Project(namedExpressions, withFilter)，继承了LogicalPlan"></a>第三步:最终返回的是 Project(namedExpressions, withFilter)，继承了LogicalPlan</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Project</span>(<span class="params">projectList: <span class="type">Seq</span>[<span class="type">NamedExpression</span>], child: <span class="type">LogicalPlan</span></span>) <span class="keyword">extends</span> <span class="title">UnaryNode</span> </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">output</span></span>: <span class="type">Seq</span>[<span class="type">Attribute</span>] = projectList.map(_.toAttribute)</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">maxRows</span></span>: <span class="type">Option</span>[<span class="type">Long</span>] = child.maxRows</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="keyword">lazy</span> <span class="keyword">val</span> resolved: <span class="type">Boolean</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> hasSpecialExpressions = projectList.exists ( _.collect &#123;</span><br><span class="line">        <span class="keyword">case</span> agg: <span class="type">AggregateExpression</span> =&gt; agg</span><br><span class="line">        <span class="keyword">case</span> generator: <span class="type">Generator</span> =&gt; generator</span><br><span class="line">        <span class="keyword">case</span> window: <span class="type">WindowExpression</span> =&gt; window</span><br><span class="line">      &#125;.nonEmpty</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    !expressions.exists(!_.resolved) &amp;&amp; childrenResolved &amp;&amp; !hasSpecialExpressions</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">validConstraints</span></span>: <span class="type">Set</span>[<span class="type">Expression</span>] =</span><br><span class="line">    child.constraints.union(getAliasedConstraints(projectList))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>SparkSQL是通过AntlrV4这个开源解析框架解析的.在使用的时候做了几层抽象和封装：</p>
<p>1.构造这模式抽象AstBuilder，将AntlrV4的SQL语法实现细节封装<br>2.封装SparksqlParser ，并使用构造这模式，封装SparkSqlAstbuilder继承AstBuilder，那么AntlrV4的特性就都能被SparkSqlParser使用。<br>3.为了兼容用户自定义的解析器，解析器定定一个为ParseInferface接口类型。用户可以通过SparkSession注入自己的解析器，Spark底层会将用户的解析器和SPark的解析器做合并和统一，并保证完整性。</p>
<p><strong>然后我回到最初的SQL:</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sql</span></span>(sqlText: <span class="type">String</span>): <span class="type">DataFrame</span> = &#123;</span><br><span class="line">   <span class="type">Dataset</span>.ofRows(self, sessionState.sqlParser.parsePlan(sqlText))</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p>分析完了parsePlan,接下来我们看看ofRows方法:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ofRows</span></span>(sparkSession: <span class="type">SparkSession</span>, logicalPlan: <span class="type">LogicalPlan</span>): <span class="type">DataFrame</span> = &#123;</span><br><span class="line">   <span class="comment">//QueryExecution创建</span></span><br><span class="line">  <span class="keyword">val</span> qe = sparkSession.sessionState.executePlan(logicalPlan)</span><br><span class="line">  qe.assertAnalyzed()</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Dataset</span>[<span class="type">Row</span>](sparkSession, qe, <span class="type">RowEncoder</span>(qe.analyzed.schema))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>executePlan(logicalPlan)方法创建QueryExecution</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">executePlan</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">QueryExecution</span> = createQueryExecution(plan)</span><br></pre></td></tr></table></figure>

<p><strong>createQueryExecution(plan)创建QueryExecution</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  QueryExecution是Spark用来执行关系型查询的主要工作流。</span></span><br><span class="line"><span class="comment"> *  它是被设计用来为开发人员提供更方便的对查询执行中间阶段的访问。</span></span><br><span class="line"><span class="comment"> *  QueryExecution中最重要的是成员变量，它的成员变量几乎都是lazy variable，</span></span><br><span class="line"><span class="comment"> *  它的方法大部分是为了提供给这些lazy variable去调用的</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QueryExecution</span>(<span class="params">val sparkSession: <span class="type">SparkSession</span>, val logical: <span class="type">LogicalPlan</span></span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> Move the planner an optimizer into here from SessionState.</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">planner</span> </span>= sparkSession.sessionState.planner</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">assertAnalyzed</span></span>(): <span class="type">Unit</span> = analyzed</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">assertSupported</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (sparkSession.sessionState.conf.isUnsupportedOperationCheckEnabled) &#123;</span><br><span class="line">      <span class="type">UnsupportedOperationChecker</span>.checkForBatch(analyzed)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//调用analyzer解析器,对Unresolved LogicalPlan进行元数据绑定生成的Resolved LogicalPlan</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> analyzed: <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line">    <span class="type">SparkSession</span>.setActiveSession(sparkSession)</span><br><span class="line">    sparkSession.sessionState.analyzer.executeAndCheck(logical)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 如果缓存中有查询结果，则直接替换为缓存的结果</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> withCachedData: <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line">    assertAnalyzed()</span><br><span class="line">    assertSupported()</span><br><span class="line">    sparkSession.sharedState.cacheManager.useCachedData(analyzed)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//调用optimizer优化器</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> optimizedPlan: <span class="type">LogicalPlan</span> = sparkSession.sessionState.optimizer.execute(withCachedData)</span><br><span class="line"></span><br><span class="line">  <span class="comment">//已经进行过优化的逻辑执行计划进行转换而得到的物理执行计划SparkPlan</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> sparkPlan: <span class="type">SparkPlan</span> = &#123;</span><br><span class="line">    <span class="type">SparkSession</span>.setActiveSession(sparkSession)</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> We use next(), i.e. take the first plan returned by the planner, here for now,</span></span><br><span class="line">    <span class="comment">//       but we will implement to choose the best plan.</span></span><br><span class="line">   <span class="comment">// 在一系列plan中选取一个</span></span><br><span class="line">    planner.plan(<span class="type">ReturnAnswer</span>(optimizedPlan)).next()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// executedPlan should not be used to initialize any SparkPlan. It should be</span></span><br><span class="line">  <span class="comment">// only used for execution.</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> executedPlan: <span class="type">SparkPlan</span> = prepareForExecution(sparkPlan)</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Internal version of the RDD. Avoids copies and has no schema */</span></span><br><span class="line">  <span class="comment">//QueryExecution最后生成的RDD,触发了action操作后才会执行</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> toRdd: <span class="type">RDD</span>[<span class="type">InternalRow</span>] = executedPlan.execute()</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="2-2-analyzer解析器"><a href="#2-2-analyzer解析器" class="headerlink" title="2.2 analyzer解析器"></a>2.2 analyzer解析器</h2><p>parser生成逻辑执行计划后，使用analyzer将逻辑执行计划进行分析。</p>
<h3 id="第一步-sparkSession-sessionState-analyzer-executeAndCheck-logical-方法"><a href="#第一步-sparkSession-sessionState-analyzer-executeAndCheck-logical-方法" class="headerlink" title="第一步:sparkSession.sessionState.analyzer.executeAndCheck(logical)方法"></a>第一步:sparkSession.sessionState.analyzer.executeAndCheck(logical)方法</h3><p>源码地址：org.apache.spark.sql.catalyst.analysis.Analyzer.scala</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Analyzer</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    //管理着临时表、view、函数及外部依赖元数据（如hive metastore），是analyzer进行绑定的桥梁</span></span></span><br><span class="line"><span class="class"><span class="params">    catalog: <span class="type">SessionCatalog</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    conf: <span class="type">SQLConf</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    maxIterations: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">RuleExecutor</span>[<span class="type">LogicalPlan</span>] <span class="keyword">with</span> <span class="title">CheckAnalysis</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(catalog: <span class="type">SessionCatalog</span>, conf: <span class="type">SQLConf</span>) = &#123;</span><br><span class="line">    <span class="keyword">this</span>(catalog, conf, conf.optimizerMaxIterations)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">executeAndCheck</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">LogicalPlan</span> = <span class="type">AnalysisHelper</span>.markInAnalyzer &#123;</span><br><span class="line">    <span class="comment">// 执行 analyze逻辑</span></span><br><span class="line">    <span class="keyword">val</span> analyzed = execute(plan)</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      checkAnalysis(analyzed)</span><br><span class="line">      analyzed</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">AnalysisException</span> =&gt;</span><br><span class="line">        <span class="keyword">val</span> ae = <span class="keyword">new</span> <span class="type">AnalysisException</span>(e.message, e.line, e.startPosition, <span class="type">Option</span>(analyzed))</span><br><span class="line">        ae.setStackTrace(e.getStackTrace)</span><br><span class="line">        <span class="keyword">throw</span> ae</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="第二步-execute-plan-方法"><a href="#第二步-execute-plan-方法" class="headerlink" title="第二步:execute(plan)方法"></a>第二步:execute(plan)方法</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">execute</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line">  <span class="type">AnalysisContext</span>.reset()</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    executeSameContext(plan)</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="type">AnalysisContext</span>.reset()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">executeSameContext</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">LogicalPlan</span> = <span class="keyword">super</span>.execute(plan)</span><br></pre></td></tr></table></figure>

<h3 id="第三步-super-execute-plan-方法"><a href="#第三步-super-execute-plan-方法" class="headerlink" title="第三步:super.execute(plan)方法"></a>第三步:super.execute(plan)方法</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 优化规则执行器</span></span><br><span class="line"><span class="comment"> * 按批次，按顺序对LogicalPlan执行rule，会迭代多次</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">RuleExecutor</span>[<span class="type">TreeType</span> &lt;: <span class="type">TreeNode</span>[_]] <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * An execution strategy for rules that indicates the maximum number of executions. If the</span></span><br><span class="line"><span class="comment">   * execution reaches fix point (i.e. converge) before maxIterations, it will stop.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="comment">/** 控制运行次数的策略，如果在达到最大迭代次数前到达稳定点就停止运行 */</span></span><br><span class="line">  <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Strategy</span> </span>&#123; <span class="function"><span class="keyword">def</span> <span class="title">maxIterations</span></span>: <span class="type">Int</span> &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** A strategy that only runs once. */</span></span><br><span class="line">  <span class="comment">/** 只运行一次的策略 */</span></span><br><span class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">object</span> <span class="title">Once</span> <span class="keyword">extends</span> <span class="title">Strategy</span> </span>&#123; <span class="keyword">val</span> maxIterations = <span class="number">1</span> &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** A strategy that runs until fix point or maxIterations times, whichever comes first. */</span></span><br><span class="line">   <span class="comment">/** 运行到稳定点或者最大迭代次数的策略，2选1 */</span></span><br><span class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">FixedPoint</span>(<span class="params">maxIterations: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Strategy</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">  <span class="title">/**</span> <span class="title">A</span> <span class="title">batch</span> <span class="title">of</span> <span class="title">rules</span>. <span class="title">*/</span></span></span><br><span class="line"><span class="class">  <span class="title">//</span>  <span class="title">一个批次的rules</span></span></span><br><span class="line"><span class="class">  <span class="title">protected</span> <span class="title">case</span> <span class="title">class</span> <span class="title">Batch</span>(<span class="params">name: <span class="type">String</span>, strategy: <span class="type">Strategy</span>, rules: <span class="type">Rule</span>[<span class="type">TreeType</span>]*</span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">  <span class="title">/**</span> <span class="title">Defines</span> <span class="title">a</span> <span class="title">sequence</span> <span class="title">of</span> <span class="title">rule</span> <span class="title">batches</span>, <span class="title">to</span> <span class="title">be</span> <span class="title">overridden</span> <span class="title">by</span> <span class="title">the</span> <span class="title">implementation</span>. <span class="title">*/</span></span></span><br><span class="line"><span class="class">  <span class="title">//</span>  <span class="title">所有的rule，按批次存放</span></span></span><br><span class="line"><span class="class">  <span class="title">protected</span> <span class="title">def</span> <span class="title">batches</span></span>: <span class="type">Seq</span>[<span class="type">Batch</span>]</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Defines a check function that checks for structural integrity of the plan after the execution</span></span><br><span class="line"><span class="comment">   * of each rule. For example, we can check whether a plan is still resolved after each rule in</span></span><br><span class="line"><span class="comment">   * `Optimizer`, so we can catch rules that return invalid plans. The check function returns</span></span><br><span class="line"><span class="comment">   * `false` if the given plan doesn&#x27;t pass the structural integrity check.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">isPlanIntegral</span></span>(plan: <span class="type">TreeType</span>): <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Executes the batches of rules defined by the subclass. The batches are executed serially</span></span><br><span class="line"><span class="comment">   * using the defined execution strategy. Within each batch, rules are also executed serially.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="comment">// 执行rule，关键代码很简单，就是按批次，按顺序对plan执行rule，会迭代多次</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">execute</span></span>(plan: <span class="type">TreeType</span>): <span class="type">TreeType</span> = &#123;</span><br><span class="line">    <span class="comment">// 用来对比执行规则前后，初始的plan有无变化</span></span><br><span class="line">    <span class="keyword">var</span> curPlan = plan</span><br><span class="line">    <span class="keyword">val</span> queryExecutionMetrics = <span class="type">RuleExecutor</span>.queryExecutionMeter</span><br><span class="line"></span><br><span class="line">    batches.foreach &#123; batch =&gt;</span><br><span class="line">      <span class="keyword">val</span> batchStartPlan = curPlan</span><br><span class="line">      <span class="keyword">var</span> iteration = <span class="number">1</span></span><br><span class="line">      <span class="keyword">var</span> lastPlan = curPlan</span><br><span class="line">      <span class="keyword">var</span> <span class="keyword">continue</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// Run until fix point (or the max number of iterations as specified in the strategy.</span></span><br><span class="line">      <span class="comment">// 执行直到达到稳定点或者最大迭代次数</span></span><br><span class="line">      <span class="keyword">while</span> (<span class="keyword">continue</span>) &#123;</span><br><span class="line">        curPlan = batch.rules.foldLeft(curPlan) &#123;</span><br><span class="line">          <span class="keyword">case</span> (plan, rule) =&gt;</span><br><span class="line">            <span class="keyword">val</span> startTime = <span class="type">System</span>.nanoTime()</span><br><span class="line">            <span class="comment">// 执行rule，得到新的plan</span></span><br><span class="line">            <span class="keyword">val</span> result = rule(plan)</span><br><span class="line">            <span class="keyword">val</span> runTime = <span class="type">System</span>.nanoTime() - startTime</span><br><span class="line">            <span class="comment">// 判断rule是否起了作用</span></span><br><span class="line">            <span class="keyword">if</span> (!result.fastEquals(plan)) &#123;</span><br><span class="line">              queryExecutionMetrics.incNumEffectiveExecution(rule.ruleName)</span><br><span class="line">              queryExecutionMetrics.incTimeEffectiveExecutionBy(rule.ruleName, runTime)</span><br><span class="line">              logTrace(</span><br><span class="line">                <span class="string">s&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">                  |=== Applying Rule $&#123;rule.ruleName&#125; ===</span></span><br><span class="line"><span class="string">                  |$&#123;sideBySide(plan.treeString, result.treeString).mkString(&quot;</span>\<span class="string">n&quot;)&#125;</span></span><br><span class="line"><span class="string">                &quot;</span><span class="string">&quot;&quot;</span>.stripMargin)</span><br><span class="line">            &#125;</span><br><span class="line">            queryExecutionMetrics.incExecutionTimeBy(rule.ruleName, runTime)</span><br><span class="line">            queryExecutionMetrics.incNumExecution(rule.ruleName)</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Run the structural integrity checker against the plan after each rule.</span></span><br><span class="line">            <span class="keyword">if</span> (!isPlanIntegral(result)) &#123;</span><br><span class="line">              <span class="keyword">val</span> message = <span class="string">s&quot;After applying rule <span class="subst">$&#123;rule.ruleName&#125;</span> in batch <span class="subst">$&#123;batch.name&#125;</span>, &quot;</span> +</span><br><span class="line">                <span class="string">&quot;the structural integrity of the plan is broken.&quot;</span></span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">TreeNodeException</span>(result, message, <span class="literal">null</span>)</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            result</span><br><span class="line">        &#125;</span><br><span class="line">        iteration += <span class="number">1</span></span><br><span class="line">        <span class="comment">// 到达最大迭代次数, 不再执行优化</span></span><br><span class="line">        <span class="keyword">if</span> (iteration &gt; batch.strategy.maxIterations) &#123;</span><br><span class="line">          <span class="comment">// Only log if this is a rule that is supposed to run more than once.</span></span><br><span class="line">          <span class="comment">// 只对最大迭代次数大于1的情况打log</span></span><br><span class="line">          <span class="keyword">if</span> (iteration != <span class="number">2</span>) &#123;</span><br><span class="line">            <span class="keyword">val</span> message = <span class="string">s&quot;Max iterations (<span class="subst">$&#123;iteration - 1&#125;</span>) reached for batch <span class="subst">$&#123;batch.name&#125;</span>&quot;</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="type">Utils</span>.isTesting) &#123;</span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">TreeNodeException</span>(curPlan, message, <span class="literal">null</span>)</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              logWarning(message)</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">continue</span> = <span class="literal">false</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// plan不变了，到达稳定点，不再执行优化</span></span><br><span class="line">        <span class="keyword">if</span> (curPlan.fastEquals(lastPlan)) &#123;</span><br><span class="line">          logTrace(</span><br><span class="line">            <span class="string">s&quot;Fixed point reached for batch <span class="subst">$&#123;batch.name&#125;</span> after <span class="subst">$&#123;iteration - 1&#125;</span> iterations.&quot;</span>)</span><br><span class="line">          <span class="keyword">continue</span> = <span class="literal">false</span></span><br><span class="line">        &#125;</span><br><span class="line">        lastPlan = curPlan</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 该批次rule是否起作用</span></span><br><span class="line">      <span class="keyword">if</span> (!batchStartPlan.fastEquals(curPlan)) &#123;</span><br><span class="line">        logDebug(</span><br><span class="line">          <span class="string">s&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">            |=== Result of Batch $&#123;batch.name&#125; ===</span></span><br><span class="line"><span class="string">            |$&#123;sideBySide(batchStartPlan.treeString, curPlan.treeString).mkString(&quot;</span>\<span class="string">n&quot;)&#125;</span></span><br><span class="line"><span class="string">          &quot;</span><span class="string">&quot;&quot;</span>.stripMargin)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        logTrace(<span class="string">s&quot;Batch <span class="subst">$&#123;batch.name&#125;</span> has no effect.&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    curPlan</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="第四步-rule-plan"><a href="#第四步-rule-plan" class="headerlink" title="第四步:rule(plan)"></a>第四步:rule(plan)</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 输入为旧的plan，输出为新的plan，仅此而已。</span></span><br><span class="line"><span class="comment"> * 所以真正的逻辑在各个继承实现的rule里，analyze的过程也就是执行各个rule的过程</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Rule</span>[<span class="type">TreeType</span> &lt;: <span class="type">TreeNode</span>[_]] <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Name for this rule, automatically inferred based on class name. */</span></span><br><span class="line">  <span class="keyword">val</span> ruleName: <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> className = getClass.getName</span><br><span class="line">    <span class="keyword">if</span> (className endsWith <span class="string">&quot;$&quot;</span>) className.dropRight(<span class="number">1</span>) <span class="keyword">else</span> className</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(plan: <span class="type">TreeType</span>): <span class="type">TreeType</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="第五步-rule的集合-转换规则"><a href="#第五步-rule的集合-转换规则" class="headerlink" title="第五步:rule的集合(转换规则)"></a>第五步:rule的集合(转换规则)</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">lazy</span> <span class="keyword">val</span> batches: <span class="type">Seq</span>[<span class="type">Batch</span>] = <span class="type">Seq</span>(</span><br><span class="line">  <span class="type">Batch</span>(<span class="string">&quot;Hints&quot;</span>, fixedPoint,</span><br><span class="line">    <span class="keyword">new</span> <span class="type">ResolveHints</span>.<span class="type">ResolveBroadcastHints</span>(conf),</span><br><span class="line">    <span class="type">ResolveHints</span>.<span class="type">ResolveCoalesceHints</span>,</span><br><span class="line">    <span class="type">ResolveHints</span>.<span class="type">RemoveAllHints</span>),</span><br><span class="line">  <span class="type">Batch</span>(<span class="string">&quot;Simple Sanity Check&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">    <span class="type">LookupFunctions</span>),</span><br><span class="line">  <span class="type">Batch</span>(<span class="string">&quot;Substitution&quot;</span>, fixedPoint,</span><br><span class="line">    <span class="type">CTESubstitution</span>,</span><br><span class="line">    <span class="type">WindowsSubstitution</span>,</span><br><span class="line">    <span class="type">EliminateUnions</span>,</span><br><span class="line">    <span class="keyword">new</span> <span class="type">SubstituteUnresolvedOrdinals</span>(conf)),</span><br><span class="line">  <span class="type">Batch</span>(<span class="string">&quot;Resolution&quot;</span>, fixedPoint,</span><br><span class="line">    <span class="type">ResolveTableValuedFunctions</span> ::</span><br><span class="line">      <span class="comment">//通过catalog解析表名 </span></span><br><span class="line">      <span class="type">ResolveRelations</span> ::</span><br><span class="line">      <span class="comment">//解析从子节点的操作生成的属性，一般是别名引起的，比如a.id </span></span><br><span class="line">      <span class="type">ResolveReferences</span> ::</span><br><span class="line">      <span class="type">ResolveCreateNamedStruct</span> ::</span><br><span class="line">      <span class="type">ResolveDeserializer</span> ::</span><br><span class="line">      <span class="type">ResolveNewInstance</span> ::</span><br><span class="line">      <span class="type">ResolveUpCast</span> ::</span><br><span class="line">      <span class="type">ResolveGroupingAnalytics</span> ::</span><br><span class="line">      <span class="type">ResolvePivot</span> ::</span><br><span class="line">      <span class="type">ResolveOrdinalInOrderByAndGroupBy</span> ::</span><br><span class="line">      <span class="type">ResolveAggAliasInGroupBy</span> ::</span><br><span class="line">      <span class="type">ResolveMissingReferences</span> ::</span><br><span class="line">      <span class="type">ExtractGenerator</span> ::</span><br><span class="line">      <span class="type">ResolveGenerate</span> ::</span><br><span class="line">      <span class="comment">//解析函数</span></span><br><span class="line">      <span class="type">ResolveFunctions</span> ::</span><br><span class="line">      <span class="type">ResolveAliases</span> ::</span><br><span class="line">      <span class="type">ResolveSubquery</span> ::</span><br><span class="line">      <span class="type">ResolveSubqueryColumnAliases</span> ::</span><br><span class="line">      <span class="type">ResolveWindowOrder</span> ::</span><br><span class="line">      <span class="type">ResolveWindowFrame</span> ::</span><br><span class="line">      <span class="type">ResolveNaturalAndUsingJoin</span> ::</span><br><span class="line">      <span class="type">ResolveOutputRelation</span> ::</span><br><span class="line">      <span class="type">ExtractWindowExpressions</span> ::</span><br><span class="line">      <span class="comment">//解析全局的聚合函数，比如select sum(score) from table </span></span><br><span class="line">      <span class="type">GlobalAggregates</span> ::</span><br><span class="line">      <span class="type">ResolveAggregateFunctions</span> ::</span><br><span class="line">      <span class="type">TimeWindowing</span> ::</span><br><span class="line">      <span class="type">ResolveInlineTables</span>(conf) ::</span><br><span class="line">      <span class="comment">//解析having子句后面的聚合过滤条件，比如having sum(score) &gt; 400</span></span><br><span class="line">      <span class="type">ResolveHigherOrderFunctions</span>(catalog) ::</span><br><span class="line">      <span class="type">ResolveLambdaVariables</span>(conf) ::</span><br><span class="line">      <span class="type">ResolveTimeZone</span>(conf) ::</span><br><span class="line">      <span class="type">ResolveRandomSeed</span> ::</span><br><span class="line">      <span class="type">TypeCoercion</span>.typeCoercionRules(conf) ++</span><br><span class="line">      extendedResolutionRules: _*),</span><br><span class="line">  <span class="type">Batch</span>(<span class="string">&quot;Post-Hoc Resolution&quot;</span>, <span class="type">Once</span>, postHocResolutionRules: _*),</span><br><span class="line">  <span class="type">Batch</span>(<span class="string">&quot;View&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">    <span class="type">AliasViewChild</span>(conf)),</span><br><span class="line">  <span class="type">Batch</span>(<span class="string">&quot;Nondeterministic&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">    <span class="type">PullOutNondeterministic</span>),</span><br><span class="line">  <span class="type">Batch</span>(<span class="string">&quot;UDF&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">    <span class="type">HandleNullInputsForUDF</span>),</span><br><span class="line">  <span class="type">Batch</span>(<span class="string">&quot;FixNullability&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">    <span class="type">FixNullability</span>),</span><br><span class="line">  <span class="type">Batch</span>(<span class="string">&quot;Subquery&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">    <span class="type">UpdateOuterReferences</span>),</span><br><span class="line">  <span class="type">Batch</span>(<span class="string">&quot;Cleanup&quot;</span>, fixedPoint,</span><br><span class="line">    <span class="type">CleanupAliases</span>))</span><br></pre></td></tr></table></figure>

<h3 id="第六步-ResolveRelations-通过catalog解析表名"><a href="#第六步-ResolveRelations-通过catalog解析表名" class="headerlink" title="第六步:ResolveRelations 通过catalog解析表名"></a>第六步:ResolveRelations 通过catalog解析表名</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ResolveRelations</span> <span class="keyword">extends</span> <span class="title">Rule</span>[<span class="type">LogicalPlan</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If the unresolved relation is running directly on files, we just return the original</span></span><br><span class="line">  <span class="comment">// UnresolvedRelation, the plan will get resolved later. Else we look up the table from catalog</span></span><br><span class="line">  <span class="comment">// and change the default database name(in AnalysisContext) if it is a view.</span></span><br><span class="line">  <span class="comment">// We usually look up a table from the default database if the table identifier has an empty</span></span><br><span class="line">  <span class="comment">// database part, for a view the default database should be the currentDb when the view was</span></span><br><span class="line">  <span class="comment">// created. When the case comes to resolving a nested view, the view may have different default</span></span><br><span class="line">  <span class="comment">// database with that the referenced view has, so we need to use</span></span><br><span class="line">  <span class="comment">// `AnalysisContext.defaultDatabase` to track the current default database.</span></span><br><span class="line">  <span class="comment">// When the relation we resolve is a view, we fetch the view.desc(which is a CatalogTable), and</span></span><br><span class="line">  <span class="comment">// then set the value of `CatalogTable.viewDefaultDatabase` to</span></span><br><span class="line">  <span class="comment">// `AnalysisContext.defaultDatabase`, we look up the relations that the view references using</span></span><br><span class="line">  <span class="comment">// the default database.</span></span><br><span class="line">  <span class="comment">// For example:</span></span><br><span class="line">  <span class="comment">// |- view1 (defaultDatabase = db1)</span></span><br><span class="line">  <span class="comment">//   |- operator</span></span><br><span class="line">  <span class="comment">//     |- table2 (defaultDatabase = db1)</span></span><br><span class="line">  <span class="comment">//     |- view2 (defaultDatabase = db2)</span></span><br><span class="line">  <span class="comment">//        |- view3 (defaultDatabase = db3)</span></span><br><span class="line">  <span class="comment">//   |- view4 (defaultDatabase = db4)</span></span><br><span class="line">  <span class="comment">// In this case, the view `view1` is a nested view, it directly references `table2`, `view2`</span></span><br><span class="line">  <span class="comment">// and `view4`, the view `view2` references `view3`. On resolving the table, we look up the</span></span><br><span class="line">  <span class="comment">// relations `table2`, `view2`, `view4` using the default database `db1`, and look up the</span></span><br><span class="line">  <span class="comment">// relation `view3` using the default database `db2`.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Note this is compatible with the views defined by older versions of Spark(before 2.2), which</span></span><br><span class="line">  <span class="comment">// have empty defaultDatabase and all the relations in viewText have database part defined.</span></span><br><span class="line">  <span class="comment">// 在Catalog中匹配table信息</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">resolveRelation</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">LogicalPlan</span> = plan <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="comment">//不是这种情况 select * from parquet.`/path/to/query`  </span></span><br><span class="line">    <span class="keyword">case</span> u: <span class="type">UnresolvedRelation</span> <span class="keyword">if</span> !isRunningDirectlyOnFiles(u.tableIdentifier) =&gt;</span><br><span class="line">      <span class="comment">// 默认数据库</span></span><br><span class="line">      <span class="keyword">val</span> defaultDatabase = <span class="type">AnalysisContext</span>.get.defaultDatabase</span><br><span class="line">      <span class="comment">// 在Catalog中查找</span></span><br><span class="line">      <span class="keyword">val</span> foundRelation = lookupTableFromCatalog(u, defaultDatabase)</span><br><span class="line">      resolveRelation(foundRelation)</span><br><span class="line">    <span class="comment">// The view&#x27;s child should be a logical plan parsed from the `desc.viewText`, the variable</span></span><br><span class="line">    <span class="comment">// `viewText` should be defined, or else we throw an error on the generation of the View</span></span><br><span class="line">    <span class="comment">// operator.</span></span><br><span class="line">    <span class="keyword">case</span> view @ <span class="type">View</span>(desc, _, child) <span class="keyword">if</span> !child.resolved =&gt;</span><br><span class="line">      <span class="comment">// Resolve all the UnresolvedRelations and Views in the child.</span></span><br><span class="line">      <span class="keyword">val</span> newChild = <span class="type">AnalysisContext</span>.withAnalysisContext(desc.viewDefaultDatabase) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="type">AnalysisContext</span>.get.nestedViewDepth &gt; conf.maxNestedViewDepth) &#123;</span><br><span class="line">          view.failAnalysis(<span class="string">s&quot;The depth of view <span class="subst">$&#123;view.desc.identifier&#125;</span> exceeds the maximum &quot;</span> +</span><br><span class="line">            <span class="string">s&quot;view resolution depth (<span class="subst">$&#123;conf.maxNestedViewDepth&#125;</span>). Analysis is aborted to &quot;</span> +</span><br><span class="line">            <span class="string">s&quot;avoid errors. Increase the value of <span class="subst">$&#123;SQLConf.MAX_NESTED_VIEW_DEPTH.key&#125;</span> to work &quot;</span> +</span><br><span class="line">            <span class="string">&quot;around this.&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        executeSameContext(child)</span><br><span class="line">      &#125;</span><br><span class="line">      view.copy(child = newChild)</span><br><span class="line">    <span class="keyword">case</span> p @ <span class="type">SubqueryAlias</span>(_, view: <span class="type">View</span>) =&gt;</span><br><span class="line">      <span class="keyword">val</span> newChild = resolveRelation(view)</span><br><span class="line">      p.copy(child = newChild)</span><br><span class="line">    <span class="keyword">case</span> _ =&gt; plan</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// rule的入口，resolveOperatorsUp 后序遍历树，并对每个节点应用rule</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">LogicalPlan</span> = plan.resolveOperatorsUp &#123;</span><br><span class="line">    <span class="keyword">case</span> i @ <span class="type">InsertIntoTable</span>(u: <span class="type">UnresolvedRelation</span>, parts, child, _, _) <span class="keyword">if</span> child.resolved =&gt;</span><br><span class="line">      <span class="type">EliminateSubqueryAliases</span>(lookupTableFromCatalog(u)) <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> v: <span class="type">View</span> =&gt;</span><br><span class="line">          u.failAnalysis(<span class="string">s&quot;Inserting into a view is not allowed. View: <span class="subst">$&#123;v.desc.identifier&#125;</span>.&quot;</span>)</span><br><span class="line">        <span class="keyword">case</span> other =&gt; i.copy(table = other)</span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment">// 匹配到UnresolvedRelation</span></span><br><span class="line">    <span class="keyword">case</span> u: <span class="type">UnresolvedRelation</span> =&gt; resolveRelation(u)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Look up the table with the given name from catalog. The database we used is decided by the</span></span><br><span class="line">  <span class="comment">// precedence:</span></span><br><span class="line">  <span class="comment">// 1. Use the database part of the table identifier, if it is defined;</span></span><br><span class="line">  <span class="comment">// 2. Use defaultDatabase, if it is defined(In this case, no temporary objects can be used,</span></span><br><span class="line">  <span class="comment">//    and the default database is only used to look up a view);</span></span><br><span class="line">  <span class="comment">// 3. Use the currentDb of the SessionCatalog.</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">lookupTableFromCatalog</span></span>(</span><br><span class="line">    u: <span class="type">UnresolvedRelation</span>,</span><br><span class="line">    defaultDatabase: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">None</span>): <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> tableIdentWithDb = u.tableIdentifier.copy(</span><br><span class="line">      database = u.tableIdentifier.database.orElse(defaultDatabase))</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      catalog.lookupRelation(tableIdentWithDb)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="comment">// 如果没有找到表，便会抛出异常了</span></span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">NoSuchTableException</span> =&gt;</span><br><span class="line">        u.failAnalysis(<span class="string">s&quot;Table or view not found: <span class="subst">$&#123;tableIdentWithDb.unquotedString&#125;</span>&quot;</span>, e)</span><br><span class="line">      <span class="comment">// If the database is defined and that database is not found, throw an AnalysisException.</span></span><br><span class="line">      <span class="comment">// Note that if the database is not defined, it is possible we are looking up a temp view.</span></span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">NoSuchDatabaseException</span> =&gt;</span><br><span class="line">        u.failAnalysis(<span class="string">s&quot;Table or view not found: <span class="subst">$&#123;tableIdentWithDb.unquotedString&#125;</span>, the &quot;</span> +</span><br><span class="line">          <span class="string">s&quot;database <span class="subst">$&#123;e.db&#125;</span> doesn&#x27;t exist.&quot;</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//相当于后序遍历树</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resolveOperatorsUp</span></span>(rule: <span class="type">PartialFunction</span>[<span class="type">LogicalPlan</span>, <span class="type">LogicalPlan</span>]): <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line">  <span class="comment">//plan是否已经被处理过</span></span><br><span class="line">  <span class="keyword">if</span> (!analyzed) &#123;</span><br><span class="line">    <span class="type">AnalysisHelper</span>.allowInvokingTransformsInAnalyzer &#123;</span><br><span class="line">      <span class="comment">//递归调用,优先处理它的子节点</span></span><br><span class="line">      <span class="keyword">val</span> afterRuleOnChildren = mapChildren(_.resolveOperatorsUp(rule))</span><br><span class="line">      <span class="keyword">if</span> (self fastEquals afterRuleOnChildren) &#123;</span><br><span class="line">        <span class="type">CurrentOrigin</span>.withOrigin(origin) &#123;</span><br><span class="line">          rule.applyOrElse(self, identity[<span class="type">LogicalPlan</span>])</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">CurrentOrigin</span>.withOrigin(origin) &#123;</span><br><span class="line">          rule.applyOrElse(afterRuleOnChildren, identity[<span class="type">LogicalPlan</span>])</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    self</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//catalog 存储了spark sql的所有数据表信息</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SessionCatalog</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    externalCatalogBuilder: (</span>) <span class="title">=&gt;</span> <span class="title">ExternalCatalog</span>,</span></span><br><span class="line"><span class="class">    <span class="title">globalTempViewManagerBuilder</span></span>: () =&gt; <span class="type">GlobalTempViewManager</span>,</span><br><span class="line">    functionRegistry: <span class="type">FunctionRegistry</span>,</span><br><span class="line">    conf: <span class="type">SQLConf</span>,</span><br><span class="line">    hadoopConf: <span class="type">Configuration</span>,</span><br><span class="line">    parser: <span class="type">ParserInterface</span>,</span><br><span class="line">    functionResourceLoader: <span class="type">FunctionResourceLoader</span>) <span class="keyword">extends</span> <span class="type">Logging</span> &#123;</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lookupRelation</span></span>(name: <span class="type">TableIdentifier</span>): <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line">    synchronized &#123;</span><br><span class="line">      <span class="keyword">val</span> db = formatDatabaseName(name.database.getOrElse(currentDb))</span><br><span class="line">      <span class="keyword">val</span> table = formatTableName(name.table)</span><br><span class="line">      <span class="comment">//若db等于globalTempViewManager.database</span></span><br><span class="line">      <span class="keyword">if</span> (db == globalTempViewManager.database) &#123;</span><br><span class="line">        <span class="comment">//globalTempViewManager(HashMap[String, LogicalPlan])维护了一个全局viewName和其元数据LogicalPlan的映射</span></span><br><span class="line">        globalTempViewManager.get(table).map &#123; viewDef =&gt;</span><br><span class="line">          <span class="type">SubqueryAlias</span>(table, db, viewDef)</span><br><span class="line">        &#125;.getOrElse(<span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NoSuchTableException</span>(db, table))</span><br><span class="line">      <span class="comment">//若database已定义，且临时表中未有此table</span></span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (name.database.isDefined || !tempViews.contains(table)) &#123;</span><br><span class="line">        <span class="comment">//从externalCatalog(如hive)中获取table对应的元数据信息metadata:CatalogTable，</span></span><br><span class="line">        <span class="comment">//此对象包含了table对应的类型（table（内部还是外部表），view）、存储格式、字段shema信息等</span></span><br><span class="line">        <span class="keyword">val</span> metadata = externalCatalog.getTable(db, table)</span><br><span class="line">        <span class="comment">//返回的table是View类型</span></span><br><span class="line">        <span class="keyword">if</span> (metadata.tableType == <span class="type">CatalogTableType</span>.<span class="type">VIEW</span>) &#123;</span><br><span class="line">          <span class="keyword">val</span> viewText = metadata.viewText.getOrElse(sys.error(<span class="string">&quot;Invalid view without text.&quot;</span>))</span><br><span class="line">          <span class="comment">// The relation is a view, so we wrap the relation by:</span></span><br><span class="line">          <span class="comment">// 1. Add a [[View]] operator over the relation to keep track of the view desc;</span></span><br><span class="line">          <span class="comment">// 2. Wrap the logical plan in a [[SubqueryAlias]] which tracks the name of the view.</span></span><br><span class="line">          <span class="comment">/**</span></span><br><span class="line"><span class="comment">           * 构造View对象（包括将viewText通过parser模块解析成语法树），并传入构造一个SubqueryAlias返回</span></span><br><span class="line"><span class="comment">           * </span></span><br><span class="line"><span class="comment">           * 说明此table名对应的就是一个如hive的table表，通过metadata、数据和分区列的schema构造了CatalogRelation，</span></span><br><span class="line"><span class="comment">           * 并以此tableRelation构造SubqueryAlias返回。</span></span><br><span class="line"><span class="comment">           * </span></span><br><span class="line"><span class="comment">           * 这里就可以看出从一个未绑定的UnresolvedRelation到通过catalog替换的过程。</span></span><br><span class="line"><span class="comment">           */</span></span><br><span class="line">          <span class="keyword">val</span> child = <span class="type">View</span>(</span><br><span class="line">            desc = metadata,</span><br><span class="line">            output = metadata.schema.toAttributes,</span><br><span class="line">            child = parser.parsePlan(viewText))</span><br><span class="line">          <span class="type">SubqueryAlias</span>(table, db, child)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="type">SubqueryAlias</span>(table, db, <span class="type">UnresolvedCatalogRelation</span>(metadata))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//明是个session级别的临时表，从tempTables获取到包含元数据信息的LogicalPlan 并构造SubqueryAlias返回</span></span><br><span class="line">        <span class="type">SubqueryAlias</span>(table, tempViews(table))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>总结：</strong><br>Analyzer 分析前后的 LogicalPlan 对比</p>
<p><img src="https://img-blog.csdnimg.cn/20190129155353223.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW9qaWFvNTIxNzY1MTQ2NTE0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>分析后，每张表对应的字段集，字段类型，数据存储位置都已确定。Project 与 Filter 操作的字段类型以及在表中的位置也已确定。</p>
<p>有了这些信息，已经可以直接将该 LogicalPlan 转换为 Physical Plan 进行执行。</p>
<p>但是由于不同用户提交的 SQL 质量不同，直接执行会造成不同用户提交的语义相同的不同 SQL 执行效率差距甚远。换句话说，如果要保证较高的执行效率，用户需要做大量的 SQL 优化，使用体验大大降低。</p>
<p>为了尽可能保证无论用户是否熟悉 SQL 优化，提交的 SQL 质量如何， Spark SQL 都能以较高效率执行，还需在执行前进行 LogicalPlan 优化。</p>
<h2 id="2-3-Optimizer优化器"><a href="#2-3-Optimizer优化器" class="headerlink" title="2.3 Optimizer优化器"></a>2.3 Optimizer优化器</h2><p>optimizer是catalyst中关键的一个部分，提供对sql查询的一个优化。optimizer的主要职责是针对Analyzer的resolved logical plan，根据不同的batch优化策略)，来对执行计划树进行优化，优化逻辑计划节点(Logical Plan)以及表达式(Expression)，同时，此部分也是转换成物理执行计划的前置。</p>
<h3 id="第一步-sparkSession-sessionState-optimizer-execute-withCachedData-方法"><a href="#第一步-sparkSession-sessionState-optimizer-execute-withCachedData-方法" class="headerlink" title="第一步:sparkSession.sessionState.optimizer.execute(withCachedData)方法"></a>第一步:sparkSession.sessionState.optimizer.execute(withCachedData)方法</h3><p>源码地址：org.apache.spark.sql.catalyst.optimizer.Optimizer.scala</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Optimizer的主要职责是将Analyzer给Resolved的Logical Plan根据不同的优化策略Batch，</span></span><br><span class="line"><span class="comment"> * 来对语法树进行优化，优化逻辑计划节点(Logical Plan)以及表达式(Expression)， 也是转换成物理执行计划的前置。</span></span><br><span class="line"><span class="comment"> * 它的工作原理和analyzer一致，也是通过其下的batch里面的Rule[LogicalPlan]来进行处理的</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Optimizer</span>(<span class="params">sessionCatalog: <span class="type">SessionCatalog</span></span>)</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">RuleExecutor</span>[<span class="type">LogicalPlan</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Check for structural integrity of the plan in test mode. Currently we only check if a plan is</span></span><br><span class="line">  <span class="comment">// still resolved after the execution of each rule.</span></span><br><span class="line">  <span class="keyword">override</span> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">isPlanIntegral</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">    !<span class="type">Utils</span>.isTesting || plan.resolved</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">fixedPoint</span> </span>= <span class="type">FixedPoint</span>(<span class="type">SQLConf</span>.get.optimizerMaxIterations)</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Defines the default rule batches in the Optimizer.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Implementations of this class should override this method, and [[nonExcludableRules]] if</span></span><br><span class="line"><span class="comment">   * necessary, instead of [[batches]]. The rule batches that eventually run in the Optimizer,</span></span><br><span class="line"><span class="comment">   * i.e., returned by [[batches]], will be (defaultBatches - (excludedRules - nonExcludableRules)).</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">defaultBatches</span></span>: <span class="type">Seq</span>[<span class="type">Batch</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> operatorOptimizationRuleSet =</span><br><span class="line">      <span class="type">Seq</span>(</span><br><span class="line">        <span class="comment">// Operator push down</span></span><br><span class="line">        <span class="type">PushProjectionThroughUnion</span>, <span class="comment">//谓词下推</span></span><br><span class="line">        <span class="type">ReorderJoin</span>,</span><br><span class="line">        <span class="type">EliminateOuterJoin</span>,</span><br><span class="line">        <span class="type">PushPredicateThroughJoin</span>,</span><br><span class="line">        <span class="type">PushDownPredicate</span>,</span><br><span class="line">        <span class="type">LimitPushDown</span>,</span><br><span class="line">        <span class="type">ColumnPruning</span>, <span class="comment">//列剪裁</span></span><br><span class="line">        <span class="type">InferFiltersFromConstraints</span>,</span><br><span class="line">        <span class="comment">// Operator combine</span></span><br><span class="line">        <span class="type">CollapseRepartition</span>,</span><br><span class="line">        <span class="type">CollapseProject</span>,</span><br><span class="line">        <span class="type">CollapseWindow</span>,</span><br><span class="line">        <span class="type">CombineFilters</span>, <span class="comment">//合并filter</span></span><br><span class="line">        <span class="type">CombineLimits</span>, <span class="comment">//合并limit</span></span><br><span class="line">        <span class="type">CombineUnions</span>,</span><br><span class="line">        <span class="comment">// Constant folding and strength reduction</span></span><br><span class="line">        <span class="type">NullPropagation</span>, <span class="comment">//null处理，NULL容易产生数据倾斜</span></span><br><span class="line">        <span class="type">ConstantPropagation</span>,</span><br><span class="line">        <span class="type">FoldablePropagation</span>,</span><br><span class="line">        <span class="type">OptimizeIn</span>, <span class="comment">// 关键字in的优化，替代为InSet</span></span><br><span class="line">        <span class="type">ConstantFolding</span>, <span class="comment">//针对常量的优化，在这里会直接计算可以获得的常量</span></span><br><span class="line">        <span class="type">ReorderAssociativeOperator</span>,</span><br><span class="line">        <span class="type">LikeSimplification</span>, <span class="comment">//like的简单优化</span></span><br><span class="line">        <span class="comment">//简化过滤条件，比如true and score &gt; 0 直接替换成score &gt; </span></span><br><span class="line">        <span class="type">BooleanSimplification</span>,</span><br><span class="line">        <span class="comment">//简化filter，比如where 1=1 或者where 1=2，前者直接去掉这个过滤</span></span><br><span class="line">        <span class="type">SimplifyConditionals</span>,</span><br><span class="line">        <span class="type">RemoveDispensableExpressions</span>,</span><br><span class="line">        <span class="type">SimplifyBinaryComparison</span>,</span><br><span class="line">        <span class="type">PruneFilters</span>,</span><br><span class="line">        <span class="type">EliminateSorts</span>,</span><br><span class="line">        <span class="comment">//简化转换，比如两个比较字段的数据类型是一样的，就不需要转换</span></span><br><span class="line">        <span class="type">SimplifyCasts</span>,</span><br><span class="line">        <span class="comment">//简化大小写转换，比如Upper(Upper(&#x27;a&#x27;))转为认为是Upper(&#x27;a&#x27;)</span></span><br><span class="line">        <span class="type">SimplifyCaseConversionExpressions</span>,</span><br><span class="line">        <span class="type">RewriteCorrelatedScalarSubquery</span>,</span><br><span class="line">        <span class="type">EliminateSerialization</span>,</span><br><span class="line">        <span class="type">RemoveRedundantAliases</span>,</span><br><span class="line">        <span class="type">RemoveRedundantProject</span>,</span><br><span class="line">        <span class="type">SimplifyExtractValueOps</span>,</span><br><span class="line">        <span class="type">CombineConcats</span>) ++</span><br><span class="line">        extendedOperatorOptimizationRules</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> operatorOptimizationBatch: <span class="type">Seq</span>[<span class="type">Batch</span>] = &#123;</span><br><span class="line">      <span class="keyword">val</span> rulesWithoutInferFiltersFromConstraints =</span><br><span class="line">        operatorOptimizationRuleSet.filterNot(_ == <span class="type">InferFiltersFromConstraints</span>)</span><br><span class="line">      <span class="type">Batch</span>(<span class="string">&quot;Operator Optimization before Inferring Filters&quot;</span>, fixedPoint, <span class="comment">//精度优化</span></span><br><span class="line">        rulesWithoutInferFiltersFromConstraints: _*) ::</span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;Infer Filters&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">          <span class="type">InferFiltersFromConstraints</span>) ::</span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;Operator Optimization after Inferring Filters&quot;</span>, fixedPoint,</span><br><span class="line">          rulesWithoutInferFiltersFromConstraints: _*) :: <span class="type">Nil</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    (<span class="type">Batch</span>(<span class="string">&quot;Eliminate Distinct&quot;</span>, <span class="type">Once</span>, <span class="type">EliminateDistinct</span>) ::</span><br><span class="line">      <span class="comment">// Technically some of the rules in Finish Analysis are not optimizer rules and belong more</span></span><br><span class="line">      <span class="comment">// in the analyzer, because they are needed for correctness (e.g. ComputeCurrentTime).</span></span><br><span class="line">      <span class="comment">// However, because we also use the analyzer to canonicalized queries (for view definition),</span></span><br><span class="line">      <span class="comment">// we do not eliminate subqueries or compute current time in the analyzer.</span></span><br><span class="line">      <span class="type">Batch</span>(<span class="string">&quot;Finish Analysis&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">        <span class="type">EliminateSubqueryAliases</span>,</span><br><span class="line">        <span class="type">EliminateView</span>,</span><br><span class="line">        <span class="type">ReplaceExpressions</span>,</span><br><span class="line">        <span class="type">ComputeCurrentTime</span>,</span><br><span class="line">        <span class="type">GetCurrentDatabase</span>(sessionCatalog),</span><br><span class="line">        <span class="type">RewriteDistinctAggregates</span>,</span><br><span class="line">        <span class="type">ReplaceDeduplicateWithAggregate</span>) ::</span><br><span class="line">        <span class="comment">//////////////////////////////////////////////////////////////////////////////////////////</span></span><br><span class="line">        <span class="comment">// Optimizer rules start here</span></span><br><span class="line">        <span class="comment">//////////////////////////////////////////////////////////////////////////////////////////</span></span><br><span class="line">        <span class="comment">// - Do the first call of CombineUnions before starting the major Optimizer rules,</span></span><br><span class="line">        <span class="comment">//   since it can reduce the number of iteration and the other rules could add/move</span></span><br><span class="line">        <span class="comment">//   extra operators between two adjacent Union operators.</span></span><br><span class="line">        <span class="comment">// - Call CombineUnions again in Batch(&quot;Operator Optimizations&quot;),</span></span><br><span class="line">        <span class="comment">//   since the other rules might make two separate Unions operators adjacent.</span></span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;Union&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">          <span class="type">CombineUnions</span>) ::</span><br><span class="line">        <span class="comment">// run this once earlier. this might simplify the plan and reduce cost of optimizer.</span></span><br><span class="line">        <span class="comment">// for example, a query such as Filter(LocalRelation) would go through all the heavy</span></span><br><span class="line">        <span class="comment">// optimizer rules that are triggered when there is a filter</span></span><br><span class="line">        <span class="comment">// (e.g. InferFiltersFromConstraints). if we run this batch earlier, the query becomes just</span></span><br><span class="line">        <span class="comment">// LocalRelation and does not trigger many rules</span></span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;LocalRelation early&quot;</span>, fixedPoint,</span><br><span class="line">          <span class="type">ConvertToLocalRelation</span>,</span><br><span class="line">          <span class="type">PropagateEmptyRelation</span>) ::</span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;Pullup Correlated Expressions&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">          <span class="type">PullupCorrelatedPredicates</span>) ::</span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;Subquery&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">          <span class="type">OptimizeSubqueries</span>) ::</span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;Replace Operators&quot;</span>, fixedPoint,</span><br><span class="line">          <span class="type">RewriteExceptAll</span>,</span><br><span class="line">          <span class="type">RewriteIntersectAll</span>,</span><br><span class="line">          <span class="type">ReplaceIntersectWithSemiJoin</span>,</span><br><span class="line">          <span class="type">ReplaceExceptWithFilter</span>,</span><br><span class="line">          <span class="type">ReplaceExceptWithAntiJoin</span>,</span><br><span class="line">          <span class="type">ReplaceDistinctWithAggregate</span>) :: <span class="comment">// aggregate替换distinct</span></span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;Aggregate&quot;</span>, fixedPoint,</span><br><span class="line">          <span class="type">RemoveLiteralFromGroupExpressions</span>,</span><br><span class="line">          <span class="type">RemoveRepetitionFromGroupExpressions</span>) :: <span class="type">Nil</span> ++</span><br><span class="line">        operatorOptimizationBatch) :+</span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;Join Reorder&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">          <span class="type">CostBasedJoinReorder</span>) :+</span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;Remove Redundant Sorts&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">          <span class="type">RemoveRedundantSorts</span>) :+</span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;Decimal Optimizations&quot;</span>, fixedPoint,</span><br><span class="line">          <span class="type">DecimalAggregates</span>) :+</span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;Object Expressions Optimization&quot;</span>, fixedPoint,</span><br><span class="line">          <span class="type">EliminateMapObjects</span>,</span><br><span class="line">          <span class="type">CombineTypedFilters</span>) :+</span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;LocalRelation&quot;</span>, fixedPoint,</span><br><span class="line">          <span class="type">ConvertToLocalRelation</span>,</span><br><span class="line">          <span class="type">PropagateEmptyRelation</span>) :+</span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;Extract PythonUDF From JoinCondition&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">          <span class="type">PullOutPythonUDFInJoinCondition</span>) :+</span><br><span class="line">        <span class="comment">// The following batch should be executed after batch &quot;Join Reorder&quot; &quot;LocalRelation&quot; and</span></span><br><span class="line">        <span class="comment">// &quot;Extract PythonUDF From JoinCondition&quot;.</span></span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;Check Cartesian Products&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">          <span class="type">CheckCartesianProducts</span>) :+</span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;RewriteSubquery&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">          <span class="type">RewritePredicateSubquery</span>,</span><br><span class="line">          <span class="type">ColumnPruning</span>,<span class="comment">//去掉一些用不上的列</span></span><br><span class="line">          <span class="type">CollapseProject</span>,</span><br><span class="line">          <span class="type">RemoveRedundantProject</span>) :+</span><br><span class="line">        <span class="type">Batch</span>(<span class="string">&quot;UpdateAttributeReferences&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">          <span class="type">UpdateNullabilityInAttributeReferences</span>)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h3 id="第二步-PushPredicateThroughJoin的关键代码"><a href="#第二步-PushPredicateThroughJoin的关键代码" class="headerlink" title="第二步:PushPredicateThroughJoin的关键代码"></a>第二步:PushPredicateThroughJoin的关键代码</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">PushPredicateThroughJoin</span> <span class="keyword">extends</span> <span class="title">Rule</span>[<span class="type">LogicalPlan</span>] <span class="keyword">with</span> <span class="title">PredicateHelper</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">LogicalPlan</span> = plan transform &#123;</span><br><span class="line">    <span class="comment">// push the where condition down into join filter</span></span><br><span class="line">   <span class="comment">// match 这个结构  </span></span><br><span class="line">  <span class="keyword">case</span> f @ <span class="type">Filter</span>(filterCondition, <span class="type">Join</span>(left, right, joinType, joinCondition)) =&gt;</span><br><span class="line">      <span class="keyword">val</span> (leftFilterConditions, rightFilterConditions, commonFilterCondition) =</span><br><span class="line">        split(splitConjunctivePredicates(filterCondition), left, right)</span><br><span class="line">      joinType <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="comment">// 是 inner join</span></span><br><span class="line">        <span class="keyword">case</span> _: <span class="type">InnerLike</span> =&gt;</span><br><span class="line">          <span class="comment">// push down the single side `where` condition into respective sides</span></span><br><span class="line">          <span class="comment">// left下推为Filter</span></span><br><span class="line">          <span class="keyword">val</span> newLeft = leftFilterConditions.</span><br><span class="line">            reduceLeftOption(<span class="type">And</span>).map(<span class="type">Filter</span>(_, left)).getOrElse(left)</span><br><span class="line">          <span class="comment">// right下推为Filter</span></span><br><span class="line">          <span class="keyword">val</span> newRight = rightFilterConditions.</span><br><span class="line">            reduceLeftOption(<span class="type">And</span>).map(<span class="type">Filter</span>(_, right)).getOrElse(right)</span><br><span class="line">          <span class="keyword">val</span> (newJoinConditions, others) =</span><br><span class="line">            commonFilterCondition.partition(canEvaluateWithinJoin)</span><br><span class="line">          <span class="keyword">val</span> newJoinCond = (newJoinConditions ++ joinCondition).reduceLeftOption(<span class="type">And</span>)</span><br><span class="line">          <span class="comment">// 最终的优化结果</span></span><br><span class="line">          <span class="keyword">val</span> join = <span class="type">Join</span>(newLeft, newRight, joinType, newJoinCond)</span><br><span class="line">          <span class="keyword">if</span> (others.nonEmpty) &#123;</span><br><span class="line">            <span class="type">Filter</span>(others.reduceLeft(<span class="type">And</span>), join)</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            join</span><br><span class="line">          &#125;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">RightOuter</span> =&gt;</span><br><span class="line">          <span class="comment">// push down the right side only `where` condition</span></span><br><span class="line">          <span class="keyword">val</span> newLeft = left</span><br><span class="line">          <span class="keyword">val</span> newRight = rightFilterConditions.</span><br><span class="line">            reduceLeftOption(<span class="type">And</span>).map(<span class="type">Filter</span>(_, right)).getOrElse(right)</span><br><span class="line">          <span class="keyword">val</span> newJoinCond = joinCondition</span><br><span class="line">          <span class="keyword">val</span> newJoin = <span class="type">Join</span>(newLeft, newRight, <span class="type">RightOuter</span>, newJoinCond)</span><br><span class="line"></span><br><span class="line">          (leftFilterConditions ++ commonFilterCondition).</span><br><span class="line">            reduceLeftOption(<span class="type">And</span>).map(<span class="type">Filter</span>(_, newJoin)).getOrElse(newJoin)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">LeftOuter</span> | <span class="type">LeftExistence</span>(_) =&gt;</span><br><span class="line">          <span class="comment">// push down the left side only `where` condition</span></span><br><span class="line">          <span class="keyword">val</span> newLeft = leftFilterConditions.</span><br><span class="line">            reduceLeftOption(<span class="type">And</span>).map(<span class="type">Filter</span>(_, left)).getOrElse(left)</span><br><span class="line">          <span class="keyword">val</span> newRight = right</span><br><span class="line">          <span class="keyword">val</span> newJoinCond = joinCondition</span><br><span class="line">          <span class="keyword">val</span> newJoin = <span class="type">Join</span>(newLeft, newRight, joinType, newJoinCond)</span><br><span class="line"></span><br><span class="line">          (rightFilterConditions ++ commonFilterCondition).</span><br><span class="line">            reduceLeftOption(<span class="type">And</span>).map(<span class="type">Filter</span>(_, newJoin)).getOrElse(newJoin)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">FullOuter</span> =&gt; f <span class="comment">// DO Nothing for Full Outer Join</span></span><br><span class="line">        <span class="keyword">case</span> <span class="type">NaturalJoin</span>(_) =&gt; sys.error(<span class="string">&quot;Untransformed NaturalJoin node&quot;</span>)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">UsingJoin</span>(_, _) =&gt; sys.error(<span class="string">&quot;Untransformed Using join node&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">  ......</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>总结 :</p>
<p>Spark SQL 目前的优化主要是基于规则的优化，即 RBO （Rule-based optimization）</p>
<ul>
<li>每个优化以 Rule 的形式存在，每条 Rule 都是对 Analyzed Plan 的等价转换</li>
<li>RBO 设计良好，易于扩展，新的规则可以非常方便地嵌入进 Optimizer</li>
<li>RBO 目前已经足够好，但仍然需要更多规则来 cover 更多的场景</li>
<li>优化思路主要是减少参与计算的数据量以及计算本身的代价</li>
</ul>
<p><strong>PushdownPredicate</strong></p>
<p>PushdownPredicate 是最常见的用于减少参与计算的数据量的方法。</p>
<p>直接对两表进行 Join 操作，然后再 进行 Filter 操作。引入 PushdownPredicate 后，可先对两表进行 Filter 再进行 Join</p>
<p><img src="https://img-blog.csdnimg.cn/2019013014250169.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW9qaWFvNTIxNzY1MTQ2NTE0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>当 Filter 可过滤掉大部分数据时，参与 Join 的数据量大大减少，从而使得 Join 操作速度大大提高。</p>
<p>这里需要说明的是，此处的优化是 LogicalPlan 的优化，从逻辑上保证了将 Filter 下推后由于参与 Join 的数据量变少而提高了性能。另一方面，在物理层面，Filter 下推后，对于支持 Filter 下推的 Storage，并不需要将表的全量数据扫描出来再过滤，而是直接只扫描符合 Filter 条件的数据，从而在物理层面极大减少了扫描表的开销，提高了执行速度。</p>
<p><strong>ConstantFolding</strong></p>
<p>本文的 SQL 查询中，Project 部分包含了 100 + 800 + match_score + english_score 。如果不进行优化，那如果有一亿条记录，就会计算一亿次 100 + 80，非常浪费资源。因此可通过 ConstantFolding 将这些常量合并，从而减少不必要的计算，提高执行速度</p>
<p><img src="https://img-blog.csdnimg.cn/20190130142719285.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW9qaWFvNTIxNzY1MTQ2NTE0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p><strong>ColumnPruning</strong></p>
<p>在上图中，Filter 与 Join 操作会保留两边所有字段，然后在 Project 操作中筛选出需要的特定列。如果能将 Project 下推，在扫描表时就只筛选出满足后续操作的最小字段集，则能大大减少 Filter 与 Project 操作的中间结果集数据量，从而极大提高执行速度。<br><img src="https://img-blog.csdnimg.cn/20190130143128524.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW9qaWFvNTIxNzY1MTQ2NTE0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>此处的优化是逻辑上的优化。在物理上，Project 下推后，对于列式存储，如 Parquet 和 ORC，可在扫描表时就只扫描需要的列而跳过不需要的列，进一步减少了扫描开销，提高了执行速度。</p>
<h2 id="2-4-SparkPlanner"><a href="#2-4-SparkPlanner" class="headerlink" title="2.4 SparkPlanner"></a>2.4 SparkPlanner</h2><p>得到优化后的 LogicalPlan 后，SparkPlanner 将其转化为 SparkPlan 即物理计划。</p>
<h3 id="第一步-planner-plan-ReturnAnswer-optimizedPlan-next"><a href="#第一步-planner-plan-ReturnAnswer-optimizedPlan-next" class="headerlink" title="第一步:planner.plan(ReturnAnswer(optimizedPlan)).next()"></a>第一步:planner.plan(ReturnAnswer(optimizedPlan)).next()</h3><p>源码地址：org.apache.spark.sql.catalyst.planning.QueryPlanner.scala</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericStrategy</span>[<span class="type">PhysicalPlan</span> &lt;: <span class="type">TreeNode</span>[<span class="type">PhysicalPlan</span>]] <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Returns a placeholder for a physical plan that executes `plan`. This placeholder will be</span></span><br><span class="line"><span class="comment">   * filled in automatically by the QueryPlanner using the other execution strategies that are</span></span><br><span class="line"><span class="comment">   * available.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">planLater</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">PhysicalPlan</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">Seq</span>[<span class="type">PhysicalPlan</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">QueryPlanner</span>[<span class="type">PhysicalPlan</span> &lt;: <span class="type">TreeNode</span>[<span class="type">PhysicalPlan</span>]] </span>&#123;</span><br><span class="line">  <span class="comment">/** A list of execution strategies that can be used by the planner */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">strategies</span></span>: <span class="type">Seq</span>[<span class="type">GenericStrategy</span>[<span class="type">PhysicalPlan</span>]]</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 整合所有的Strategy，_(plan)每个Strategy应用plan上，</span></span><br><span class="line"><span class="comment">   * 得到所有Strategies执行完后生成的所有Physical Plan的集合。</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">plan</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">Iterator</span>[<span class="type">PhysicalPlan</span>] = &#123;</span><br><span class="line">    <span class="comment">// Obviously a lot to do here still...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Collect physical plan candidates.</span></span><br><span class="line">    <span class="comment">// strategies 实现了转化</span></span><br><span class="line">    <span class="keyword">val</span> candidates = strategies.iterator.flatMap(_(plan))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// The candidates may contain placeholders marked as [[planLater]],</span></span><br><span class="line">    <span class="comment">// so try to replace them by their child plans.</span></span><br><span class="line">    <span class="comment">// 移除planLater</span></span><br><span class="line">    <span class="keyword">val</span> plans = candidates.flatMap &#123; candidate =&gt;</span><br><span class="line">      <span class="keyword">val</span> placeholders = collectPlaceholders(candidate)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (placeholders.isEmpty) &#123;</span><br><span class="line">        <span class="comment">// Take the candidate as is because it does not contain placeholders.</span></span><br><span class="line">        <span class="type">Iterator</span>(candidate)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// Plan the logical plan marked as [[planLater]] and replace the placeholders.</span></span><br><span class="line">        placeholders.iterator.foldLeft(<span class="type">Iterator</span>(candidate)) &#123;</span><br><span class="line">          <span class="keyword">case</span> (candidatesWithPlaceholders, (placeholder, logicalPlan)) =&gt;</span><br><span class="line">            <span class="comment">// Plan the logical plan for the placeholder.</span></span><br><span class="line">            <span class="keyword">val</span> childPlans = <span class="keyword">this</span>.plan(logicalPlan)</span><br><span class="line"></span><br><span class="line">            candidatesWithPlaceholders.flatMap &#123; candidateWithPlaceholders =&gt;</span><br><span class="line">              childPlans.map &#123; childPlan =&gt;</span><br><span class="line">                <span class="comment">// Replace the placeholder by the child plan</span></span><br><span class="line">                candidateWithPlaceholders.transformUp &#123;</span><br><span class="line">                  <span class="keyword">case</span> p <span class="keyword">if</span> p.eq(placeholder) =&gt; childPlan</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 裁剪plan，去掉 bad plan，但目前只是原封不动返回</span></span><br><span class="line">    <span class="keyword">val</span> pruned = prunePlans(plans)</span><br><span class="line">    assert(pruned.hasNext, <span class="string">s&quot;No plan for <span class="subst">$plan</span>&quot;</span>)</span><br><span class="line">    pruned</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>



<h3 id="第二步-SparkPlanner继承于SparkStrategies，而SparkStrategies继承了QueryPlanner"><a href="#第二步-SparkPlanner继承于SparkStrategies，而SparkStrategies继承了QueryPlanner" class="headerlink" title="第二步:SparkPlanner继承于SparkStrategies，而SparkStrategies继承了QueryPlanner"></a>第二步:SparkPlanner继承于SparkStrategies，而SparkStrategies继承了QueryPlanner</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//包含不同策略的策略来优化物理执行计划</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SparkPlanner</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    val sparkContext: <span class="type">SparkContext</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    val conf: <span class="type">SQLConf</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    val experimentalMethods: <span class="type">ExperimentalMethods</span></span>)</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">SparkStrategies</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//partitions的个数 </span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">numPartitions</span></span>: <span class="type">Int</span> = conf.numShufflePartitions</span><br><span class="line"></span><br><span class="line">  <span class="comment">//策略的集合</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">strategies</span></span>: <span class="type">Seq</span>[<span class="type">Strategy</span>] =</span><br><span class="line">    experimentalMethods.extraStrategies ++</span><br><span class="line">      extraPlanningStrategies ++ (</span><br><span class="line">      <span class="type">PythonEvals</span> ::</span><br><span class="line">      <span class="type">DataSourceV2Strategy</span> ::</span><br><span class="line">      <span class="comment">//一个针对Hadoop文件系统做的策略，当执行计划的底层Relation是HadoopFsRelation时会调用到，用来扫描文件</span></span><br><span class="line">      <span class="type">FileSourceStrategy</span> ::</span><br><span class="line">      <span class="comment">//Spark针对DataSource预定义了四种scan接口，TableScan、PrunedScan、PrunedFilteredScan、CatalystScan</span></span><br><span class="line">      <span class="comment">//(CatalystScan是unstable的，也是不常用的)，如果开发者（用户）自己实现的DataSource是实现了这四种接口之一的</span></span><br><span class="line">      <span class="comment">//在scan到执行计划的底层Relation时，就会调用来扫描文件</span></span><br><span class="line">      <span class="type">DataSourceStrategy</span>(conf) ::</span><br><span class="line">      <span class="comment">//在Spark SQL中加limit n时候回调用到（如果不指定，Spark 默认也会limit 20），</span></span><br><span class="line">      <span class="comment">//在源码中，会给每种case的limit节点的子节点使用PlanLater</span></span><br><span class="line">      <span class="type">SpecialLimits</span> ::</span><br><span class="line">      <span class="comment">//执行聚合函数的策略</span></span><br><span class="line">      <span class="type">Aggregation</span> ::</span><br><span class="line">      <span class="type">Window</span> ::</span><br><span class="line">      <span class="comment">//JoinSelection用到了相关的统计信息来选择将Join转换为</span></span><br><span class="line">      <span class="comment">//BroadcastHashJoinExec还是ShuffledHashJoinExec</span></span><br><span class="line">      <span class="comment">//还是SortMergeJoinExec，属于CBO基于代价的策略</span></span><br><span class="line">      <span class="type">JoinSelection</span> ::</span><br><span class="line">      <span class="comment">//当数据在内存中被缓存过，就会用到该策略。</span></span><br><span class="line">      <span class="type">InMemoryScans</span> ::</span><br><span class="line">      <span class="comment">//一些基本操作的执行策略，如flatMap，sort，project等，但是实际上大都是给这些节点的子节点套上一个PlanLater。</span></span><br><span class="line">      <span class="type">BasicOperators</span> :: <span class="type">Nil</span>)</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20190130175726850.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW9qaWFvNTIxNzY1MTQ2NTE0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>直接使用 BroadcastExchangeExec 将数据广播出去，然后结合广播数据对 people 表使用 BroadcastHashJoinExec 进行 Join。再经过 Project 后使用 HashAggregateExec 进行分组聚合。</p>
<h3 id="第三步-lazy-val-executedPlan-SparkPlan-prepareForExecution-sparkPlan-执行前的一些准备工作"><a href="#第三步-lazy-val-executedPlan-SparkPlan-prepareForExecution-sparkPlan-执行前的一些准备工作" class="headerlink" title="第三步:lazy val executedPlan: SparkPlan = prepareForExecution(sparkPlan) 执行前的一些准备工作"></a>第三步:lazy val executedPlan: SparkPlan = prepareForExecution(sparkPlan) 执行前的一些准备工作</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">prepareForExecution</span></span>(plan: <span class="type">SparkPlan</span>): <span class="type">SparkPlan</span> = &#123;</span><br><span class="line">  <span class="comment">//将规则遍历应用到plan</span></span><br><span class="line">  preparations.foldLeft(plan) &#123; <span class="keyword">case</span> (sp, rule) =&gt; rule.apply(sp) &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** A sequence of rules that will be applied in order to the physical plan before execution. */</span></span><br><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">preparations</span></span>: <span class="type">Seq</span>[<span class="type">Rule</span>[<span class="type">SparkPlan</span>]] = <span class="type">Seq</span>(</span><br><span class="line">  <span class="type">PlanSubqueries</span>(sparkSession),</span><br><span class="line">  <span class="type">EnsureRequirements</span>(sparkSession.sessionState.conf),</span><br><span class="line">  <span class="type">CollapseCodegenStages</span>(sparkSession.sessionState.conf),</span><br><span class="line">  <span class="type">ReuseExchange</span>(sparkSession.sessionState.conf),</span><br><span class="line">  <span class="type">ReuseSubquery</span>(sparkSession.sessionState.conf))</span><br></pre></td></tr></table></figure>

<h3 id="第四步-EnsureRequirements的apply-方法"><a href="#第四步-EnsureRequirements的apply-方法" class="headerlink" title="第四步:EnsureRequirements的apply 方法"></a>第四步:EnsureRequirements的apply 方法</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(plan: <span class="type">SparkPlan</span>): <span class="type">SparkPlan</span> = plan.transformUp &#123;</span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> remove this after we create a physical operator for `RepartitionByExpression`.</span></span><br><span class="line">  <span class="keyword">case</span> operator @ <span class="type">ShuffleExchangeExec</span>(upper: <span class="type">HashPartitioning</span>, child, _) =&gt;</span><br><span class="line">    child.outputPartitioning <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> lower: <span class="type">HashPartitioning</span> <span class="keyword">if</span> upper.semanticEquals(lower) =&gt; child</span><br><span class="line">      <span class="keyword">case</span> _ =&gt; operator</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">case</span> operator: <span class="type">SparkPlan</span> =&gt;</span><br><span class="line">    <span class="comment">//执行 ensureDistributionAndOrdering</span></span><br><span class="line">    ensureDistributionAndOrdering(reorderJoinPredicates(operator))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="第五步-ensureDistributionAndOrdering方法"><a href="#第五步-ensureDistributionAndOrdering方法" class="headerlink" title="第五步:ensureDistributionAndOrdering方法"></a>第五步:ensureDistributionAndOrdering方法</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Preparations 会比较 children的实际输出分布和需求输出分布的不同(比较partitioning)，</span></span><br><span class="line"><span class="comment">  * 然后添加ShuffleExchangeExec、ExchangeCoordinator、SortExec做转化处理，使其匹配</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">ensureDistributionAndOrdering</span></span>(operator: <span class="type">SparkPlan</span>): <span class="type">SparkPlan</span> = &#123;</span><br><span class="line">   <span class="keyword">val</span> requiredChildDistributions: <span class="type">Seq</span>[<span class="type">Distribution</span>] = operator.requiredChildDistribution</span><br><span class="line">   <span class="keyword">val</span> requiredChildOrderings: <span class="type">Seq</span>[<span class="type">Seq</span>[<span class="type">SortOrder</span>]] = operator.requiredChildOrdering</span><br><span class="line">   <span class="keyword">var</span> children: <span class="type">Seq</span>[<span class="type">SparkPlan</span>] = operator.children</span><br><span class="line">   assert(requiredChildDistributions.length == children.length)</span><br><span class="line">   assert(requiredChildOrderings.length == children.length)</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Ensure that the operator&#x27;s children satisfy their output distribution requirements.</span></span><br><span class="line">   <span class="comment">// children的实际输出分布(其实就是partitioning)满足要求的输出分布</span></span><br><span class="line">   children = children.zip(requiredChildDistributions).map &#123;</span><br><span class="line">     <span class="comment">//满足，直接返回</span></span><br><span class="line">     <span class="keyword">case</span> (child, distribution) <span class="keyword">if</span> child.outputPartitioning.satisfies(distribution) =&gt;</span><br><span class="line">       child</span><br><span class="line">     <span class="comment">// 广播单独处理</span></span><br><span class="line">     <span class="keyword">case</span> (child, <span class="type">BroadcastDistribution</span>(mode)) =&gt;</span><br><span class="line">       <span class="type">BroadcastExchangeExec</span>(mode, child)</span><br><span class="line">     <span class="keyword">case</span> (child, distribution) =&gt;</span><br><span class="line">       <span class="keyword">val</span> numPartitions = distribution.requiredNumPartitions</span><br><span class="line">         .getOrElse(defaultNumPreShufflePartitions)</span><br><span class="line">        <span class="comment">// 做一次shuffle(可以认为是重新分区,改变分布)，满足需求。</span></span><br><span class="line">       <span class="type">ShuffleExchangeExec</span>(distribution.createPartitioning(numPartitions), child)</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Get the indexes of children which have specified distribution requirements and need to have</span></span><br><span class="line">   <span class="comment">// same number of partitions.</span></span><br><span class="line">   <span class="comment">// 过滤有指定分布需求的children</span></span><br><span class="line">   <span class="keyword">val</span> childrenIndexes = requiredChildDistributions.zipWithIndex.filter &#123;</span><br><span class="line">     <span class="keyword">case</span> (<span class="type">UnspecifiedDistribution</span>, _) =&gt; <span class="literal">false</span></span><br><span class="line">     <span class="keyword">case</span> (_: <span class="type">BroadcastDistribution</span>, _) =&gt; <span class="literal">false</span></span><br><span class="line">     <span class="keyword">case</span> _ =&gt; <span class="literal">true</span></span><br><span class="line">   &#125;.map(_._2)</span><br><span class="line"></span><br><span class="line">   <span class="comment">// children 的 partition 数量</span></span><br><span class="line">   <span class="keyword">val</span> childrenNumPartitions =</span><br><span class="line">     childrenIndexes.map(children(_).outputPartitioning.numPartitions).toSet</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> (childrenNumPartitions.size &gt; <span class="number">1</span>) &#123;</span><br><span class="line">     <span class="comment">// Get the number of partitions which is explicitly required by the distributions.</span></span><br><span class="line">     <span class="comment">// children 的分布需要的partition数量</span></span><br><span class="line">     <span class="keyword">val</span> requiredNumPartitions = &#123;</span><br><span class="line">       <span class="keyword">val</span> numPartitionsSet = childrenIndexes.flatMap &#123;</span><br><span class="line">         index =&gt; requiredChildDistributions(index).requiredNumPartitions</span><br><span class="line">       &#125;.toSet</span><br><span class="line">       assert(numPartitionsSet.size &lt;= <span class="number">1</span>,</span><br><span class="line">         <span class="string">s&quot;<span class="subst">$operator</span> have incompatible requirements of the number of partitions for its children&quot;</span>)</span><br><span class="line">       numPartitionsSet.headOption</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="comment">// partition 数量目标</span></span><br><span class="line">     <span class="keyword">val</span> targetNumPartitions = requiredNumPartitions.getOrElse(childrenNumPartitions.max)</span><br><span class="line">     <span class="comment">// 指定分布的children的partition数量全部统一为 targetNumPartitions</span></span><br><span class="line">     children = children.zip(requiredChildDistributions).zipWithIndex.map &#123;</span><br><span class="line">       <span class="keyword">case</span> ((child, distribution), index) <span class="keyword">if</span> childrenIndexes.contains(index) =&gt;</span><br><span class="line">         <span class="keyword">if</span> (child.outputPartitioning.numPartitions == targetNumPartitions) &#123;</span><br><span class="line">           child   <span class="comment">// 符合目标，直接返回</span></span><br><span class="line">         &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="comment">// 不符合目标，shuffle</span></span><br><span class="line">           <span class="keyword">val</span> defaultPartitioning = distribution.createPartitioning(targetNumPartitions)</span><br><span class="line">           child <span class="keyword">match</span> &#123;</span><br><span class="line">             <span class="comment">// If child is an exchange, we replace it with a new one having defaultPartitioning.</span></span><br><span class="line">             <span class="keyword">case</span> <span class="type">ShuffleExchangeExec</span>(_, c, _) =&gt; <span class="type">ShuffleExchangeExec</span>(defaultPartitioning, c)</span><br><span class="line">             <span class="keyword">case</span> _ =&gt; <span class="type">ShuffleExchangeExec</span>(defaultPartitioning, child)</span><br><span class="line">           &#125;</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">case</span> ((child, _), _) =&gt; child</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Now, we need to add ExchangeCoordinator if necessary.</span></span><br><span class="line">   <span class="comment">// Actually, it is not a good idea to add ExchangeCoordinators while we are adding Exchanges.</span></span><br><span class="line">   <span class="comment">// However, with the way that we plan the query, we do not have a place where we have a</span></span><br><span class="line">   <span class="comment">// global picture of all shuffle dependencies of a post-shuffle stage. So, we add coordinator</span></span><br><span class="line">   <span class="comment">// at here for now.</span></span><br><span class="line">   <span class="comment">// Once we finish https://issues.apache.org/jira/browse/SPARK-10665,</span></span><br><span class="line">   <span class="comment">// we can first add Exchanges and then add coordinator once we have a DAG of query fragments.</span></span><br><span class="line">   <span class="comment">//添加ExchangeCoordinator,调节多个spark plan的数据分布</span></span><br><span class="line">   children = withExchangeCoordinator(children, requiredChildDistributions)</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Now that we&#x27;ve performed any necessary shuffles, add sorts to guarantee output orderings:</span></span><br><span class="line">   <span class="comment">// 如果有sort的需求，则加上SortExec</span></span><br><span class="line">   children = children.zip(requiredChildOrderings).map &#123; <span class="keyword">case</span> (child, requiredOrdering) =&gt;</span><br><span class="line">     <span class="comment">// If child.outputOrdering already satisfies the requiredOrdering, we do not need to sort.</span></span><br><span class="line">     <span class="keyword">if</span> (<span class="type">SortOrder</span>.orderingSatisfies(child.outputOrdering, requiredOrdering)) &#123;</span><br><span class="line">       child</span><br><span class="line">     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       <span class="type">SortExec</span>(requiredOrdering, global = <span class="literal">false</span>, child = child)</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   operator.withNewChildren(children)</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<h3 id="第六步-withExchangeCoordinator-children-requiredChildDistributions-方法"><a href="#第六步-withExchangeCoordinator-children-requiredChildDistributions-方法" class="headerlink" title="第六步:withExchangeCoordinator(children, requiredChildDistributions)方法"></a>第六步:withExchangeCoordinator(children, requiredChildDistributions)方法</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">withExchangeCoordinator</span></span>(</span><br><span class="line">    children: <span class="type">Seq</span>[<span class="type">SparkPlan</span>],</span><br><span class="line">    requiredChildDistributions: <span class="type">Seq</span>[<span class="type">Distribution</span>]): <span class="type">Seq</span>[<span class="type">SparkPlan</span>] = &#123;</span><br><span class="line">  <span class="comment">// 判断是否需要添加 ExchangeCoordinator</span></span><br><span class="line">  <span class="keyword">val</span> supportsCoordinator =</span><br><span class="line">    <span class="keyword">if</span> (children.exists(_.isInstanceOf[<span class="type">ShuffleExchangeExec</span>])) &#123;</span><br><span class="line">      <span class="comment">// Right now, ExchangeCoordinator only support HashPartitionings.</span></span><br><span class="line">      children.forall &#123;</span><br><span class="line">        <span class="comment">// 条件1 children中有ShuffleExchangeExec且分区为HashPartitioning  </span></span><br><span class="line">        <span class="keyword">case</span> e @ <span class="type">ShuffleExchangeExec</span>(hash: <span class="type">HashPartitioning</span>, _, _) =&gt; <span class="literal">true</span></span><br><span class="line">        <span class="keyword">case</span> child =&gt;</span><br><span class="line">          child.outputPartitioning <span class="keyword">match</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> hash: <span class="type">HashPartitioning</span> =&gt; <span class="literal">true</span></span><br><span class="line">            <span class="keyword">case</span> collection: <span class="type">PartitioningCollection</span> =&gt;</span><br><span class="line">              collection.partitionings.forall(_.isInstanceOf[<span class="type">HashPartitioning</span>])</span><br><span class="line">            <span class="keyword">case</span> _ =&gt; <span class="literal">false</span></span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// In this case, although we do not have Exchange operators, we may still need to</span></span><br><span class="line">      <span class="comment">// shuffle data when we have more than one children because data generated by</span></span><br><span class="line">      <span class="comment">// these children may not be partitioned in the same way.</span></span><br><span class="line">      <span class="comment">// Please see the comment in withCoordinator for more details.</span></span><br><span class="line">      <span class="comment">// 条件2 分布为ClusteredDistribution 或 HashClusteredDistribution</span></span><br><span class="line">      <span class="keyword">val</span> supportsDistribution = requiredChildDistributions.forall &#123; dist =&gt;</span><br><span class="line">        dist.isInstanceOf[<span class="type">ClusteredDistribution</span>] || dist.isInstanceOf[<span class="type">HashClusteredDistribution</span>]</span><br><span class="line">      &#125;</span><br><span class="line">      children.length &gt; <span class="number">1</span> &amp;&amp; supportsDistribution</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> withCoordinator =</span><br><span class="line">    <span class="comment">// adaptiveExecutionEnabled 且 符合条件1或2</span></span><br><span class="line">    <span class="comment">//adaptiveExecutionEnabled 默认是false的，所以ExchangeCoordinator默认是关闭的</span></span><br><span class="line">    <span class="keyword">if</span> (adaptiveExecutionEnabled &amp;&amp; supportsCoordinator) &#123;</span><br><span class="line">      <span class="keyword">val</span> coordinator =</span><br><span class="line">        <span class="keyword">new</span> <span class="type">ExchangeCoordinator</span>(</span><br><span class="line">          targetPostShuffleInputSize,</span><br><span class="line">          minNumPostShufflePartitions)</span><br><span class="line">      children.zip(requiredChildDistributions).map &#123;</span><br><span class="line">        <span class="keyword">case</span> (e: <span class="type">ShuffleExchangeExec</span>, _) =&gt;</span><br><span class="line">          <span class="comment">// This child is an Exchange, we need to add the coordinator.</span></span><br><span class="line">          <span class="comment">// 条件1， 直接添加 coordinator</span></span><br><span class="line">          e.copy(coordinator = <span class="type">Some</span>(coordinator))</span><br><span class="line">        <span class="keyword">case</span> (child, distribution) =&gt;</span><br><span class="line">          <span class="comment">// If this child is not an Exchange, we need to add an Exchange for now.</span></span><br><span class="line">          <span class="comment">// Ideally, we can try to avoid this Exchange. However, when we reach here,</span></span><br><span class="line">          <span class="comment">// there are at least two children operators (because if there is a single child</span></span><br><span class="line">          <span class="comment">// and we can avoid Exchange, supportsCoordinator will be false and we</span></span><br><span class="line">          <span class="comment">// will not reach here.). Although we can make two children have the same number of</span></span><br><span class="line">          <span class="comment">// post-shuffle partitions. Their numbers of pre-shuffle partitions may be different.</span></span><br><span class="line">          <span class="comment">// For example, let&#x27;s say we have the following plan</span></span><br><span class="line">          <span class="comment">//         Join</span></span><br><span class="line">          <span class="comment">//         /  \</span></span><br><span class="line">          <span class="comment">//       Agg  Exchange</span></span><br><span class="line">          <span class="comment">//       /      \</span></span><br><span class="line">          <span class="comment">//    Exchange  t2</span></span><br><span class="line">          <span class="comment">//      /</span></span><br><span class="line">          <span class="comment">//     t1</span></span><br><span class="line">          <span class="comment">// In this case, because a post-shuffle partition can include multiple pre-shuffle</span></span><br><span class="line">          <span class="comment">// partitions, a HashPartitioning will not be strictly partitioned by the hashcodes</span></span><br><span class="line">          <span class="comment">// after shuffle. So, even we can use the child Exchange operator of the Join to</span></span><br><span class="line">          <span class="comment">// have a number of post-shuffle partitions that matches the number of partitions of</span></span><br><span class="line">          <span class="comment">// Agg, we cannot say these two children are partitioned in the same way.</span></span><br><span class="line">          <span class="comment">// Here is another case</span></span><br><span class="line">          <span class="comment">//         Join</span></span><br><span class="line">          <span class="comment">//         /  \</span></span><br><span class="line">          <span class="comment">//       Agg1  Agg2</span></span><br><span class="line">          <span class="comment">//       /      \</span></span><br><span class="line">          <span class="comment">//   Exchange1  Exchange2</span></span><br><span class="line">          <span class="comment">//       /       \</span></span><br><span class="line">          <span class="comment">//      t1       t2</span></span><br><span class="line">          <span class="comment">// In this case, two Aggs shuffle data with the same column of the join condition.</span></span><br><span class="line">          <span class="comment">// After we use ExchangeCoordinator, these two Aggs may not be partitioned in the same</span></span><br><span class="line">          <span class="comment">// way. Let&#x27;s say that Agg1 and Agg2 both have 5 pre-shuffle partitions and 2</span></span><br><span class="line">          <span class="comment">// post-shuffle partitions. It is possible that Agg1 fetches those pre-shuffle</span></span><br><span class="line">          <span class="comment">// partitions by using a partitionStartIndices [0, 3]. However, Agg2 may fetch its</span></span><br><span class="line">          <span class="comment">// pre-shuffle partitions by using another partitionStartIndices [0, 4].</span></span><br><span class="line">          <span class="comment">// So, Agg1 and Agg2 are actually not co-partitioned.</span></span><br><span class="line">          <span class="comment">//</span></span><br><span class="line">          <span class="comment">// It will be great to introduce a new Partitioning to represent the post-shuffle</span></span><br><span class="line">          <span class="comment">// partitions when one post-shuffle partition includes multiple pre-shuffle partitions.</span></span><br><span class="line">          <span class="comment">// 条件2，这个child的children虽然分区数目一样，但是不一定是同一种分区方式，所以加上coordinator</span></span><br><span class="line">          <span class="keyword">val</span> targetPartitioning = distribution.createPartitioning(defaultNumPreShufflePartitions)</span><br><span class="line">          assert(targetPartitioning.isInstanceOf[<span class="type">HashPartitioning</span>])</span><br><span class="line">          <span class="type">ShuffleExchangeExec</span>(targetPartitioning, child, <span class="type">Some</span>(coordinator))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// If we do not need ExchangeCoordinator, the original children are returned.</span></span><br><span class="line">      children</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  withCoordinator</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="第七步-executedPlan-execute-最后一步执行"><a href="#第七步-executedPlan-execute-最后一步执行" class="headerlink" title="第七步:executedPlan.execute()最后一步执行"></a>第七步:executedPlan.execute()最后一步执行</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">execute</span></span>(): <span class="type">RDD</span>[<span class="type">InternalRow</span>] = executeQuery &#123;</span><br><span class="line">  <span class="keyword">if</span> (isCanonicalizedPlan) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">&quot;A canonicalized plan is not supposed to be executed.&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//执行各个具体SparkPlan的doExecute函数</span></span><br><span class="line">  doExecute()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">executeQuery</span></span>[<span class="type">T</span>](query: =&gt; <span class="type">T</span>): <span class="type">T</span> = &#123;</span><br><span class="line">  <span class="type">RDDOperationScope</span>.withScope(sparkContext, nodeName, <span class="literal">false</span>, <span class="literal">true</span>) &#123;</span><br><span class="line">    prepare()</span><br><span class="line">    waitForSubqueries()</span><br><span class="line">    query</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">prepare</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// doPrepare() may depend on it&#x27;s children, we should call prepare() on all the children first.</span></span><br><span class="line">  children.foreach(_.prepare())</span><br><span class="line">  synchronized &#123;</span><br><span class="line">    <span class="keyword">if</span> (!prepared) &#123;</span><br><span class="line">      prepareSubqueries()</span><br><span class="line">      doPrepare()</span><br><span class="line">      prepared = <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>关键是两个函数doPrepare和doExecute方法</p>
<h3 id="第八步-以排序为例看一下SortExec的-doExecute方法"><a href="#第八步-以排序为例看一下SortExec的-doExecute方法" class="headerlink" title="第八步:以排序为例看一下SortExec的 doExecute方法"></a>第八步:以排序为例看一下SortExec的 doExecute方法</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doExecute</span></span>(): <span class="type">RDD</span>[<span class="type">InternalRow</span>] = &#123;</span><br><span class="line">  <span class="keyword">val</span> peakMemory = longMetric(<span class="string">&quot;peakMemory&quot;</span>)</span><br><span class="line">  <span class="keyword">val</span> spillSize = longMetric(<span class="string">&quot;spillSize&quot;</span>)</span><br><span class="line">  <span class="keyword">val</span> sortTime = longMetric(<span class="string">&quot;sortTime&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">//调用child的execute方法，然后对每个partition进行排序</span></span><br><span class="line">  child.execute().mapPartitionsInternal &#123; iter =&gt;</span><br><span class="line">    <span class="keyword">val</span> sorter = createSorter()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> metrics = <span class="type">TaskContext</span>.get().taskMetrics()</span><br><span class="line">    <span class="comment">// Remember spill data size of this task before execute this operator so that we can</span></span><br><span class="line">    <span class="comment">// figure out how many bytes we spilled for this operator.</span></span><br><span class="line">    <span class="keyword">val</span> spillSizeBefore = metrics.memoryBytesSpilled</span><br><span class="line">    <span class="comment">// 排序</span></span><br><span class="line">    <span class="keyword">val</span> sortedIterator = sorter.sort(iter.asInstanceOf[<span class="type">Iterator</span>[<span class="type">UnsafeRow</span>]])</span><br><span class="line">    sortTime += sorter.getSortTimeNanos / <span class="number">1000000</span></span><br><span class="line">    peakMemory += sorter.getPeakMemoryUsage</span><br><span class="line">    spillSize += metrics.memoryBytesSpilled - spillSizeBefore</span><br><span class="line">    metrics.incPeakExecutionMemory(sorter.getPeakMemoryUsage)</span><br><span class="line"></span><br><span class="line">    sortedIterator</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="第九步-child-execute-也就是ShuffleExchangeExec"><a href="#第九步-child-execute-也就是ShuffleExchangeExec" class="headerlink" title="第九步 :child.execute() 也就是ShuffleExchangeExec"></a>第九步 :child.execute() 也就是ShuffleExchangeExec</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">val</span> exchanges = <span class="type">ArrayBuffer</span>[<span class="type">ShuffleExchangeExec</span>]()</span><br><span class="line"></span><br><span class="line"><span class="keyword">override</span> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">doPrepare</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// If an ExchangeCoordinator is needed, we register this Exchange operator</span></span><br><span class="line">  <span class="comment">// to the coordinator when we do prepare. It is important to make sure</span></span><br><span class="line">  <span class="comment">// we register this operator right before the execution instead of register it</span></span><br><span class="line">  <span class="comment">// in the constructor because it is possible that we create new instances of</span></span><br><span class="line">  <span class="comment">// Exchange operators when we transform the physical plan</span></span><br><span class="line">  <span class="comment">// (then the ExchangeCoordinator will hold references of unneeded Exchanges).</span></span><br><span class="line">  <span class="comment">// So, we should only call registerExchange just before we start to execute</span></span><br><span class="line">  <span class="comment">// the plan.</span></span><br><span class="line">  coordinator <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="comment">// 向exchangeCoordinator注册该exchange</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(exchangeCoordinator) =&gt; exchangeCoordinator.registerExchange(<span class="keyword">this</span>)</span><br><span class="line">    <span class="keyword">case</span> _ =&gt;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@GuardedBy</span>(<span class="string">&quot;this&quot;</span>)</span><br><span class="line"><span class="comment">// 注册就是添加到array中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">registerExchange</span></span>(exchange: <span class="type">ShuffleExchangeExec</span>): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">  exchanges += exchange</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doExecute</span></span>(): <span class="type">RDD</span>[<span class="type">InternalRow</span>] = attachTree(<span class="keyword">this</span>, <span class="string">&quot;execute&quot;</span>) &#123;</span><br><span class="line">  <span class="comment">// Returns the same ShuffleRowRDD if this plan is used by multiple plans.</span></span><br><span class="line">   <span class="comment">// 有缓存则直接返回缓存</span></span><br><span class="line">  <span class="keyword">if</span> (cachedShuffleRDD == <span class="literal">null</span>) &#123;</span><br><span class="line">    cachedShuffleRDD = coordinator <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="comment">// 有exchangeCoordinator  </span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(exchangeCoordinator) =&gt;</span><br><span class="line">        <span class="keyword">val</span> shuffleRDD = exchangeCoordinator.postShuffleRDD(<span class="keyword">this</span>)</span><br><span class="line">        assert(shuffleRDD.partitions.length == newPartitioning.numPartitions)</span><br><span class="line">        shuffleRDD</span><br><span class="line">     <span class="comment">// 没有exchangeCoordinator</span></span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">        <span class="keyword">val</span> shuffleDependency = prepareShuffleDependency()</span><br><span class="line">        preparePostShuffleRDD(shuffleDependency)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  cachedShuffleRDD</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="第十步-没有exchangeCoordinator的情况-prepareShuffleDependency-方法"><a href="#第十步-没有exchangeCoordinator的情况-prepareShuffleDependency-方法" class="headerlink" title="第十步:没有exchangeCoordinator的情况 prepareShuffleDependency()方法"></a>第十步:没有exchangeCoordinator的情况 prepareShuffleDependency()方法</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回一个ShuffleDependency，ShuffleDependency中最重要的是rddWithPartitionIds，</span></span><br><span class="line"><span class="comment"> * 它决定了每一条InternalRow shuffle后的partition id</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span>[exchange] <span class="function"><span class="keyword">def</span> <span class="title">prepareShuffleDependency</span></span>()</span><br><span class="line">  : <span class="type">ShuffleDependency</span>[<span class="type">Int</span>, <span class="type">InternalRow</span>, <span class="type">InternalRow</span>] = &#123;</span><br><span class="line">  <span class="type">ShuffleExchangeExec</span>.prepareShuffleDependency(</span><br><span class="line">    child.execute(), child.output, newPartitioning, serializer)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepareShuffleDependency</span></span>(</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">InternalRow</span>],</span><br><span class="line">    outputAttributes: <span class="type">Seq</span>[<span class="type">Attribute</span>],</span><br><span class="line">    newPartitioning: <span class="type">Partitioning</span>,</span><br><span class="line">    serializer: <span class="type">Serializer</span>): <span class="type">ShuffleDependency</span>[<span class="type">Int</span>, <span class="type">InternalRow</span>, <span class="type">InternalRow</span>] = &#123;</span><br><span class="line"> </span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Now, we manually create a ShuffleDependency. Because pairs in rddWithPartitionIds</span></span><br><span class="line">  <span class="comment">// are in the form of (partitionId, row) and every partitionId is in the expected range</span></span><br><span class="line">  <span class="comment">// [0, part.numPartitions - 1]. The partitioner of this is a PartitionIdPassthrough.</span></span><br><span class="line">  <span class="keyword">val</span> dependency =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">ShuffleDependency</span>[<span class="type">Int</span>, <span class="type">InternalRow</span>, <span class="type">InternalRow</span>](</span><br><span class="line">      rddWithPartitionIds,</span><br><span class="line">      <span class="keyword">new</span> <span class="type">PartitionIdPassthrough</span>(part.numPartitions),</span><br><span class="line">      serializer)</span><br><span class="line"></span><br><span class="line">  dependency</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="第十一步-preparePostShuffleRDD-shuffleDependency-方法"><a href="#第十一步-preparePostShuffleRDD-shuffleDependency-方法" class="headerlink" title="第十一步: preparePostShuffleRDD(shuffleDependency)方法"></a>第十一步: preparePostShuffleRDD(shuffleDependency)方法</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[exchange] <span class="function"><span class="keyword">def</span> <span class="title">preparePostShuffleRDD</span></span>(</span><br><span class="line">    shuffleDependency: <span class="type">ShuffleDependency</span>[<span class="type">Int</span>, <span class="type">InternalRow</span>, <span class="type">InternalRow</span>],</span><br><span class="line">    specifiedPartitionStartIndices: <span class="type">Option</span>[<span class="type">Array</span>[<span class="type">Int</span>]] = <span class="type">None</span>): <span class="type">ShuffledRowRDD</span> = &#123;</span><br><span class="line">  <span class="comment">// If an array of partition start indices is provided, we need to use this array</span></span><br><span class="line">  <span class="comment">// to create the ShuffledRowRDD. Also, we need to update newPartitioning to</span></span><br><span class="line">  <span class="comment">// update the number of post-shuffle partitions.</span></span><br><span class="line">  <span class="comment">// 如果specifiedPartitionStartIndices存在，它将决定shuffle后的分区情况</span></span><br><span class="line">  <span class="comment">// exchangeCoordinator 会用到specifiedPartitionStartIndices来实现功能</span></span><br><span class="line">  specifiedPartitionStartIndices.foreach &#123; indices =&gt;</span><br><span class="line">    assert(newPartitioning.isInstanceOf[<span class="type">HashPartitioning</span>])</span><br><span class="line">    newPartitioning = <span class="type">UnknownPartitioning</span>(indices.length)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">new</span> <span class="type">ShuffledRowRDD</span>(shuffleDependency, specifiedPartitionStartIndices)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//返回结果是ShuffledRowRDD</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ShuffledRowRDD</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    var dependency: <span class="type">ShuffleDependency</span>[<span class="type">Int</span>, <span class="type">InternalRow</span>, <span class="type">InternalRow</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">    specifiedPartitionStartIndices: <span class="type">Option</span>[<span class="type">Array</span>[<span class="type">Int</span>]] = <span class="type">None</span></span>)</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">RDD</span>[<span class="type">InternalRow</span>](<span class="params">dependency.rdd.context, <span class="type">Nil</span></span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 分区数目</span></span><br><span class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">val</span> numPreShufflePartitions = dependency.partitioner.numPartitions</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 每个partition的startIndice</span></span><br><span class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">val</span> partitionStartIndices: <span class="type">Array</span>[<span class="type">Int</span>] = specifiedPartitionStartIndices <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(indices) =&gt; indices</span><br><span class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">      <span class="comment">// When specifiedPartitionStartIndices is not defined, every post-shuffle partition</span></span><br><span class="line">      <span class="comment">// corresponds to a pre-shuffle partition.</span></span><br><span class="line">      (<span class="number">0</span> until numPreShufflePartitions).toArray</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// rdd 的partitioner</span></span><br><span class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">val</span> part: <span class="type">Partitioner</span> =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">CoalescedPartitioner</span>(dependency.partitioner, partitionStartIndices)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getDependencies</span></span>: <span class="type">Seq</span>[<span class="type">Dependency</span>[_]] = <span class="type">List</span>(dependency)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="keyword">val</span> partitioner: <span class="type">Option</span>[<span class="type">Partitioner</span>] = <span class="type">Some</span>(part)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 获取所有的partition</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getPartitions</span></span>: <span class="type">Array</span>[<span class="type">Partition</span>] = &#123;</span><br><span class="line">    assert(partitionStartIndices.length == part.numPartitions)</span><br><span class="line">    <span class="type">Array</span>.tabulate[<span class="type">Partition</span>](partitionStartIndices.length) &#123; i =&gt;</span><br><span class="line">      <span class="keyword">val</span> startIndex = partitionStartIndices(i)</span><br><span class="line">      <span class="keyword">val</span> endIndex =</span><br><span class="line">        <span class="keyword">if</span> (i &lt; partitionStartIndices.length - <span class="number">1</span>) &#123;</span><br><span class="line">          partitionStartIndices(i + <span class="number">1</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          numPreShufflePartitions</span><br><span class="line">        &#125;</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ShuffledRowRDDPartition</span>(i, startIndex, endIndex)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getPreferredLocations</span></span>(partition: <span class="type">Partition</span>): <span class="type">Seq</span>[<span class="type">String</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> tracker = <span class="type">SparkEnv</span>.get.mapOutputTracker.asInstanceOf[<span class="type">MapOutputTrackerMaster</span>]</span><br><span class="line">    <span class="keyword">val</span> dep = dependencies.head.asInstanceOf[<span class="type">ShuffleDependency</span>[_, _, _]]</span><br><span class="line">    tracker.getPreferredLocationsForShuffle(dep, partition.index)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(split: <span class="type">Partition</span>, context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[<span class="type">InternalRow</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> shuffledRowPartition = split.asInstanceOf[<span class="type">ShuffledRowRDDPartition</span>]</span><br><span class="line">    <span class="comment">// The range of pre-shuffle partitions that we are fetching at here is</span></span><br><span class="line">    <span class="comment">// [startPreShufflePartitionIndex, endPreShufflePartitionIndex - 1].</span></span><br><span class="line">    <span class="keyword">val</span> reader =</span><br><span class="line">      <span class="type">SparkEnv</span>.get.shuffleManager.getReader(</span><br><span class="line">        dependency.shuffleHandle,</span><br><span class="line">        shuffledRowPartition.startPreShufflePartitionIndex,</span><br><span class="line">        shuffledRowPartition.endPreShufflePartitionIndex,</span><br><span class="line">        context)</span><br><span class="line">    reader.read().asInstanceOf[<span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">Int</span>, <span class="type">InternalRow</span>]]].map(_._2)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">clearDependencies</span></span>() &#123;</span><br><span class="line">    <span class="keyword">super</span>.clearDependencies()</span><br><span class="line">    dependency = <span class="literal">null</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * A Partitioner that might group together one or more partitions from the parent.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param parent a parent partitioner</span></span><br><span class="line"><span class="comment"> * @param partitionStartIndices indices of partitions in parent that should create new partitions</span></span><br><span class="line"><span class="comment"> *   in child (this should be an array of increasing partition IDs). For example, if we have a</span></span><br><span class="line"><span class="comment"> *   parent with 5 partitions, and partitionStartIndices is [0, 2, 4], we get three output</span></span><br><span class="line"><span class="comment"> *   partitions, corresponding to partition ranges [0, 1], [2, 3] and [4] of the parent partitioner.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CoalescedPartitioner</span>(<span class="params">val parent: <span class="type">Partitioner</span>, val partitionStartIndices: <span class="type">Array</span>[<span class="type">Int</span>]</span>)</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 实现 partition 的转换 </span></span><br><span class="line">  <span class="meta">@transient</span> <span class="keyword">private</span> <span class="keyword">lazy</span> <span class="keyword">val</span> parentPartitionMapping: <span class="type">Array</span>[<span class="type">Int</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> n = parent.numPartitions</span><br><span class="line">    <span class="keyword">val</span> result = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Int</span>](n)</span><br><span class="line">    <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until partitionStartIndices.length) &#123;</span><br><span class="line">      <span class="keyword">val</span> start = partitionStartIndices(i)</span><br><span class="line">      <span class="keyword">val</span> end = <span class="keyword">if</span> (i &lt; partitionStartIndices.length - <span class="number">1</span>) partitionStartIndices(i + <span class="number">1</span>) <span class="keyword">else</span> n</span><br><span class="line">      <span class="keyword">for</span> (j &lt;- start until end) &#123;</span><br><span class="line">        result(j) = i</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    result</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h3 id="第十二步-有exchangeCoordinator的情况-exchangeCoordinator-postShuffleRDD-this-方法"><a href="#第十二步-有exchangeCoordinator的情况-exchangeCoordinator-postShuffleRDD-this-方法" class="headerlink" title="第十二步: 有exchangeCoordinator的情况 exchangeCoordinator.postShuffleRDD(this)方法"></a>第十二步: 有exchangeCoordinator的情况 exchangeCoordinator.postShuffleRDD(this)方法</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//返回的是ShuffledRowRDD</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">postShuffleRDD</span></span>(exchange: <span class="type">ShuffleExchangeExec</span>): <span class="type">ShuffledRowRDD</span> = &#123;</span><br><span class="line">    doEstimationIfNecessary()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!postShuffleRDDs.containsKey(exchange)) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(</span><br><span class="line">        <span class="string">s&quot;The given <span class="subst">$exchange</span> is not registered in this coordinator.&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    postShuffleRDDs.get(exchange)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GuardedBy</span>(<span class="string">&quot;this&quot;</span>)</span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">doEstimationIfNecessary</span></span>(): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">  <span class="comment">// It is unlikely that this method will be called from multiple threads</span></span><br><span class="line">  <span class="comment">// (when multiple threads trigger the execution of THIS physical)</span></span><br><span class="line">  <span class="comment">// because in common use cases, we will create new physical plan after</span></span><br><span class="line">  <span class="comment">// users apply operations (e.g. projection) to an existing DataFrame.</span></span><br><span class="line">  <span class="comment">// However, if it happens, we have synchronized to make sure only one</span></span><br><span class="line">  <span class="comment">// thread will trigger the job submission.</span></span><br><span class="line">  <span class="keyword">if</span> (!estimated) &#123;</span><br><span class="line">    <span class="comment">// Make sure we have the expected number of registered Exchange operators.</span></span><br><span class="line">    assert(exchanges.length == numExchanges)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> newPostShuffleRDDs = <span class="keyword">new</span> <span class="type">JHashMap</span>[<span class="type">ShuffleExchangeExec</span>, <span class="type">ShuffledRowRDD</span>](numExchanges)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Submit all map stages</span></span><br><span class="line">    <span class="keyword">val</span> shuffleDependencies = <span class="type">ArrayBuffer</span>[<span class="type">ShuffleDependency</span>[<span class="type">Int</span>, <span class="type">InternalRow</span>, <span class="type">InternalRow</span>]]()</span><br><span class="line">    <span class="keyword">val</span> submittedStageFutures = <span class="type">ArrayBuffer</span>[<span class="type">SimpleFutureAction</span>[<span class="type">MapOutputStatistics</span>]]()</span><br><span class="line">    <span class="keyword">var</span> i = <span class="number">0</span></span><br><span class="line">    <span class="comment">// 依次执行每个注册的exchange的prepareShuffleDependency方法</span></span><br><span class="line">    <span class="keyword">while</span> (i &lt; numExchanges) &#123;</span><br><span class="line">      <span class="keyword">val</span> exchange = exchanges(i)</span><br><span class="line">      <span class="keyword">val</span> shuffleDependency = exchange.prepareShuffleDependency()</span><br><span class="line">      shuffleDependencies += shuffleDependency</span><br><span class="line">      <span class="keyword">if</span> (shuffleDependency.rdd.partitions.length != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// submitMapStage does not accept RDD with 0 partition.</span></span><br><span class="line">        <span class="comment">// So, we will not submit this dependency.</span></span><br><span class="line">        submittedStageFutures +=</span><br><span class="line">          exchange.sqlContext.sparkContext.submitMapStage(shuffleDependency)</span><br><span class="line">      &#125;</span><br><span class="line">      i += <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Wait for the finishes of those submitted map stages.</span></span><br><span class="line">    <span class="comment">// 统计结果</span></span><br><span class="line">    <span class="keyword">val</span> mapOutputStatistics = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">MapOutputStatistics</span>](submittedStageFutures.length)</span><br><span class="line">    <span class="keyword">var</span> j = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (j &lt; submittedStageFutures.length) &#123;</span><br><span class="line">      <span class="comment">// This call is a blocking call. If the stage has not finished, we will wait at here.</span></span><br><span class="line">      mapOutputStatistics(j) = submittedStageFutures(j).get()</span><br><span class="line">      j += <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If we have mapOutputStatistics.length &lt; numExchange, it is because we do not submit</span></span><br><span class="line">    <span class="comment">// a stage when the number of partitions of this dependency is 0.</span></span><br><span class="line">    assert(mapOutputStatistics.length &lt;= numExchanges)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Now, we estimate partitionStartIndices. partitionStartIndices.length will be the</span></span><br><span class="line">    <span class="comment">// number of post-shuffle partitions.</span></span><br><span class="line">    <span class="comment">// 得到partitionStartIndices</span></span><br><span class="line">    <span class="keyword">val</span> partitionStartIndices =</span><br><span class="line">      <span class="keyword">if</span> (mapOutputStatistics.length == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="type">Array</span>.empty[<span class="type">Int</span>]</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 根据 mapOutputStatistics 获取 partitionStartIndices</span></span><br><span class="line">        estimatePartitionStartIndices(mapOutputStatistics)</span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment">// 执行preparePostShuffleRDD，和没有exchangeCoordinator唯一的不同是有partitionStartIndices参数！</span></span><br><span class="line">    <span class="keyword">var</span> k = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (k &lt; numExchanges) &#123;</span><br><span class="line">      <span class="keyword">val</span> exchange = exchanges(k)</span><br><span class="line">      <span class="keyword">val</span> rdd =</span><br><span class="line">        exchange.preparePostShuffleRDD(shuffleDependencies(k), <span class="type">Some</span>(partitionStartIndices))</span><br><span class="line">      newPostShuffleRDDs.put(exchange, rdd)</span><br><span class="line"></span><br><span class="line">      k += <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Finally, we set postShuffleRDDs and estimated.</span></span><br><span class="line">    assert(postShuffleRDDs.isEmpty)</span><br><span class="line">    assert(newPostShuffleRDDs.size() == numExchanges)</span><br><span class="line">    <span class="comment">// 结果放入缓存</span></span><br><span class="line">    postShuffleRDDs.putAll(newPostShuffleRDDs)</span><br><span class="line">    estimated = <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Estimates partition start indices for post-shuffle partitions based on</span></span><br><span class="line"><span class="comment"> * mapOutputStatistics provided by all pre-shuffle stages.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">estimatePartitionStartIndices</span></span>(</span><br><span class="line">    mapOutputStatistics: <span class="type">Array</span>[<span class="type">MapOutputStatistics</span>]): <span class="type">Array</span>[<span class="type">Int</span>] = &#123;</span><br><span class="line">  <span class="comment">// If minNumPostShufflePartitions is defined, it is possible that we need to use a</span></span><br><span class="line">  <span class="comment">// value less than advisoryTargetPostShuffleInputSize as the target input size of</span></span><br><span class="line">  <span class="comment">// a post shuffle task.</span></span><br><span class="line">  <span class="comment">// 每个partition的目标inputsize，即每个分区数据量的大小</span></span><br><span class="line">  <span class="keyword">val</span> targetPostShuffleInputSize = minNumPostShufflePartitions <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(numPartitions) =&gt;</span><br><span class="line">      <span class="keyword">val</span> totalPostShuffleInputSize = mapOutputStatistics.map(_.bytesByPartitionId.sum).sum</span><br><span class="line">      <span class="comment">// The max at here is to make sure that when we have an empty table, we</span></span><br><span class="line">      <span class="comment">// only have a single post-shuffle partition.</span></span><br><span class="line">      <span class="comment">// There is no particular reason that we pick 16. We just need a number to</span></span><br><span class="line">      <span class="comment">// prevent maxPostShuffleInputSize from being set to 0.</span></span><br><span class="line">      <span class="keyword">val</span> maxPostShuffleInputSize =</span><br><span class="line">        math.max(math.ceil(totalPostShuffleInputSize / numPartitions.toDouble).toLong, <span class="number">16</span>)</span><br><span class="line">      math.min(maxPostShuffleInputSize, advisoryTargetPostShuffleInputSize)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt; advisoryTargetPostShuffleInputSize</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  logInfo(</span><br><span class="line">    <span class="string">s&quot;advisoryTargetPostShuffleInputSize: <span class="subst">$advisoryTargetPostShuffleInputSize</span>, &quot;</span> +</span><br><span class="line">    <span class="string">s&quot;targetPostShuffleInputSize <span class="subst">$targetPostShuffleInputSize</span>.&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Make sure we do get the same number of pre-shuffle partitions for those stages.</span></span><br><span class="line">  <span class="comment">// 得到分区数，应该有且只有一个数值</span></span><br><span class="line">  <span class="keyword">val</span> distinctNumPreShufflePartitions =</span><br><span class="line">    mapOutputStatistics.map(stats =&gt; stats.bytesByPartitionId.length).distinct</span><br><span class="line">  <span class="comment">// The reason that we are expecting a single value of the number of pre-shuffle partitions</span></span><br><span class="line">  <span class="comment">// is that when we add Exchanges, we set the number of pre-shuffle partitions</span></span><br><span class="line">  <span class="comment">// (i.e. map output partitions) using a static setting, which is the value of</span></span><br><span class="line">  <span class="comment">// spark.sql.shuffle.partitions. Even if two input RDDs are having different</span></span><br><span class="line">  <span class="comment">// number of partitions, they will have the same number of pre-shuffle partitions</span></span><br><span class="line">  <span class="comment">// (i.e. map output partitions).</span></span><br><span class="line">  assert(</span><br><span class="line">    distinctNumPreShufflePartitions.length == <span class="number">1</span>,</span><br><span class="line">    <span class="string">&quot;There should be only one distinct value of the number pre-shuffle partitions &quot;</span> +</span><br><span class="line">      <span class="string">&quot;among registered Exchange operator.&quot;</span>)</span><br><span class="line">  <span class="keyword">val</span> numPreShufflePartitions = distinctNumPreShufflePartitions.head</span><br><span class="line">   <span class="comment">// 开始构建partitionStartIndices  </span></span><br><span class="line">  <span class="keyword">val</span> partitionStartIndices = <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]()</span><br><span class="line">  <span class="comment">// The first element of partitionStartIndices is always 0.</span></span><br><span class="line">  partitionStartIndices += <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> postShuffleInputSize = <span class="number">0</span>L</span><br><span class="line">  <span class="comment">// 根据targetPostShuffleInputSize，对分区进行调整，会做一些合并之类的操作。</span></span><br><span class="line">  <span class="keyword">var</span> i = <span class="number">0</span></span><br><span class="line">  <span class="keyword">while</span> (i &lt; numPreShufflePartitions) &#123;</span><br><span class="line">    <span class="comment">// We calculate the total size of ith pre-shuffle partitions from all pre-shuffle stages.</span></span><br><span class="line">    <span class="comment">// Then, we add the total size to postShuffleInputSize.</span></span><br><span class="line">    <span class="keyword">var</span> nextShuffleInputSize = <span class="number">0</span>L</span><br><span class="line">    <span class="keyword">var</span> j = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (j &lt; mapOutputStatistics.length) &#123;</span><br><span class="line">      nextShuffleInputSize += mapOutputStatistics(j).bytesByPartitionId(i)</span><br><span class="line">      j += <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If including the nextShuffleInputSize would exceed the target partition size, then start a</span></span><br><span class="line">    <span class="comment">// new partition.</span></span><br><span class="line">    <span class="keyword">if</span> (i &gt; <span class="number">0</span> &amp;&amp; postShuffleInputSize + nextShuffleInputSize &gt; targetPostShuffleInputSize) &#123;</span><br><span class="line">      partitionStartIndices += i</span><br><span class="line">      <span class="comment">// reset postShuffleInputSize.</span></span><br><span class="line">      postShuffleInputSize = nextShuffleInputSize</span><br><span class="line">    &#125; <span class="keyword">else</span> postShuffleInputSize += nextShuffleInputSize</span><br><span class="line"></span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  partitionStartIndices.toArray</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>有exchangeCoordinator的情况就生成了partitionStartIndices，从而对分区进行了调整</p>
<p>execute 最终的输出是rdd，剩下的结果便是spark对rdd的运算了。其实 spark sql 最终的目标便也是生成rdd，交给spark core来运算</p>
<p><strong>本文参考:</strong></p>
<figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">https://blog.csdn.net/jiaojiao521765146514/article/details/86627052</span></span><br></pre></td></tr></table></figure>




    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>HF
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://example.com/2020/06/07/SparkSql-2-4-3%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" title="SparkSql-2.4.3源码解析">http://example.com/2020/06/07/SparkSql-2-4-3源码解析/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Spark/" rel="tag"># Spark</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/06/07/YARN-%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5/" rel="prev" title="YARN-调度策略">
      <i class="fa fa-chevron-left"></i> YARN-调度策略
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/08/09/%E7%BA%BF%E6%80%A7%E8%A1%A8/" rel="next" title="线性表">
      线性表 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%80-%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88"><span class="nav-number">1.</span> <span class="nav-text">一 架构概览</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%8C-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90"><span class="nav-number">2.</span> <span class="nav-text">二 源码分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-sql%E7%9A%84parser"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 sql的parser</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5-%E4%BB%8E-astBuilder-visitSingleStatement%E7%BB%93%E7%82%B9%E5%BC%80%E5%A7%8B%EF%BC%8C%E9%81%8D%E5%8E%86%E8%AF%AD%E6%B3%95%E6%A0%91%EF%BC%8C%E5%B0%86%E7%BB%93%E7%82%B9%E8%BD%AC%E6%8D%A2%E4%B8%BA%E9%80%BB%E8%BE%91%E8%AE%A1%E5%88%92"><span class="nav-number">2.1.1.</span> <span class="nav-text">第一步: 从 astBuilder.visitSingleStatement结点开始，遍历语法树，将结点转换为逻辑计划</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5-AstBuilder-scala-%E5%AE%9E%E7%8E%B0%E4%BA%86SqlBaseBaseVisitor%E7%94%A8%E4%BA%8E%E8%A7%A3%E6%9E%90%E9%80%BB%E8%BE%91%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">2.1.2.</span> <span class="nav-text">第二步:AstBuilder.scala 实现了SqlBaseBaseVisitor用于解析逻辑的实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5-%E6%9C%80%E7%BB%88%E8%BF%94%E5%9B%9E%E7%9A%84%E6%98%AF-Project-namedExpressions-withFilter-%EF%BC%8C%E7%BB%A7%E6%89%BF%E4%BA%86LogicalPlan"><span class="nav-number">2.1.3.</span> <span class="nav-text">第三步:最终返回的是 Project(namedExpressions, withFilter)，继承了LogicalPlan</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-analyzer%E8%A7%A3%E6%9E%90%E5%99%A8"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 analyzer解析器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5-sparkSession-sessionState-analyzer-executeAndCheck-logical-%E6%96%B9%E6%B3%95"><span class="nav-number">2.2.1.</span> <span class="nav-text">第一步:sparkSession.sessionState.analyzer.executeAndCheck(logical)方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5-execute-plan-%E6%96%B9%E6%B3%95"><span class="nav-number">2.2.2.</span> <span class="nav-text">第二步:execute(plan)方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5-super-execute-plan-%E6%96%B9%E6%B3%95"><span class="nav-number">2.2.3.</span> <span class="nav-text">第三步:super.execute(plan)方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E5%9B%9B%E6%AD%A5-rule-plan"><span class="nav-number">2.2.4.</span> <span class="nav-text">第四步:rule(plan)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%BA%94%E6%AD%A5-rule%E7%9A%84%E9%9B%86%E5%90%88-%E8%BD%AC%E6%8D%A2%E8%A7%84%E5%88%99"><span class="nav-number">2.2.5.</span> <span class="nav-text">第五步:rule的集合(转换规则)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E5%85%AD%E6%AD%A5-ResolveRelations-%E9%80%9A%E8%BF%87catalog%E8%A7%A3%E6%9E%90%E8%A1%A8%E5%90%8D"><span class="nav-number">2.2.6.</span> <span class="nav-text">第六步:ResolveRelations 通过catalog解析表名</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-Optimizer%E4%BC%98%E5%8C%96%E5%99%A8"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 Optimizer优化器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5-sparkSession-sessionState-optimizer-execute-withCachedData-%E6%96%B9%E6%B3%95"><span class="nav-number">2.3.1.</span> <span class="nav-text">第一步:sparkSession.sessionState.optimizer.execute(withCachedData)方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5-PushPredicateThroughJoin%E7%9A%84%E5%85%B3%E9%94%AE%E4%BB%A3%E7%A0%81"><span class="nav-number">2.3.2.</span> <span class="nav-text">第二步:PushPredicateThroughJoin的关键代码</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-SparkPlanner"><span class="nav-number">2.4.</span> <span class="nav-text">2.4 SparkPlanner</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5-planner-plan-ReturnAnswer-optimizedPlan-next"><span class="nav-number">2.4.1.</span> <span class="nav-text">第一步:planner.plan(ReturnAnswer(optimizedPlan)).next()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5-SparkPlanner%E7%BB%A7%E6%89%BF%E4%BA%8ESparkStrategies%EF%BC%8C%E8%80%8CSparkStrategies%E7%BB%A7%E6%89%BF%E4%BA%86QueryPlanner"><span class="nav-number">2.4.2.</span> <span class="nav-text">第二步:SparkPlanner继承于SparkStrategies，而SparkStrategies继承了QueryPlanner</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5-lazy-val-executedPlan-SparkPlan-prepareForExecution-sparkPlan-%E6%89%A7%E8%A1%8C%E5%89%8D%E7%9A%84%E4%B8%80%E4%BA%9B%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="nav-number">2.4.3.</span> <span class="nav-text">第三步:lazy val executedPlan: SparkPlan &#x3D; prepareForExecution(sparkPlan) 执行前的一些准备工作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E5%9B%9B%E6%AD%A5-EnsureRequirements%E7%9A%84apply-%E6%96%B9%E6%B3%95"><span class="nav-number">2.4.4.</span> <span class="nav-text">第四步:EnsureRequirements的apply 方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%BA%94%E6%AD%A5-ensureDistributionAndOrdering%E6%96%B9%E6%B3%95"><span class="nav-number">2.4.5.</span> <span class="nav-text">第五步:ensureDistributionAndOrdering方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E5%85%AD%E6%AD%A5-withExchangeCoordinator-children-requiredChildDistributions-%E6%96%B9%E6%B3%95"><span class="nav-number">2.4.6.</span> <span class="nav-text">第六步:withExchangeCoordinator(children, requiredChildDistributions)方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%B8%83%E6%AD%A5-executedPlan-execute-%E6%9C%80%E5%90%8E%E4%B8%80%E6%AD%A5%E6%89%A7%E8%A1%8C"><span class="nav-number">2.4.7.</span> <span class="nav-text">第七步:executedPlan.execute()最后一步执行</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E5%85%AB%E6%AD%A5-%E4%BB%A5%E6%8E%92%E5%BA%8F%E4%B8%BA%E4%BE%8B%E7%9C%8B%E4%B8%80%E4%B8%8BSortExec%E7%9A%84-doExecute%E6%96%B9%E6%B3%95"><span class="nav-number">2.4.8.</span> <span class="nav-text">第八步:以排序为例看一下SortExec的 doExecute方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%B9%9D%E6%AD%A5-child-execute-%E4%B9%9F%E5%B0%B1%E6%98%AFShuffleExchangeExec"><span class="nav-number">2.4.9.</span> <span class="nav-text">第九步 :child.execute() 也就是ShuffleExchangeExec</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E5%8D%81%E6%AD%A5-%E6%B2%A1%E6%9C%89exchangeCoordinator%E7%9A%84%E6%83%85%E5%86%B5-prepareShuffleDependency-%E6%96%B9%E6%B3%95"><span class="nav-number">2.4.10.</span> <span class="nav-text">第十步:没有exchangeCoordinator的情况 prepareShuffleDependency()方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E5%8D%81%E4%B8%80%E6%AD%A5-preparePostShuffleRDD-shuffleDependency-%E6%96%B9%E6%B3%95"><span class="nav-number">2.4.11.</span> <span class="nav-text">第十一步: preparePostShuffleRDD(shuffleDependency)方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E5%8D%81%E4%BA%8C%E6%AD%A5-%E6%9C%89exchangeCoordinator%E7%9A%84%E6%83%85%E5%86%B5-exchangeCoordinator-postShuffleRDD-this-%E6%96%B9%E6%B3%95"><span class="nav-number">2.4.12.</span> <span class="nav-text">第十二步: 有exchangeCoordinator的情况 exchangeCoordinator.postShuffleRDD(this)方法</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="HF"
      src="/images/hexo.jpg">
  <p class="site-author-name" itemprop="name">HF</p>
  <div class="site-description" itemprop="description">第二名就是头号输家</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">78</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">38</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">39</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      推荐阅读
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.54tianzhisheng.cn/tags/Flink/" title="http:&#x2F;&#x2F;www.54tianzhisheng.cn&#x2F;tags&#x2F;Flink&#x2F;" rel="noopener" target="_blank">Flink</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://nginxconfig.io/" title="https:&#x2F;&#x2F;nginxconfig.io&#x2F;" rel="noopener" target="_blank">Nginxconfig</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://linux.51yip.com/" title="http:&#x2F;&#x2F;linux.51yip.com&#x2F;" rel="noopener" target="_blank">Linux命令手册</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://echarts.baidu.com/index.html" title="https:&#x2F;&#x2F;echarts.baidu.com&#x2F;index.html" rel="noopener" target="_blank">echarts可视化库</a>
        </li>
    </ul>
  </div>
<div style="">
  <canvas id="canvas" style="width:60%;">当前浏览器不支持canvas，请更换浏览器后再试</canvas>
</div>
<script>
(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*更新时钟*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //时间发生变化
            if(NewData[i] !== data[i]){
                //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //增加小球
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*渲染*/
    function render(){
        //重置画布宽度，达到清空画布的效果
        canvas.height = 100;
        //渲染时钟
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //渲染小球
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //更新时钟
        updateDigitTime();
        //更新小球状态
        updateBalls();
        //渲染
        render();
    },50);
}

})();
</script>
      </div>

    
          <script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
         <script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
           <div class="widget-wrap">
        <h3 class="widget-title">Tag Cloud</h3>
        <div id="myCanvasContainer" class="widget tagcloud">
            <canvas width="250" height="250" id="resCanvas" style="width=100%">
                <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ai/" rel="tag">Ai</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Azkaban/" rel="tag">Azkaban</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Blog/" rel="tag">Blog</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ClouderaManager/" rel="tag">ClouderaManager</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ElSearch/" rel="tag">ElSearch</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Flink/" rel="tag">Flink</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Flume/" rel="tag">Flume</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/" rel="tag">Git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hbase/" rel="tag">Hbase</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hdfs/" rel="tag">Hdfs</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/" rel="tag">Hexo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/" rel="tag">Hive</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hue/" rel="tag">Hue</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Impala/" rel="tag">Impala</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/" rel="tag">Java</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jvm/" rel="tag">Jvm</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kettle/" rel="tag">Kettle</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kudu/" rel="tag">Kudu</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Livy/" rel="tag">Livy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MapReduce/" rel="tag">MapReduce</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mysql/" rel="tag">Mysql</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Oozie/" rel="tag">Oozie</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis/" rel="tag">Redis</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scala/" rel="tag">Scala</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Shell/" rel="tag">Shell</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/" rel="tag">Spark</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sqoop/" rel="tag">Sqoop</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Web/" rel="tag">Web</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Yarn/" rel="tag">Yarn</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ZK/" rel="tag">ZK</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E5%8F%AF%E8%A7%86%E5%8C%96/" rel="tag">数据分析与可视化</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">数据库</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%88%86%E6%9E%90/" rel="tag">数据挖掘与分析</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" rel="tag">数据结构与算法</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习与深度学习</a><span class="tag-list-count">2</span></li></ul>
            </canvas>
        </div>
    </div>
    

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright" style=" text-align:center;">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">HF</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">1.2m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">18:26</span>
</div>

  <!-- 网站运行时间的设置 -->
<div class="run_time" style=" text-align:center;">
  <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
  <script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("07/23/2017 10:00:00");//此处修改你的建站时间或者网站上线时间 
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
    } 
    setInterval("createtime()",250);
  </script>
</div>
        
<div class="busuanzi-count" style=" text-align:center;">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      我的第 <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> 位朋友，
    </span>
  



  
    <span class="site-pv">
      历经 <span class="busuanzi-value" id="busuanzi_value_site_pv"></span> 次回眸才与你相遇
    </span>
  
</div>










      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_lines.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  
<div class="moon-menu">
  <div class="moon-menu-items">
    
    <div class="moon-menu-item" onclick="back2bottom()">
      <i class='fas fa-chevron-down'></i>    </div>
    
    <div class="moon-menu-item" onclick="back2top()">
      <i class='fas fa-chevron-up'></i>    </div>
    
  </div>
  <div class="moon-menu-button">
    <svg class="moon-menu-bg">
      <circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle>
      <circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle>
    </svg>
    <div class="moon-menu-content">
      <div class="moon-menu-icon"><i class='fas fa-ellipsis-v'></i></div>
      <div class="moon-menu-text"></div>
    </div>
  </div>
</div><script src="/js/injector.js"></script>
</body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/clicklove.js"></script>
<!-- 雪花特效 -->
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/jquery.min.js"></script>
<script type="text/javascript" src="/js/snow.js"></script>